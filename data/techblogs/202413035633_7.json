[{"id": 71474, "date": "2023-10-12T09:30:00", "date_gmt": "2023-10-12T16:30:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=71474"}, "modified": "2023-11-02T11:14:42", "modified_gmt": "2023-11-02T18:14:42", "slug": "networking-for-data-centers-and-the-era-of-ai", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/networking-for-data-centers-and-the-era-of-ai/", "title": {"rendered": "Networking for Data Centers and the Era of AI"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>Traditional cloud data centers have served as the bedrock of computing infrastructure for over a decade, catering to a diverse range of users and applications. However, data centers have evolved in recent years to keep up with advancements in technology and the surging demand for AI-driven computing. This post explores the pivotal role that networking plays in shaping the future of data centers and facilitating the era of AI.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Specialized data centers: AI factories and AI clouds</h2>\n\n\n\n<p>Two distinct classes of data centers are currently emerging: AI factories and AI clouds. Both of these are tailored to meet the unique demands of AI workloads, which are characterized by their reliance on accelerated computing.</p>\n\n\n\n<p>AI factories are designed to handle massive, large-scale workflows and the development of <a href=\"https://www.nvidia.com/en-us/glossary/data-science/large-language-models/\">large language models</a> (LLMs) and other foundational AI models. These models are the building blocks with which more advanced AI systems are constructed. To enable seamless scaling and efficient utilization of resources across thousands of GPUs, a robust and high-performance network is imperative.</p>\n\n\n\n<p>AI clouds extend the capabilities of traditional cloud infrastructure to support large-scale <a href=\"https://www.nvidia.com/en-us/glossary/data-science/generative-ai/\">generative AI</a> applications. Generative AI goes beyond conventional AI systems by creating new content, such as images, text, and audio, based on the data it&#8217;s been trained on. Managing AI clouds with thousands of users requires advanced management tools and a networking infrastructure that can handle diverse workloads efficiently.</p>\n\n\n\n<h2 class=\"wp-block-heading\">AI and distributed computing</h2>\n\n\n\n<p>AI workloads are computationally intensive, particularly those involving large and complex models like ChatGPT and BERT. To expedite model training and processing vast datasets, AI practitioners have turned to distributed computing. This approach involves distributing the workload across multiple interconnected servers or nodes connected through a high-speed, low-latency network.</p>\n\n\n\n<p>Distributed computing is pivotal for the success of AI, and the network&#8217;s scalability and capacity to handle a growing number of nodes is crucial. A highly scalable network enables AI researchers to tap into more computational resources, leading to faster and improved performance.</p>\n\n\n\n<p>When crafting the network architecture for AI data centers, it&#8217;s essential to create an integrated solution with distributed computing as a top priority. Data center architects must carefully consider network design and tailor solutions to the unique demands of the AI workloads they plan to deploy.</p>\n\n\n\n<p><a href=\"https://www.nvidia.com/en-us/networking/quantum2/\">NVIDIA Quantum-2 InfiniBand</a> and<a href=\"https://www.nvidia.com/en-us/networking/spectrumx/\"> NVIDIA Spectrum-X</a> are two networking platforms specifically designed and optimized to meet the networking challenges of the AI data center, each with its own unique features and innovations.<strong>&nbsp;</strong></p>\n\n\n\n<h2 class=\"wp-block-heading\">InfiniBand drives AI performance&nbsp;</h2>\n\n\n\n<p>InfiniBand technology has been a driving force behind large-scale supercomputing deployments for complex distributed scientific computing. It has become the de facto network for AI factories. With ultra-low latencies, InfiniBand has become a linchpin for accelerating today&#8217;s mainstream high-performance computing (HPC) and AI applications. Many crucial network capabilities required for efficient AI systems are native to the NVIDIA Quantum-2 InfiniBand platform.</p>\n\n\n\n<p>In-network computing, driven by InfiniBand, integrates hardware-based computing engines into the network. This offloads complex operations at scale and utilizes the NVIDIA Scalable Hierarchical Aggregation and Reduction Protocol (SHARP), an in-network aggregation mechanism. SHARP supports multiple concurrent collective operations, doubling data bandwidth for data reductions and performance enhancements.</p>\n\n\n\n<p>The InfiniBand adaptive routing optimally spreads traffic, mitigating congestion and enhancing resource utilization. Directed by a Subnet Manager, InfiniBand selects congestion-free routes based on network conditions, maximizing efficiency without compromising order of packet arrival.</p>\n\n\n\n<p>The InfiniBand Congestion Control Architecture guarantees deterministic bandwidth and latency. It uses a three-stage process to manage congestion, preventing performance bottlenecks in AI workloads.</p>\n\n\n\n<p>These inherent optimizations empower InfiniBand to meet the demands of AI applications, ultimately driving superior performance and efficiency.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Navigating Ethernet for AI deployments</h2>\n\n\n\n<p>Deploying Ethernet networks for an AI infrastructure requires addressing needs specific to the Ethernet protocol. Over time, Ethernet has incorporated an expansive, comprehensive, and (at times) complex feature set that caters to a huge range of network scenarios.&nbsp;</p>\n\n\n\n<p>As such, out-of-the-box or traditional Ethernet isn&#8217;t explicitly designed for high performance. AI clouds that use traditional Ethernet for their compute fabric can only achieve a fraction of the performance that they would achieve with an optimized network.</p>\n\n\n\n<p>In multi-tenant environments where multiple AI jobs run simultaneously, performance isolation is critical to prevent further degradation of performance. If there is a link fault, the traditional Ethernet fabric can cause the cluster\u2019s AI performance to drop by half. This is because traditional Ethernet has primarily been optimized for everyday enterprise workflows and isn\u2019t designed to meet the demands of high-performance AI applications that rely on the <a href=\"https://developer.nvidia.com/nccl\">NVIDIA Collective Communications Library (NCCL)</a>.</p>\n\n\n\n<p>These performance issues are due to factors inherent to traditional Ethernet, including:</p>\n\n\n\n<ul>\n<li>Higher switch latencies, common across commodity ASICs</li>\n\n\n\n<li>Split buffer switch architecture, which can lead to bandwidth unfairness</li>\n\n\n\n<li>Load balancing that is suboptimized for the large flows generated by AI workloads</li>\n\n\n\n<li>Performance isolation and noisy neighbor issues</li>\n</ul>\n\n\n\n<p>The Spectrum-X networking platform solves these issues and more. Spectrum-X builds on the standard Ethernet protocol with RDMA over Converged Ethernet (RoCE) Extensions, enhancing performance for AI. These extensions leverage the best practices native to InfiniBand and bring innovations such as adaptive routing and congestion control to Ethernet.&nbsp;</p>\n\n\n\n<p>Spectrum-X is the only Ethernet platform that delivers the high effective bandwidth and performance isolation needed for multi-tenant generative AI clouds, enabled due to Spectrum-4 working in close coordination with <a href=\"https://www.nvidia.com/en-us/networking/products/data-processing-unit/\">NVIDIA BlueField-3 DPUs</a>.&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\">Summary</h2>\n\n\n\n<p>The era of AI is here, and the network is the cornerstone of its success. To fully embrace the potential of AI, data center architects must carefully consider network design and tailor these designs to the unique demands of AI workloads. Addressing \u200cnetworking considerations is key to unlocking the full potential of AI technologies and driving innovation in the data center industry.</p>\n\n\n\n<p><a href=\"https://www.nvidia.com/en-us/networking/quantum2/\">NVIDIA Quantum InfiniBand</a> is an ideal choice for AI factories, thanks to its ultra-low latencies, scalable performance, and advanced feature sets. <a href=\"https://www.nvidia.com/en-us/networking/spectrumx/\">NVIDIA Spectrum-X</a>, with its purpose-built technology innovations for AI, offers a groundbreaking solution for organizations building Ethernet-based AI clouds.</p>\n\n\n\n<p>To learn more about AI performance demands and network requirements, see the <a href=\"https://nvdam.widen.net/s/bvpmlkbgzt/networking-overall-whitepaper-networking-for-ai-2911204\">Networking for the Era of AI</a> whitepaper. Join the conversation in the <a href=\"https://forums.developer.nvidia.com/c/infrastructure/369\">NVIDIA Developer Infrastructure and Networking Forum</a>.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Traditional cloud data centers have served as the bedrock of computing infrastructure for over a decade, catering to a diverse range of users and applications. However, data centers have evolved in recent years to keep up with advancements in technology and the surging demand for AI-driven computing. This post explores the pivotal role that networking &hellip; <a href=\"https://developer.nvidia.com/blog/networking-for-data-centers-and-the-era-of-ai/\">Continued</a></p>\n", "protected": false}, "author": 1890, "featured_media": 71583, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1276836", "discourse_permalink": "https://forums.developer.nvidia.com/t/networking-for-data-centers-and-the-era-of-ai/269263", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [852, 3110, 1205], "tags": [3516, 1466, 1634, 453, 658, 2932, 281, 3017], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/networking-data-center-ai.png", "jetpack_shortlink": "https://wp.me/pcCQAL-iAO", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71474"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1890"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=71474"}], "version-history": [{"count": 9, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71474/revisions"}], "predecessor-version": [{"id": 71525, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71474/revisions/71525"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/71583"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=71474"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=71474"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=71474"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 68954, "date": "2023-10-11T07:30:00", "date_gmt": "2023-10-11T14:30:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=68954"}, "modified": "2023-11-29T17:12:19", "modified_gmt": "2023-11-30T01:12:19", "slug": "announcing-steerlm-a-simple-and-practical-technique-to-customize-llms-during-inference", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/announcing-steerlm-a-simple-and-practical-technique-to-customize-llms-during-inference/", "title": {"rendered": "Announcing NVIDIA SteerLM: A Simple and Practical Technique to Customize LLMs During Inference"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>With the advent of <a href=\"https://www.nvidia.com/en-us/glossary/data-science/large-language-models/\">large language models (LLMs)</a> such as GPT-3, Megatron-Turing, Chinchilla, PaLM-2, Falcon, and Llama 2, remarkable progress in natural language generation has been made in recent years. However, despite their ability to produce human-like text, \u200cfoundation LLMs can fail to provide helpful and nuanced responses aligned with user preferences.&nbsp;</p>\n\n\n\n<p>The current approach to improving LLMs involves <a href=\"https://developer.nvidia.com/blog/selecting-large-language-model-customization-techniques/\">supervised fine-tuning (SFT</a>) on human demonstrations followed by reinforcement learning from human feedback (RLHF). While RLHF can enhance performance, it has some limitations, including training complexity and a lack of user control.</p>\n\n\n\n<p>To overcome these challenges, NVIDIA Research developed and released NVIDIA SteerLM, a new four-step technique that simplifies LLM customization while enabling dynamic steering of model outputs based on attributes you specify, as part of <a href=\"https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/\">NVIDIA NeMo</a>. This post provides an in-depth look at how SteerLM works, why it marks a significant advance, and how to train a SteerLM model.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Language models bring promise and potential pitfalls</h2>\n\n\n\n<p>By pretraining on massive text corpora, LLMs acquire broad linguistic capabilities and world knowledge. Researchers have successfully <a href=\"https://blogs.nvidia.com/blog/2023/01/26/what-are-large-language-models-used-for/\">applied LLMs to diverse natural language processing (NLP) tasks</a> like translation, question answering, and text generation. However, these models often fail to follow user-provided instructions, and instead produce generic, repetitive, or nonsensical text. Access to human feedback is essential for customizing LLMs.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Opportunities with existing approaches&nbsp;</h2>\n\n\n\n<p>SFT augments model capabilities, but causes responses to become short and mechanical. RLHF further optimizes models by favoring human-preferred responses over alternatives. However, RLHF requires an extremely complex training infrastructure, hindering broad adoption.&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\">Introducing SteerLM&nbsp;</h2>\n\n\n\n<p>SteerLM leverages a supervised fine-tuning method that empowers you to control responses during inference. It overcomes the limitations of prior alignment techniques, and consists of four key steps:</p>\n\n\n\n<ol>\n<li>Train an attribute prediction model on human-annotated datasets to evaluate response quality on any number of attributes like helpfulness, humor, and creativity.</li>\n\n\n\n<li>Annotate diverse datasets by predicting their attribute scores, using the model from Step 1 to enrich the diversity of data available to the model.</li>\n\n\n\n<li>Perform attribute-conditioned SFT by training the LLM to generate responses conditioned on specified combinations of attributes, like user-perceived quality and helpfulness.</li>\n\n\n\n<li>Bootstrap training through model sampling by generating diverse responses conditioned on maximum quality (Figure 1, 4a), then fine-tuning on them to further improve alignment (Figure 1, 4b).&nbsp;</li>\n</ol>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"1051\" height=\"460\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/steerlm-four-steps.png\" alt=\"Diagram of the four steps of Steer LM. Step 1. The base language model is trained to assess the quality of responses by predicting attribute values. Step 2. The attribute prediction model is used to annotate response quality across diverse datasets. Step 3. Given a prompt and desired attribute values, a new base model is fine-tuned to generate responses that align with the specified attributes. Step 4. Multiple responses are sampled from the fine-tuned model in Step 3, specifying maximum quality. The sampled responses are evaluated by the trained attribute prediction model, leading to another round of fine-tuning.\n\" class=\"wp-image-68960\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/steerlm-four-steps.png 1051w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/steerlm-four-steps-300x131.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/steerlm-four-steps-625x274.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/steerlm-four-steps-179x78.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/steerlm-four-steps-768x336.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/steerlm-four-steps-645x282.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/steerlm-four-steps-500x219.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/steerlm-four-steps-160x70.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/steerlm-four-steps-362x158.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/steerlm-four-steps-251x110.png 251w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/steerlm-four-steps-1024x448.png 1024w\" sizes=\"(max-width: 1051px) 100vw, 1051px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 1. The four steps of SteerLM</em></em></figcaption></figure>\n\n\n\n<p>By relying solely on the standard language modeling objective, SteerLM simplifies alignment compared to RLHF. It supports user-steerable AI by enabling you to adjust attributes at inference time. This enables the developer to define preferences relevant to the application, unlike other techniques that require using predetermined preferences.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Unlocking customizable AI with user steering</h2>\n\n\n\n<p>A key innovation of SteerLM is enabling the user to specify desired attributes (humor level and toxicity tolerance, for example) at inference time when querying models. You can move from running one customization with SteerLM, to serving many use cases at inference time.&nbsp;</p>\n\n\n\n<p>&nbsp;SteerLM empowers a range of applications, including:</p>\n\n\n\n<ul>\n<li><strong>Gaming</strong>: Vary non-player character dialogue for game scenarios. To learn more, see <a href=\"https://www.nvidia.com/en-us/geforce/news/nvidia-ace-steerlm-npc-personalities/\">NVIDIA ACE Adds Emotion to AI-Powered NPCs with NeMo SteerLM</a>.</li>\n\n\n\n<li><strong>Education</strong>: Maintain a formal and helpful persona for student queries.</li>\n\n\n\n<li><strong>Enterprise</strong>: Serve multiple teams in an organization with personalized capabilities.</li>\n\n\n\n<li><strong>Accessibility</strong>: Curb undesired model biases by controlling sensitive attributes.</li>\n</ul>\n\n\n\n<p>Such flexibility promises to unlock a new generation of bespoke AI systems tailored to individual needs.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Democratizing state-of-the-art customization through simplified training</h2>\n\n\n\n<p>Compared to the specialized infrastructure required for other advanced customization techniques, the straightforward training scheme of SteerLM makes state-of-the-art customization capabilities more accessible to developers. Its performance clearly demonstrates that techniques like reinforcement learning are not required for robust instruction tuning.&nbsp;</p>\n\n\n\n<p>Leveraging standard techniques such as SFT simplifies the complexity, requiring minimal changes to infrastructure and code. Reasonable results can be achieved with limited hyperparameter optimization.&nbsp;</p>\n\n\n\n<p>Overall, this leads to a simple and practical approach to obtaining highly accurate customized LLMs. In our experiments, SteerLM 43B achieved state-of-the-art performance on the Vicuna benchmark, outperforming existing RLHF models like LLaMA 30B RLHF. Specifically, SteerLM 43B obtained an average score of 655.75 on the Vicuna automatic evaluation, compared to scores of 646.25 for Guanaco 65B and 612.75 for LLaMA 30B RLHF.&nbsp;</p>\n\n\n\n<p>These results highlight that the straightforward training process of SteerLM can lead to customized LLMs with accuracy on par with more complex RLHF techniques. Through simplified training, SteerLM makes achieving such high levels of accuracy more accessible, enabling easier democratization of customization among developers.</p>\n\n\n\n<p>For more details, see our paper, <a href=\"https://arxiv.org/abs/2310.05344\">SteerLM: Attribute Conditioned SFT as an (User-Steerable) Alternative to RLHF</a>. You can also get information about how to experiment with a&nbsp;<a rel=\"noreferrer noopener\" href=\"https://huggingface.co/nvidia/SteerLM-llama2-13B\" target=\"_blank\">Llama 2 13B model</a>&nbsp;customized using the SteerLM method.</p>\n\n\n\n<h2 class=\"wp-block-heading\">How to train a SteerLM model&nbsp;</h2>\n\n\n\n<p>This section is a step-by-step tutorial that walks you through how to run a full SteerLM pipeline on OASST data with a 2B NeMo LLM model. It includes the following:</p>\n\n\n\n<ul>\n<li>Data cleaning and preprocessing</li>\n\n\n\n<li>Training the attribute prediction (value model)</li>\n\n\n\n<li>Training the attribute-conditioned SFT (SteerLM model)</li>\n\n\n\n<li>Inference on the SteerLM model with different attribute values</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\">Step 1: Install requirements</h3>\n\n\n\n<p>Start by installing the necessary Python libraries:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>pip install fire langchain==0.0.133</code></pre>\n\n\n\n<p><a href=\"https://developer.nvidia.com/nemo-framework\">Get access to NeMo.</a></p>\n\n\n\n<h3 class=\"wp-block-heading\">Step 2: Download and subset data</h3>\n\n\n\n<p>This tutorial uses a small subset of the OASST dataset. OASST contains open-domain conversations with human annotations for 13 different quality attributes.</p>\n\n\n\n<p>First download and subset it:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>mkdir -p data\ncd data\n\nwget https://huggingface.co/datasets/OpenAssistant/oasst1/resolve/main/2023-04-12_oasst_all.trees.jsonl.gz\n\ngunzip -f 2023-04-12_oasst_all.trees.jsonl.gz\n\nmv 2023-04-12_oasst_all.trees.jsonl data.jsonl\n\nhead -5000 data.jsonl &gt; subset_data.jsonl\n\ncd -</code></pre>\n\n\n\n<h3 class=\"wp-block-heading\">Step 3: Download Llama 2 LLM model and tokenizer and convert</h3>\n\n\n\n<p>Download the <a href=\"https://huggingface.co/meta-llama/Llama-2-7b\">Llama 2 7B LLM model</a> and tokenizer into the models folder.</p>\n\n\n\n<p>Then convert the Llama 2 LLM into .nemo format:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>python NeMo/scripts/nlp_language_modeling/convert_hf_llama_to_nemo.py --in-file /path/to/llama --out-file /output_path/llama7b.nemo</code></pre>\n\n\n\n<p>Untar the .nemo file to obtain the tokenizer in NeMo format:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>tar &lt;path-to-model&gt;/llama7b.nemo\n\nmv ba4632640484461f8ae9d61f6dfe0d0b_tokenizer.model tokenizer.model\n</code></pre>\n\n\n\n<p>The prefix for the tokenizer would be different when extracted. Ensure that the correct tokenizer file is used when running the preceding command.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Step 4: Preprocess OASST data</h3>\n\n\n\n<p>Preprocess the data using the <a href=\"https://github.com/NVIDIA/NeMo/tree/main/scripts/nlp_language_modeling/sft\">NeMo preprocessing scripts</a>. Then create separate text-to-value and value-to-text versions:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>python scripts/nlp_language_modeling/sft/preprocessing.py \\\n    --input_file=data/subset_data.jsonl \\\n    --output_file_prefix=data/subset_data_output \\\n    --mask_role=User \\\n    --type=TEXT_TO_VALUE \\\n    --split_ratio=0.95 \\\n    --seed=10\n\npython scripts/nlp_language_modeling/sft/preprocessing.py \\\n    --input_file=data/subset_data.jsonl \\\n    --output_file_prefix=data/subset_data_output_v2t \\\n    --mask_role=User \\\n    --type=VALUE_TO_TEXT \\\n    --split_ratio=0.95 \\\n    --seed=10\n</code></pre>\n\n\n\n<h3 class=\"wp-block-heading\">Step 5: Clean text-to-value data</h3>\n\n\n\n<p>Running the following script will remove the records if all the tokens are masked due to truncation by sequence length.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>python scripts/nlp_language_modeling/sft/data_clean.py \\\n    --dataset_file=data/subset_data_output_train.jsonl \\\n    --output_file=data/subset_data_output_train_clean.jsonl \\\n    --library sentencepiece \\\n    --model_file tokenizer.model \\\n    --seq_len 4096\n\npython scripts/nlp_language_modeling/sft/data_clean.py \\\n    --dataset_file=data/subset_data_output_val.jsonl \\\n    --output_file=data/subset_data_output_val_clean.jsonl \\\n    --library sentencepiece \\\n    --model_file tokenizer.model \\\n    --seq_len 4096\n</code></pre>\n\n\n\n<h3 class=\"wp-block-heading\">Step 6: Train the value model on cleaned OASST data</h3>\n\n\n\n<p>For this tutorial, train the value model for 1K steps. Note that we recommend training much longer on more data to get a good value model.&nbsp;</p>\n\n\n\n<pre class=\"wp-block-code\"><code>python examples/nlp/language_modeling/tuning/megatron_gpt_sft.py \\\n    ++trainer.limit_val_batches=10 \\\n    trainer.num_nodes=1 \\\n    trainer.devices=2 \\\n    trainer.max_epochs=null \\\n    trainer.max_steps=1000 \\\n    trainer.val_check_interval=100 \\\n    trainer.precision=bf16 \\\n    model.megatron_amp_O2=False \\\n    model.restore_from_path=/model/llama7b.nemo \\\n    model.tensor_model_parallel_size=2 \\\n    model.pipeline_model_parallel_size=1 \\\n    model.optim.lr=5e-6 \\\n    model.optim.name=distributed_fused_adam \\\n    model.optim.weight_decay=0.01 \\\n    model.answer_only_loss=True \\\n    model.activations_checkpoint_granularity=selective \\\n    model.activations_checkpoint_method=uniform \\\n    model.data.chat=True \\\n    model.data.train_ds.max_seq_length=4096 \\\n    model.data.train_ds.micro_batch_size=1 \\\n    model.data.train_ds.global_batch_size=1 \\\n  model.data.train_ds.file_names=&#091;data/subset_data_output_train_clean.jsonl] \\\n    model.data.train_ds.concat_sampling_probabilities=&#091;1.0] \\\n    model.data.train_ds.num_workers=0 \\\n\u200b\u200b    model.data.train_ds.hf_dataset=True \\\n\n    model.data.train_ds.prompt_template='\\{input\\}\\{output\\}' \\\n    model.data.train_ds.add_eos=False \\\n    model.data.validation_ds.max_seq_length=4096 \\\n    model.data.validation_ds.file_names=&#091;data/subset_data_output_val_clean.jsonl] \\\n    model.data.validation_ds.names=&#091;\"oasst\"] \\\n    model.data.validation_ds.micro_batch_size=1 \\\n    model.data.validation_ds.global_batch_size=1 \\\n    model.data.validation_ds.num_workers=0 \\\n    model.data.validation_ds.metric.name=loss \\\n    model.data.validation_ds.index_mapping_dir=/indexmap_dir \\\n    model.data.validation_ds.hf_dataset=True \\\n\nmodel.data.validation_ds.prompt_template='\\{input\\}\\{output\\}' \\\n    model.data.validation_ds.add_eos=False \\\n    model.data.test_ds.max_seq_length=4096 \\\n    model.data.test_ds.file_names=&#091;data/subset_data_output_val_clean.jsonl] \\\n    model.data.test_ds.names=&#091;\"oasst\"] \\\n    model.data.test_ds.micro_batch_size=1 \\\n    model.data.test_ds.global_batch_size=1 \\\n    model.data.test_ds.num_workers=0 \\\n    model.data.test_ds.metric.name=loss \\\n    model.data.test_ds.hf_dataset=True \\\n    model.data.test_ds.prompt_template='\\{input\\}\\{output\\}' \\\n    model.data.test_ds.add_eos=False \\\n    exp_manager.explicit_log_dir=\"/home/value_model/\" \\\n    exp_manager.create_checkpoint_callback=True \\\n    exp_manager.checkpoint_callback_params.monitor=val_loss \\\n    exp_manager.checkpoint_callback_params.mode=min</code></pre>\n\n\n\n<h3 class=\"wp-block-heading\">Step 7: Generate annotations</h3>\n\n\n\n<p>To generate annotation, run the following command in the background to run an inference server:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>python examples/nlp/language_modeling/megatron_gpt_eval.py \\\n        gpt_model_file=/models/&lt;TRAINED_ATTR_PREDICTION_MODEL.nemo&gt; \\\n        pipeline_model_parallel_split_rank=0 \\\n        server=True \\\n        tensor_model_parallel_size=1 \\\n        pipeline_model_parallel_size=1 \\\n        trainer.precision=bf16 \\\n        trainer.devices=1 \\\n        trainer.num_nodes=1 \\\n        web_server=False \\\n        port=1424\n</code></pre>\n\n\n\n<p>Now execute:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>python scripts/nlp_language_modeling/sft/attribute_annotate.py  --batch_size=1 --host=localhost --input_file_name=data/subset_data_output_v2t_train.jsonl --output_file_name=data/subset_data_v2t_train_value_output.jsonl --port_num=1424\n\npython scripts/nlp_language_modeling/sft/attribute_annotate.py  --batch_size=1 --host=localhost --input_file_name=data/subset_data_output_v2t_val.jsonl --output_file_name=data/subset_data_v2t_val_value_output.jsonl --port_num=1424\n</code></pre>\n\n\n\n<h3 class=\"wp-block-heading\">Step 8: Clean the value-to-text data</h3>\n\n\n\n<p>Remove the record if all tokens are masked after truncation by sequence length:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>python scripts/data_clean.py \\\n    --dataset_file=data/subset_data_v2t_train_value_output.jsonl \\\n    --output_file=data/subset_data_v2t_train_value_output_clean.jsonl \\\n    --library sentencepiece \\\n    --model_file tokenizer.model \\\n    --seq_len 4096\n\npython scripts/data_clean.py \\\n    --dataset_file=data/subset_data_v2t_val_value_output.jsonl \\\n    --output_file=data/subset_data_v2t_val_value_output_clean.jsonl \\\n    --library sentencepiece \\\n    --model_file tokenizer.model \\\n    --seq_len 4096</code></pre>\n\n\n\n<h3 class=\"wp-block-heading\">Step 9: Train the SteerLM model</h3>\n\n\n\n<p>For the purposes of this tutorial, the SteerLM model is trained for 1K steps. Note that we recommend training much longer and on more data to get a well-tuned model.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>python examples/nlp/language_modeling/tuning/megatron_gpt_sft.py \\\n    ++trainer.limit_val_batches=10 \\\n    trainer.num_nodes=1 \\\n    trainer.devices=2 \\\n    trainer.max_epochs=null \\\n    trainer.max_steps=1000 \\\n    trainer.val_check_interval=100 \\\n    trainer.precision=bf16 \\\n    model.megatron_amp_O2=False \\\n    model.restore_from_path=/model/llama7b.nemo \\\n    model.tensor_model_parallel_size=2 \\\n    model.pipeline_model_parallel_size=1 \\\n    model.optim.lr=5e-6 \\\n    model.optim.name=distributed_fused_adam \\\n    model.optim.weight_decay=0.01 \\\n    model.answer_only_loss=True \\\n    model.activations_checkpoint_granularity=selective \\\n    model.activations_checkpoint_method=uniform \\\n    model.data.chat=True \\\n    model.data.train_ds.max_seq_length=4096 \\\n    model.data.train_ds.micro_batch_size=1 \\\n    model.data.train_ds.global_batch_size=1 \\\n    model.data.train_ds.file_names=&#091;data/subset_data_v2t_train_value_output_clean.jsonl] \\\n    model.data.train_ds.concat_sampling_probabilities=&#091;1.0] \\\n    model.data.train_ds.num_workers=0 \\\n    model.data.train_ds.prompt_template='\\{input\\}\\{output\\}' \\\n    model.data.train_ds.add_eos=False \\\n    model.data.validation_ds.max_seq_length=4096 \\\n    model.data.validation_ds.file_names=&#091;data/subset_data_v2t_val_value_output_clean.jsonl] \\\n    model.data.validation_ds.names=&#091;\"oasst\"] \\\n    model.data.validation_ds.micro_batch_size=1 \\\n    model.data.validation_ds.global_batch_size=1 \\\n    model.data.validation_ds.num_workers=0 \\\n    model.data.validation_ds.metric.name=loss \\\n    model.data.validation_ds.index_mapping_dir=/indexmap_dir \\\n    model.data.validation_ds.prompt_template='\\{input\\}\\{output\\}' \\\n    model.data.validation_ds.add_eos=False \\\n    model.data.test_ds.max_seq_length=4096 \\\n    model.data.test_ds.file_names=&#091;data/subset_data_v2t_val_value_output_clean.jsonl] \\\n    model.data.test_ds.names=&#091;\"oasst\"] \\\n    model.data.test_ds.micro_batch_size=1 \\\n    model.data.test_ds.global_batch_size=1 \\\n    model.data.test_ds.num_workers=0 \\\n    model.data.test_ds.metric.name=loss \\\n    model.data.test_ds.prompt_template='\\{input\\}\\{output\\}' \\\n    model.data.test_ds.add_eos=False \\\n    exp_manager.explicit_log_dir=\"/home/steerlm_model/\" \\\n    exp_manager.create_checkpoint_callback=True \\\n    exp_manager.checkpoint_callback_params.monitor=val_loss \\\n    exp_manager.checkpoint_callback_params.mode=min </code></pre>\n\n\n\n<h3 class=\"wp-block-heading\">Step 10: Inference&nbsp;</h3>\n\n\n\n<p>To start inference, run an inference server in the background using the following command:</p>\n\n\n\n<pre class=\"wp-block-code\"><code>python examples/nlp/language_modeling/megatron_gpt_eval.py \\\n        gpt_model_file=/models/&lt;TRAINED_STEERLM_MODEL.nemo&gt; \\\n        pipeline_model_parallel_split_rank=0 \\\n        server=True \\\n        tensor_model_parallel_size=1 \\\n        pipeline_model_parallel_size=1 \\\n        trainer.precision=bf16 \\\n        trainer.devices=1 \\\n        trainer.num_nodes=1 \\\n        web_server=False \\\n        port=1427</code></pre>\n\n\n\n<p>Next, create Python helper functions:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\ndef get_answer(question, max_tokens, values, eval_port='1427'):\n\n    prompt = f&quot;&quot;&quot;&lt;extra_id_0&gt;System\nA chat between a curious user and an artificial intelligence assistant. \nThe assistant gives helpful, detailed, and polite answers to the user's questions.\n\n&lt;extra_id_1&gt;User\n\n{question}\n\n&lt;extra_id_1&gt;Assistant\n\n&lt;extra_id_2&gt;{values}\n\n&quot;&quot;&quot;\n\n    prompts = &#91;prompt]\n    data = {\n        &quot;sentences&quot;: prompts,\n        &quot;tokens_to_generate&quot;: max_tokens,\n        &quot;top_k&quot;: 1,\n        'greedy': True,\n        'end_strings': &#91;&quot;&lt;extra_id_1&gt;&quot;, &quot;quality:&quot;, &quot;quality:4&quot;, &quot;quality:0&quot;]\n    }\n\n    url = f&quot;http://localhost:{eval_port}/generate&quot;\n    response = requests.put(url, json=data)\n    json_response = response.json()\n\n    response_sentence = json_response&#91;'sentences']&#91;0]&#91;len(prompt):]\n\n    return response_sentence\n</pre></div>\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\ndef encode_labels(labels):\n    items = &#91;]\n    for key in labels:\n        value = labels&#91;key]\n        items.append(f'{key}:{value}')\n    return ','.join(items)\n</pre></div>\n\n\n<p>Next, change the values below to steer the language model:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\nvalues = OrderedDict(&#91;\n    ('quality', 4),\n    ('toxicity', 0),\n    ('humor', 0),\n    ('creativity', 0),\n    ('violence', 0),\n    ('helpfulness', 4),\n    ('not_appropriate', 0),\n    ('hate_speech', 0),\n    ('sexual_content', 0),\n    ('fails_task', 0),\n    ('political_content', 0),\n    ('moral_judgement', 0),\n])\nvalues = encode_labels(values)\n</pre></div>\n\n\n<p>Finally, ask questions and generate responses:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\nquestion = &quot;&quot;&quot;Where and when did techno music originate?&quot;&quot;&quot;\nprint (get_answer(question, 4096, values))\n</pre></div>\n\n\n<p>SteerLM users can perform additional bootstrapping steps using the scripts and utilities mentioned in this tutorial. This step can help further improve model accuracy on different benchmarks.&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\">The future of AI with SteerLM</h2>\n\n\n\n<p>SteerLM provides a novel technique for realizing a new generation of AI systems aligned with human preferences in a controllable manner. Its conceptual simplicity, performance gains, and customizability highlight the transformative possibilities of user-steerable AI. SteerLM is now available as open-source software, accessible through the <a href=\"https://github.com/NVIDIA/NeMo\">NVIDIA/NeMo</a> GitHub repo. You can also get information about how to experiment with a <a href=\"https://huggingface.co/nvidia/SteerLM-llama2-13B\">Llama 2 13B model</a> customized using the SteerLM method.</p>\n\n\n\n<p>For full enterprise security and support, SteerLM will be integrated into <a href=\"https://www.nvidia.com/en-us/ai-data-science/generative-ai/nemo-framework/\">NVIDIA NeMo</a>, a rich framework for building, customizing, and deploying large generative AI models. The SteerLM method works on all models supported on NeMo, including popular community-built pretrained LLMs such as Llama 2, Falcon LLM, and MPT.&nbsp;We hope our work catalyzes further research into developing models that empower users rather than constrain them. The future of AI is steerable with SteerLM.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Acknowledgments</h3>\n\n\n\n<p><em>We would like to thank Xianchao Wu and Oleksii Kuchaiev for contributing to this post and to the inception of SteerLM.&nbsp;</em></p>\n", "protected": false}, "excerpt": {"rendered": "<p>With the advent of large language models (LLMs) such as GPT-3, Megatron-Turing, Chinchilla, PaLM-2, Falcon, and Llama 2, remarkable progress in natural language generation has been made in recent years. However, despite their ability to produce human-like text, \u200cfoundation LLMs can fail to provide helpful and nuanced responses aligned with user preferences.&nbsp; The current approach &hellip; <a href=\"https://developer.nvidia.com/blog/announcing-steerlm-a-simple-and-practical-technique-to-customize-llms-during-inference/\">Continued</a></p>\n", "protected": false}, "author": 684, "featured_media": 71400, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1276188", "discourse_permalink": "https://forums.developer.nvidia.com/t/announcing-steerlm-a-simple-and-practical-technique-to-customize-llms-during-inference/269152", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [1050, 3110, 1903], "tags": [3529, 453, 2932, 1133, 1958, 61, 3633], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/steerlm-graphic.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-hWa", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/68954"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/684"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=68954"}], "version-history": [{"count": 69, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/68954/revisions"}], "predecessor-version": [{"id": 74593, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/68954/revisions/74593"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/71400"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=68954"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=68954"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=68954"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 71481, "date": "2023-10-10T12:30:00", "date_gmt": "2023-10-10T19:30:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=71481"}, "modified": "2023-11-02T11:14:44", "modified_gmt": "2023-11-02T18:14:44", "slug": "event-ai-and-data-science-virtual-summit", "status": "publish", "type": "post", "link": "https://nvda.ws/3PJHZVF", "title": {"rendered": "Event: AI and Data Science Virtual Summit"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>Meta, NetworkX, Fast.ai, and other industry leaders share how to gain new insights from your data with emerging tools.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Meta, NetworkX, Fast.ai, and other industry leaders share how to gain new insights from your data with emerging tools.</p>\n", "protected": false}, "author": 1466, "featured_media": 71482, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "", "discourse_permalink": "", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "https://nvda.ws/3PJHZVF", "_links_to_target": "_blank"}, "categories": [696, 1903], "tags": [9, 3273, 453, 1953, 1958, 695], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/data-science-summit-graphic.png", "jetpack_shortlink": "https://wp.me/pcCQAL-iAV", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71481"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1466"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=71481"}], "version-history": [{"count": 11, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71481/revisions"}], "predecessor-version": [{"id": 71517, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71481/revisions/71517"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/71482"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=71481"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=71481"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=71481"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 71163, "date": "2023-10-05T13:00:00", "date_gmt": "2023-10-05T20:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=71163"}, "modified": "2023-11-02T11:14:44", "modified_gmt": "2023-11-02T18:14:44", "slug": "just-released-nvidia-hpc-sdk-v23-9", "status": "publish", "type": "post", "link": "https://nvda.ws/48t3LWc", "title": {"rendered": "Just Released: NVIDIA HPC SDK 23.9"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>This NVIDIA HPC SDK 23.9 update expands platform support and provides minor updates.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>This NVIDIA HPC SDK 23.9 update expands platform support and provides minor updates.</p>\n", "protected": false}, "author": 1466, "featured_media": 71166, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "", "discourse_permalink": "", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "https://nvda.ws/48t3LWc", "_links_to_target": "_blank"}, "categories": [503], "tags": [453, 1258, 49, 1958, 52, 53, 56, 3420, 1914], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/networking-infiniband-dpu-for-hpc-1.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-ivN", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71163"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1466"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=71163"}], "version-history": [{"count": 12, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71163/revisions"}], "predecessor-version": [{"id": 71473, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71163/revisions/71473"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/71166"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=71163"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=71163"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=71163"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 70167, "date": "2023-10-05T11:56:17", "date_gmt": "2023-10-05T18:56:17", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=70167"}, "modified": "2023-11-02T11:14:44", "modified_gmt": "2023-11-02T18:14:44", "slug": "power-optimization-with-nvidia-jetson", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/power-optimization-with-nvidia-jetson/", "title": {"rendered": "Power Optimization with NVIDIA Jetson"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>When working with embedded systems such as the <a href=\"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/\">Jetson modules</a>, you must optimize your application based on your power budget and compute resources. To avoid performance or even thermal throttling issues, monitoring these resources becomes really important.</p>\n\n\n\n<p>Jetson modules are designed with a GPU, CPU, and various AI accelerators. They also feature a high-efficiency power management integrated circuit (PMIC), voltage regulators, and a power tree to optimize power efficiency. NVIDIA provides several tools and resources that can help you take advantage of the power architecture and optimize your resource usage: </p>\n\n\n\n<ul>\n<li>Various power modes</li>\n\n\n\n<li>Power, thermal, and electrical management features</li>\n\n\n\n<li>A Jetson Power GUI for monitoring power and thermal status</li>\n\n\n\n<li>Tegrastats for providing command-line statistics regarding the module</li>\n\n\n\n<li>JTOP</li>\n</ul>\n\n\n\n<h2 class=\"wp-block-heading\">Jetson power modes</h2>\n\n\n\n<p>Each Jetson module supports multiple preconfigured power modes that are optimized for certain power budgets: 10 Watts, 15 Watts, 30 Watts, and so on. For each power budget, there are various configurations possible in terms of resource utilization. </p>\n\n\n\n<p>These power modes are set using <a href=\"https://docs.nvidia.com/jetson/archives/r35.3.1/DeveloperGuide/text/SD/PlatformPowerAndPerformance/JetsonOrinNanoSeriesJetsonOrinNxSeriesAndJetsonAgxOrinSeries.html#nvpmodel-gui\">nvpmodel</a>, and you can choose to use one of the preconfigured modes or create a custom power mode that is tuned to your requirements. The nvpmodel configuration enables a certain number of online GPU TPC, CPU, DLA, and PVA cores, along with certain frequencies, to keep the module within a certain power budget. </p>\n\n\n\n<p>MAXN mode is also available as an unconstrained power mode. It enables the maximum number of cores and clock frequencies for the various processors and engines that can then be tuned to create custom power modes that balance performance and power consumption.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Power, thermal, and electrical management features</h2>\n\n\n\n<p>Jetson provides various power, thermal, and electrical management features: </p>\n\n\n\n<ul>\n<li>Clock gating</li>\n\n\n\n<li>Power gating</li>\n\n\n\n<li>Dynamic voltage frequency scaling</li>\n\n\n\n<li>Deep sleep (SC7) modes</li>\n\n\n\n<li>Idle power modes</li>\n</ul>\n\n\n\n<p>For more information, see <a href=\"https://docs.nvidia.com/jetson/archives/r35.4.1/DeveloperGuide/text/SD/PlatformPowerAndPerformance/JetsonOrinNanoSeriesJetsonOrinNxSeriesAndJetsonAgxOrinSeries.html#supported-modes-and-power-efficiency\">Supported Modes and Power Efficiency</a> in the <em>Jetson Linux Developer Guide</em>. <a href=\"https://docs.nvidia.com/jetson/archives/r35.4.1/DeveloperGuide/text/SD/PlatformPowerAndPerformance/JetsonOrinNanoSeriesJetsonOrinNxSeriesAndJetsonAgxOrinSeries.html#supported-modes-and-power-efficiency\"></a></p>\n\n\n\n<h2 class=\"wp-block-heading\"><a></a>Jetson Power GUI</h2>\n\n\n\n<p>There are many tools that NVIDIA provides with JetPack that can assist you in thermal and power management. One such tool is the Jetson Power GUI, which gets installed as part of the JetPack image.</p>\n\n\n\n<p>The Jetson Power GUI lets you monitor the power and thermal status of the Jetson board. With the <strong>Main</strong> tab, you can track CPU and GPU usage, as well as the device temperature. With real-time monitoring, you can quickly identify any performance bottlenecks or excessive power consumption that may lead to performance throttling.</p>\n\n\n\n<p>With the Jetson Power GUI, you can adjust power modes, which optimize the trade-off between performance and power consumption. You can choose from one of the predefined power modes depending on the Jetson board that you are using.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-launch.png\"><img decoding=\"async\" loading=\"lazy\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-launch.png\" alt=\"Screenshot shows information about GPU/CPU utilization as well as power metrics.\" class=\"wp-image-70174\" width=\"613\" height=\"794\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-launch.png 1226w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-launch-232x300.png 232w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-launch-625x809.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-launch-89x115.png 89w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-launch-768x994.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-launch-1187x1536.png 1187w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-launch-645x835.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-launch-70x90.png 70w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-launch-362x469.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-launch-85x110.png 85w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-launch-1024x1326.png 1024w\" sizes=\"(max-width: 613px) 100vw, 613px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 1. Jetson Power launch page</em></figcaption></figure></div>\n\n\n<p>The Power GUI tool also enables you to record pertinent power-related information to a log file for a specific duration. This is useful for capturing and analyzing behavior during specific tasks or specific time duration. For example, you could capture information about the performance of Jetson within the first 3 minutes of startup.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-example-log-file.png\"><img decoding=\"async\" loading=\"lazy\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-example-log-file.png\" alt=\"Screenshot of example log file shows different CPU load over a period of time.\" class=\"wp-image-70175\" width=\"612\" height=\"545\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-example-log-file.png 1224w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-example-log-file-300x267.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-example-log-file-625x556.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-example-log-file-129x115.png 129w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-example-log-file-768x683.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-example-log-file-645x574.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-example-log-file-337x300.png 337w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-example-log-file-101x90.png 101w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-example-log-file-362x322.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-example-log-file-124x110.png 124w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-example-log-file-1024x911.png 1024w\" sizes=\"(max-width: 612px) 100vw, 612px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 2. Example log file from Power GUI</em></figcaption></figure></div>\n\n\n<p>The <strong>plot graph\u2026</strong> button provides data visualization functionality, so you can plot real-time, power-related information. The captured log file can also be used to plot a graph to help you visualize with even more simplicity how your system is performing.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/graph-plot-channel-selection.png\"><img decoding=\"async\" loading=\"lazy\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/graph-plot-channel-selection.png\" alt=\"Screenshot of power channels for plotting graphs shows how to select different information for capturing in the graph.\" class=\"wp-image-70176\" width=\"611\" height=\"337\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/graph-plot-channel-selection.png 1222w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/graph-plot-channel-selection-300x165.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/graph-plot-channel-selection-625x345.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/graph-plot-channel-selection-179x99.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/graph-plot-channel-selection-768x424.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/graph-plot-channel-selection-645x356.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/graph-plot-channel-selection-500x276.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/graph-plot-channel-selection-160x88.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/graph-plot-channel-selection-362x200.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/graph-plot-channel-selection-199x110.png 199w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/graph-plot-channel-selection-1024x565.png 1024w\" sizes=\"(max-width: 611px) 100vw, 611px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 3. Graph plot channel selection</em></figcaption></figure></div>\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/example-graph-plotted-jetson-power-gui.png\"><img decoding=\"async\" loading=\"lazy\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/example-graph-plotted-jetson-power-gui.png\" alt=\"Screenshot shows graphs for GPU, CPU, SOC, CV, VDDRQ, and SYS5V.\" class=\"wp-image-70177\" width=\"917\" height=\"674\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/example-graph-plotted-jetson-power-gui.png 1223w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/example-graph-plotted-jetson-power-gui-300x221.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/example-graph-plotted-jetson-power-gui-625x459.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/example-graph-plotted-jetson-power-gui-156x115.png 156w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/example-graph-plotted-jetson-power-gui-768x565.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/example-graph-plotted-jetson-power-gui-645x474.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/example-graph-plotted-jetson-power-gui-408x300.png 408w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/example-graph-plotted-jetson-power-gui-122x90.png 122w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/example-graph-plotted-jetson-power-gui-362x266.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/example-graph-plotted-jetson-power-gui-150x110.png 150w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/example-graph-plotted-jetson-power-gui-1024x753.png 1024w\" sizes=\"(max-width: 917px) 100vw, 917px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 4. Example graph plotted from Jetson Power GUI</em></figcaption></figure></div>\n\n\n<h2 class=\"wp-block-heading\"><a></a>Tegrastats</h2>\n\n\n\n<p>Tegrastats is a command line utility provided by NVIDIA that reports memory and processor usage on the Jetson platform. This utility is provided with JetPack and can be found at <code>&lt;top&gt;/core/utils/tegrastats</code><em>.</em></p>\n\n\n\n<p>Tegrastats provides insights into several usage metrics, such as CPU, GPU, and memory. It also gives you the ability to monitor power consumption and provides real-time updates on power usage. These metrics are crucial in understanding how the system is performing.</p>\n\n\n\n<p>Tegrastats also offers information about thermal behavior, such as the operating temperature for the CPU and GPU. This can help you prevent thermal throttling.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><a></a>Usage<strong></strong></h3>\n\n\n\n<p>To use the Tegrastats utility on Jetson, use the following commands.</p>\n\n\n\n<p>In the foreground, run the following command:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\n$ tegrastats \u2014interval &lt;int&gt;\n</pre></div>\n\n\n<p>In this command, <code>&lt;int&gt;</code> is the interval between log prints in milliseconds. By default, Tegrastats updates the statistics every second.</p>\n\n\n\n<p>In the background, run the following command:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\n$ tegrastats \u2014interval &lt;int&gt; -logfile &lt;out_file&gt; &amp;\n</pre></div>\n\n\n<p>In this command, <code>&lt;out_file&gt;</code> is the pathname of the output file to which Tegrastats writes the log prints.&nbsp;</p>\n\n\n\n<p>The following is a sample print of Tegrastats:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\nRAM 1545/31919MB (lfb 7400x4MB) SWAP 0/15959MB (cached 0MB) CPU\n&#91;0%@1190,0%@1190,0%@1190,0%@1190,0%@1190,0%@1190,0%@1190,0%@1190]\nEMC_FREQ 1%@408 GR3D_FREQ 0%@318 VIC_FREQ 0%@115 APE 150 MTS fg 0% bg 0%\nAO@38C GPU@39.5C Tdiode@43.25C PMIC@100C AUX@38.5C CPU@39.5C\nthermal@38.8C Tboard@39C GPU 0/0 CPU 468/468 SOC 937/937 CV 0/0 VDDRQ\n312/234 SYS5V 1458/1458\n</pre></div>\n\n\n<p>Tegrastats can also be integrated into scripts or applications to capture system statistics, which enables more automation scenarios.</p>\n\n\n\n<h2 class=\"wp-block-heading\">JTOP&nbsp;(Jetson-stats)</h2>\n\n\n\n<p>JTOP is a user-friendly way to monitor and control the resources on the Jetson. It can help you visualize and understand various bottlenecks in your applications. For example, it shows whether an application is heavy on memory operations or an application is not using the hardware-accelerated engines in the Jetson module. In this way, JTOP leads to a more efficient and streamlined application optimized for the Jetson module.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-launch.png\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"409\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-launch-625x409.png\" alt=\"Screenshot displays the JTOP screen where you can visualize the current status of your device in terms of power and resource consumption.\" class=\"wp-image-70178\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-launch-625x409.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-launch-300x196.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-launch-176x115.png 176w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-launch-768x503.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-launch-645x422.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-launch-458x300.png 458w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-launch-137x90.png 137w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-launch-362x237.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-launch-168x110.png 168w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-launch-1024x671.png 1024w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-launch.png 1104w\" sizes=\"(max-width: 625px) 100vw, 625px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 5. JTOP launch screen</em></figcaption></figure></div>\n\n\n<p>JTOP is specifically designed for monitoring and managing NVIDIA Jetson modules:</p>\n\n\n\n<ul>\n<li>NVIDIA Orin</li>\n\n\n\n<li>NVIDIA Xavier</li>\n\n\n\n<li>NVIDIA Nano</li>\n\n\n\n<li>NVIDIA TX</li>\n</ul>\n\n\n\n<p>It provides real-time updates about system performance. This enables you to analyze the CPU and GPU usage, operating temperature, memory usage, and other relevant information.</p>\n\n\n\n<p>With JTOP, this information can be accessed in a GUI for better visualization of the information. This way, it provides a convenient way to keep track of the system\u2019s metrics and performance figures, especially when running heavy AI workloads.</p>\n\n\n\n<p>JTOP also brings out the capability to tweak the system\u2019s performance. You can select the power mode in which they want their Jetson devices to be running, as well as control over the fan speed. This helps in optimizing system performance and thermals.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-memory-monitor.png\"><img decoding=\"async\" loading=\"lazy\" width=\"848\" height=\"686\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-memory-monitor.png\" alt=\"Screenshot shows memory monitor tab from the JTOP GUI that gives details about memory usage from the Jetson system.\" class=\"wp-image-70179\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-memory-monitor.png 848w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-memory-monitor-300x243.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-memory-monitor-625x506.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-memory-monitor-142x115.png 142w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-memory-monitor-768x621.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-memory-monitor-645x522.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-memory-monitor-371x300.png 371w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-memory-monitor-111x90.png 111w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-memory-monitor-362x293.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jtop-memory-monitor-136x110.png 136w\" sizes=\"(max-width: 848px) 100vw, 848px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 6. JTOP memory monitor</em></figcaption></figure></div>\n\n\n<p>JTOP is especially useful for building a system on a power budget but still squeezing out the maximum performance possible. To install it, use <code>pip</code>:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\n$ sudo apt update \n$ sudo apt-get install python3-pip\n$ sudo pip install -u jetson-stats\n</pre></div>\n\n\n<p>Use the <code>jtop</code> command:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\n$ jtop\n</pre></div>\n\n\n<p>The JTOP tool is also available as a Python library with APIs that enable you to include JTOP functions in your scripts with ease.</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\nfrom jtop import jtop\n\nwith jtop() as jetson:\n\twhile jetson.ok():\n\t\t#read jetson stats\n\t\tprint(jetson.stats)\n</pre></div>\n\n\n<p>For more information, see the following video from JetsonHacks.</p>\n\n\n\n<figure class=\"wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<span class=\"embed-youtube\" style=\"text-align:center; display: block;\"><iframe loading=\"lazy\" class=\"youtube-player\" width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/2cc6Irm0WuA?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent\" allowfullscreen=\"true\" style=\"border:0;\" sandbox=\"allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox\"></iframe></span>\n</div><figcaption class=\"wp-element-caption\"><em>Video 1. JTOP: The Tool Jetson Pros Use. Do You?</em></figcaption></figure>\n\n\n\n<h2 class=\"wp-block-heading\">Get started with optimizing your power today</h2>\n\n\n\n<p>The <a href=\"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/\">NVIDIA Jetson platform</a> is continuously advancing the edge inference performance for robotics and edge AI. It is an important factor in most edge AI applications to follow a power budget. With the NVIDIA tools, you can monitor system performance and model a custom power profile.</p>\n\n\n\n<p>For more information, see the following resources:</p>\n\n\n\n<ul>\n<li><a href=\"https://docs.nvidia.com/jetson/archives/r35.4.1/DeveloperGuide/text/SD/PlatformPowerAndPerformance/JetsonOrinNanoSeriesJetsonOrinNxSeriesAndJetsonAgxOrinSeries.html&quot; \\l &quot;supported-modes-and-power-efficiency\">Supported Modes and Power Efficiency</a></li>\n\n\n\n<li><a href=\"https://rnext.it/jetson_stats/\">JTOP (jetson-stats) User Guide</a></li>\n\n\n\n<li><a href=\"https://rnext.it/jetson_stats/troubleshooting.html\">Troubleshooting</a> (Jetson_stats)</li>\n\n\n\n<li><a href=\"https://github.com/rbonghi/ros_jetson_stats\">/rbonghi/ros_jetson_stats</a> GitHub repo</li>\n\n\n\n<li><a href=\"https://github.com/NVIDIA-AI-IOT/ros2_jetson_stats\">/NVIDIA-AI-IOT/ros2_jetson_stats</a> GitHub repo</li>\n</ul>\n\n\n\n<p>With all the tools mentioned in this post, you can easily create a power-efficient and performance-optimized system for your application.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>When working with embedded systems such as the Jetson modules, you must optimize your application based on your power budget and compute resources. To avoid performance or even thermal throttling issues, monitoring these resources becomes really important. Jetson modules are designed with a GPU, CPU, and various AI accelerators. They also feature a high-efficiency power &hellip; <a href=\"https://developer.nvidia.com/blog/power-optimization-with-nvidia-jetson/\">Continued</a></p>\n", "protected": false}, "author": 1865, "featured_media": 70182, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1272838", "discourse_permalink": "https://forums.developer.nvidia.com/t/power-optimization-with-nvidia-jetson/268557", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [63], "tags": [1932, 453], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/08/jetson-power-featured.png", "jetpack_shortlink": "https://wp.me/pcCQAL-ifJ", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70167"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1865"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=70167"}], "version-history": [{"count": 8, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70167/revisions"}], "predecessor-version": [{"id": 71469, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70167/revisions/71469"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/70182"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=70167"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=70167"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=70167"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 71113, "date": "2023-10-04T11:00:00", "date_gmt": "2023-10-04T18:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=71113"}, "modified": "2023-11-02T11:14:45", "modified_gmt": "2023-11-02T18:14:45", "slug": "analyzing-the-security-of-machine-learning-research-code", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/analyzing-the-security-of-machine-learning-research-code/", "title": {"rendered": "Analyzing the Security of Machine Learning Research Code"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>The <a href=\"https://developer.nvidia.com/blog/nvidia-ai-red-team-an-introduction/\">NVIDIA AI Red Team</a> is focused on scaling secure development practices across the data, science, and AI ecosystems. We participate in <a href=\"https://github.com/jupyter/security\">open-source security initiatives</a>, release <a href=\"https://developer.nvidia.com/blog/evaluating-the-security-of-jupyter-environments/\">tools</a>, present at <a href=\"https://www.blackhat.com/us-23/briefings/schedule/#poisoning-web-scale-training-datasets-is-practical-32112\">industry conferences</a>, host <a href=\"https://developer.nvidia.com/blog/improving-machine-learning-security-skills-at-a-def-con-competition/\">educational competitions</a>, and provide <a href=\"https://www.blackhat.com/us-23/training/schedule/#blackhat-machine-learning-30696\">innovative training</a>.</p>\n\n\n\n<p>Covering 3 years and totaling almost 140GB of source code, the recently released <a href=\"https://www.kaggle.com/discussions/product-feedback/430422\">Meta Kaggle for Code</a> dataset is a great opportunity to analyze the security of machine learning (ML) research and experimentation competition code at scale. Our goal was to use this data to answer the following questions:&nbsp;</p>\n\n\n\n<ol>\n<li>What is the state of security hygiene in ML research code?</li>\n\n\n\n<li>How can security organizations improve the secure coding practices of ML researchers?</li>\n</ol>\n\n\n\n<p>Our analysis shows that ML researchers continue to use insecure coding practices despite public documentation about security risks and relatively frictionless and advanced security tooling. We theorize that researchers prioritize rapid experimentation and do not think of themselves or their projects as targets because they are usually not running production services.&nbsp;</p>\n\n\n\n<p>Additionally, the Kaggle environment may exacerbate security negligence based on \u200cisolation from researchers\u2019 \u201creal infrastructure.\u201d However, researchers must acknowledge their position in the software supply chain and should be aware of risks to their research and systems from insecure coding practices.</p>\n\n\n\n<p>Although originally proposed in the 2015 research paper <a href=\"https://arxiv.org/abs/1412.6572\">Explaining and Harnessing Adversarial Examples</a>, we also found little evidence of adoption of adversarial training or assessment in ML research pipelines. This may be partly due to the structure of Kaggle competitions and scoring metrics, but it is consistent with our other research and observations. However, with recent advances in multimodal models and demonstrated image-based prompt injection attacks, researchers should prioritize testing their models under adversarial conditions and perturbations.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Observations</h2>\n\n\n\n<p>The most significant observations were the use of plaintext credentials, insecure deserialization (primarily pickle), a lack of adversarial robustness and evaluation techniques, and typos. Focus defensive controls and education around these topics.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Plaintext credentials</h3>\n\n\n\n<p>Researchers still use long-lived, plaintext credentials and commit them to source control. We found over 140 unique active, plaintext credentials to third-party services like OpenAI, AWS, GitHub, and others. For some credential types, the credentials can be associated with other user data such as emails, exposing the user to phishing and other attacks.&nbsp;</p>\n\n\n\n<p>In keeping with standard industry practices around Coordinated Vulnerability Disclosure, we reported this credential exposure to Kaggle on August 24, 2023. They have taken steps to mitigate this risk.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Insecure deserialization</h3>\n\n\n\n<p>The most prevalent risk is insecure deserialization. Furthermore, many notebooks included path traversal iteration that increased the likelihood of a malicious payload being executed.&nbsp;</p>\n\n\n\n<p>For example, a user iterated through <code>feature_dir</code> and <code>fileName</code> to repeatedly execute the following command: <code>feature = np.load(feature_dir + fileName + '.npy', allow_pickle=True)</code>.&nbsp;</p>\n\n\n\n<p>The majority of the XML Injection findings were generated from pandas <code>read html</code> calls that can be vulnerable to XML external entity attacks and most of the mishandled sensitive information findings were related to <code>http</code> usage instead of <code>https</code>.&nbsp;</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"916\" height=\"629\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/aggregated-findings-by-category-bar-graph.png\" alt=\"A horizontal bar graph with a logarithmic scale showing findings by category.\" class=\"wp-image-71120\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/aggregated-findings-by-category-bar-graph.png 916w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/aggregated-findings-by-category-bar-graph-300x206.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/aggregated-findings-by-category-bar-graph-625x429.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/aggregated-findings-by-category-bar-graph-167x115.png 167w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/aggregated-findings-by-category-bar-graph-768x527.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/aggregated-findings-by-category-bar-graph-645x443.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/aggregated-findings-by-category-bar-graph-437x300.png 437w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/aggregated-findings-by-category-bar-graph-131x90.png 131w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/aggregated-findings-by-category-bar-graph-362x249.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/aggregated-findings-by-category-bar-graph-160x110.png 160w\" sizes=\"(max-width: 916px) 100vw, 916px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. Aggregated findings by category</em></figcaption></figure></div>\n\n\n<h3 class=\"wp-block-heading\">Pickle is still the standard</h3>\n\n\n\n<p>The de facto serialization format for researchers is still the <a href=\"https://docs.python.org/3/library/pickle.html\">pickle</a> module. It was among the top 50 most imported modules with almost 5,000 imports. <a href=\"https://onnx.ai/\">ONNX</a>, a more secure serialization format for ML models, was directly imported just nine times. The pickle module may also have been used indirectly through built-in serialization formats in other libraries.&nbsp;</p>\n\n\n\n<p>For instance, many <a href=\"https://numpy.org/\">NumPy</a> or <a href=\"https://pytorch.org/\">PyTorch</a> serialization calls rely on built-in save methods that are still pickle-based. For example, we identified over 45,000 examples where pickle files were loaded as part of <a href=\"https://pandas.pydata.org/docs/index.html\">pandas</a>, <a href=\"https://joblib.readthedocs.io/en/stable/\">joblib</a>, and NumPy deserialization.&nbsp;</p>\n\n\n\n<h3 class=\"wp-block-heading\">Lack of adversarial retraining or testing</h3>\n\n\n\n<p>There is no evidence of adversarial retraining or testing. Common adversarial retraining and testing libraries like <a href=\"https://github.com/Trusted-AI/adversarial-robustness-toolbox\">Adversarial RobustnessToolbox (ART)</a>, <a href=\"https://github.com/Azure/counterfit\">Counterfit</a>, <a href=\"https://github.com/QData/TextAttack\">TextAttack</a>, and <a href=\"https://github.com/cleverhans-lab/cleverhans\">CleverHans</a> do not appear in any of the imports. For common explainability tools, there were no imports for <a href=\"https://github.com/SeldonIO/alibi\">Alibi</a>, but <a href=\"https://github.com/fairlearn/fairlearn\">Fairlearn</a> was imported 34 times.&nbsp;</p>\n\n\n\n<p>Other training techniques to protect privacy, such as federated learning and differential privacy, were almost entirely absent too (with the exception of <a href=\"https://github.com/OpenMined/PyDP\">PyDP</a>, which was imported once).</p>\n\n\n\n<h3 class=\"wp-block-heading\">Typos</h3>\n\n\n\n<p>We observed typos such as imports for <code>panda</code> and <code>mathplotlib</code> (which should have been <code>pandas</code> and <code>matplotlib</code>, respectively), among others. Typosquatting on PyPI is a notorious mechanism for spreading malware. For more details, see <a href=\"https://blog.phylum.io/a-pypi-typosquatting-campaign-post-mortem/\">A PyPI Typosquatting Campaign Post-Mortem</a>.</p>\n\n\n\n<h3 class=\"wp-block-heading\">A few positives</h3>\n\n\n\n<p>We did not identify any instances where researchers loaded serialized objects or models from sources that would be easy to hijack or modify in transit. Additionally, no URLs found in the dataset were associated with malware or social engineering according to the <a href=\"https://developers.google.com/safe-browsing/v4/lookup-api\">Google Safe Browsing Lookup API</a>.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Recommendations</h2>\n\n\n\n<p>Particularly with research, security controls must be layered and calibrated to minimally impact velocity. Understand what controls are necessary to protect the researcher, research, and network, and what additional controls may be necessary to transition successful research to production. Our recommendations, listed below, are based on the preceding observations.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Develop alternatives to entering long-lived credentials in source code</h3>\n\n\n\n<p>Alternatives include using a <a href=\"https://www.kaggle.com/discussions/product-feedback/114053\">secrets manager</a>, environment variables, input prompts, and credential vending services that provide short-lived tokens. Multifactor authentication (MFA) also reduces the impact of credentials leaked in source code.&nbsp;</p>\n\n\n\n<p>Experience shows repeatedly that if developers start using credentials in source code, the chance of a leak significantly increases. Leaks can happen in datasets like this, accidental commits into version control, or exposure through history and logging as illustrated by our <a href=\"https://youtu.be/EujDolCutI8?feature=shared&amp;t=661\">demonstration at JupyterCon 2023</a>.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Use automation to catch mistakes before they are committed to remote resources</h3>\n\n\n\n<p>Version control systems like GitHub and continuous deployment systems like Jenkins have often been \u201ccrown jewels\u201d for attackers. Use <a href=\"https://docs.trufflesecurity.com/docs/scanning-git/precommit-hooks/\">precommit hooks</a> to run security automation and prevent local mistakes from being broadcast to these targets.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Establish guidelines, standards, and toolings to limit deserialization exploitation risks&nbsp;</h3>\n\n\n\n<p>The <a href=\"https://www.youtube.com/watch?v=lECEXFtVjig\">security risks of pickle</a> are well documented, but still do require a malicious actor to have sufficient access and privileges to execute an attack. Our team recommends that organizations move towards more robust serialization formats like ONNX and protocol buffers. If your tool or organization must support pickle, implement integrity verification steps that can be validated without deserialization.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Identify and mitigate potential adversarial ML attacks</h3>\n\n\n\n<p>Vulnerabilities and exploits during research and development can impact the security and effectiveness of the resulting service. Understand the various attacks against ML systems to build appropriate threat models and defensive controls. To learn more, see <a href=\"https://developer.nvidia.com/blog/nvidia-ai-red-team-an-introduction/\">NVIDIA AI Red Team: An Introduction</a>.</p>\n\n\n\n<p>For instance, including adversarial retraining during training time can ensure your classifier is more robust to adversarial evasion attacks. Consider adding an <a href=\"https://github.com/Trusted-AI/adversarial-robustness-toolbox/wiki/ART-Metrics\">adversarial robustness metric</a> to your evaluation framework when comparing model performance. If you are sponsoring a Kaggle competition, consider adding adversarial examples to the evaluation dataset so you are rewarding the most robust solution.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Consider the lifespan and isolation of your development environments&nbsp;</h3>\n\n\n\n<p>All analyzed user code ran on the Kaggle platform\u2019s ephemeral environments, isolated from developer host machines. However, your organization may not have the same level of tenant isolation. It is important to not unnecessarily hinder the velocity of researchers, but consider the potential impact and blast-radius of a simple mistake (such as a misspelled import statement) and work to ensure <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg/domain-resource-isolation.html\">domain resource isolation</a> and network segmentation where possible.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Use allow/block lists and internal artifact repositories for artifacts like imports and datasets&nbsp;</h3>\n\n\n\n<p>Acknowledging the potential impact to research velocity, consider maintaining <a href=\"https://packaging.python.org/en/latest/guides/hosting-your-own-index/\">internal repositories</a> of \u201cknown good\u201d libraries and datasets or implement an <a href=\"https://youtu.be/ziC_DlabFto?feature=shared\">import hooking</a> scheme to reduce the risk of malicious package installs and imports. Similar hygiene for datasets improves security, reproducibility, and auditability.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Methodology</h2>\n\n\n\n<p>The dataset contains about 140GB of R, Python, and Jupyter Notebook source code publicly hosted on Kaggle. Kaggle allows users to save versions, so many of these artifacts are simply updates and changes to other files. Our analysis is limited to the Python files and Jupyter Notebooks\u2014around 3.5 million files that were executed on Kaggle from April 2020 to August 2023.</p>\n\n\n\n<p>Some analysis was manual, but we also relied heavily on two existing open-source security tools, <a href=\"https://github.com/trufflesecurity/trufflehog\">TruffleHog</a> to identify credentials and <a href=\"https://semgrep.dev/\">Semgrep</a> to perform static analysis. Use these tools to repeat our analysis and consider them for inclusion in your kit of security tools.</p>\n\n\n\n<p>To identify and validate credentials, TruffleHog can be run in a Docker container against source code repositories or local files. For this analysis, we ran TruffleHog against a local download with <code>docker run --rm -it -v \"kaggle:/pwd\" trufflesecurity/trufflehog:latest filesystem /pwd --json --only-verified &gt; trufflehog_findings.json</code>.&nbsp;</p>\n\n\n\n<p>TruffleHog also supports precommit hooks to help ensure credentials are not committed to remote repositories and CI/CD integration to continually monitor for leakage. TruffleHog was able to run against the Kaggle dataset without modification and we deduplicated findings based on unique secret values.</p>\n\n\n\n<p>Semgrep is a static code analyzer that uses rules to identify potential weaknesses in the target source code. Since Semgrep does not natively support Jupyter notebooks, we used <a href=\"https://nbconvert.readthedocs.io/en/latest/\"><code>nbconvert</code></a> to convert them to Python files before Semgrep processing. We used 162 rules from the default <a href=\"https://semgrep.dev/p/python\">Python rules</a> and <a href=\"https://github.com/trailofbits/semgrep-rules\">rules maintained by Trail of Bits</a> that are more focused on ML applications.&nbsp;</p>\n\n\n\n<p>After installing Semgrep, run these two rulesets against your local Kaggle download with <code>semgrep --config \"p/trailofbits\" --config \"p/python\" --json kaggle/ -o semgrep_findings.json</code>. During analysis, we filtered out the Trail of Bits <a href=\"https://github.com/trailofbits/semgrep-rules/blob/main/python/automatic-memory-pinning.yaml\">automatic memory pinning rule</a> because we could not find a direct path or evidence of previous exploitation.</p>\n\n\n\n<p>The NVIDIA AI Red Team wrapped these tools in a meta-tool called <a href=\"https://github.com/JosephTLucas/lintML\">lintML</a>. To reproduce our results, try it with <code>lintML \u2013semgrep-options \u201c--config \u2018p/python\u2019 \u2013config \u2018p/trailofbits\u2019\u201d &lt;directory&gt;</code>.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Limitations</h2>\n\n\n\n<p>While we are proud of the volume of this analysis, it is still \u201csingle source\u201d in that all samples were collected through Kaggle. It is likely that, while many findings may be the same, the underlying distribution of security observations from other data sources would be different.</p>\n\n\n\n<p>For example, a similar analysis performed on GitHub artifacts may skew towards \u201cmore secure\u201d as those repositories are more likely to contain productionized code.&nbsp;</p>\n\n\n\n<p>Furthermore, <a href=\"https://www.kaggle.com/competitions\">Kaggle competitions</a> reward rapid iteration and accuracy, which potentially lead to different library imports, techniques, and security considerations that productionized research. For instance, Kaggle competitions usually provide the necessary data. In reality, sourcing, cleaning, and labeling data are often significant design decisions and <a href=\"https://arxiv.org/abs/2302.10149\">sources of potential vulnerabilities</a>.</p>\n\n\n\n<p>This analysis was simultaneously enabled and limited by the tools we used. If a credential or validator did not exist in TruffleHog, there is no associated finding here. Likewise, Semgrep analysis was limited by the rulesets we chose. Only a subset of these findings are likely exploitable, but the quantity may be correlated with overall project risk.&nbsp;</p>\n\n\n\n<p>Further, the finding quantity analysis may have been biased by the distribution of rules (more deserialization rules yielding more findings). Security researchers should continue contributing to established tools for findings related to machine learning security (as the NVIDIA AI Red Team has done for both <a href=\"https://github.com/trufflesecurity/trufflehog/pull/797\">TruffleHog</a> and <a href=\"https://github.com/trailofbits/semgrep-rules/pull/24\">Semgrep</a> rules). The NVIDIA AI Red Team is particularly interested in applications of data flow and taint analysis to machine learning applications.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Conclusion</h2>\n\n\n\n<p>Kaggle is a place for experimentation, research, and competition. It rewards rapid experiment iteration and performance, so these code artifacts are not representative of production services.&nbsp;</p>\n\n\n\n<p>Or are they? Code is often reused, habits are formed during research, and defaults are sticky. In a similar analysis of over 300 highly ranked machine learning repositories on GitHub, we still found hardcoded credentials to third-party services and the full range of findings presented here. Increasing security awareness and informative and preventative controls during research helps ensure secure products and increases the professionalism and security posture of your enterprise.</p>\n\n\n\n<p>Security professionals should use this analysis as a foundation for analyzing research and development practices in their organizations. Most of these findings represent baseline security controls. If you start to find them in your organization\u2019s research code, they are signals to engage more thoroughly with research and development teams.&nbsp;</p>\n\n\n\n<p>Use similar techniques to evaluate artifacts across your machine learning development cycle to ensure relaxed research practices are not propagating risk into production products. Identify opportunities to provide low-friction tooling early, not just in production delivery pipelines. Leverage proactive adversarial assessments and exercises to increase education, awareness, and reasonable security controls.</p>\n\n\n\n<p>Researchers should focus on establishing and maintaining good security hygiene as part of scientific integrity. Security risks should be viewed as unwanted variables that should be mitigated to ensure the veracity of the experiments. Think about the provenance of data and code that you are pulling into your organization. Engage with your security teams for guidance on best-practices and environment hardening.&nbsp;</p>\n\n\n\n<p>Just as you would when rigorously testing a hypothesis, be critical when testing your project and identify opportunities where accuracy may not be the sole metric you want to optimize and consider including robustness, explainability, and fairness tests. Even if you aren&#8217;t writing a production service, you may still be\u200c exposing yourself, your research, and your organization to potential risk.</p>\n\n\n\n<p>Use our <a href=\"https://www.kaggle.com/code/lucasjt/security-practices\">Security Practices notebook</a> to begin analyzing this data yourself, or download a local copy of the <a href=\"https://www.kaggle.com/datasets/kaggle/meta-kaggle-code\">Meta Kaggle Code</a> to evaluate with TruffleHog and Semgrep. Experiment with <a href=\"https://github.com/JosephTLucas/lintML\">lintML</a> to identify risks in your ML training code.&nbsp;</p>\n\n\n\n<p>To learn more about ML security, check out <a href=\"https://www.blackhat.com/eu-23/training/schedule/index.html#black-hat-machine-learning-33946\">Black Hat Machine Learning</a> at Black Hat Europe 2023.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Acknowledgments</h3>\n\n\n\n<p><em>We would like to thank Kaggle for making this dataset available. This kind of data can help elevate security awareness and baseline the industry. The NVIDIA AI Red Team is constantly trying to meet ML practitioners where they are, and Kaggle has been a great partner and enabler for that mission. For more details, see </em><a href=\"https://developer.nvidia.com/blog/improving-machine-learning-security-skills-at-a-def-con-competition/\">Improving Machine Learning Security Skills at a DEF CON Competition</a><em>. We would also like to thank all of the Kaggle competitors for contributing code to the dataset.\u00a0</em></p>\n\n\n\n<p><em>Additionally, we would like to thank TruffleHog, Semgrep, and Trail of Bits for open sourcing security tools that enabled this research and Jupyter, pandas, NumPy, and Matplotlib for high-quality data analysis and visualization tools.</em></p>\n", "protected": false}, "excerpt": {"rendered": "<p>The NVIDIA AI Red Team is focused on scaling secure development practices across the data, science, and AI ecosystems. We participate in open-source security initiatives, release tools, present at industry conferences, host educational competitions, and provide innovative training. Covering 3 years and totaling almost 140GB of source code, the recently released Meta Kaggle for Code &hellip; <a href=\"https://developer.nvidia.com/blog/analyzing-the-security-of-machine-learning-research-code/\">Continued</a></p>\n", "protected": false}, "author": 1587, "featured_media": 71134, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1272168", "discourse_permalink": "https://forums.developer.nvidia.com/t/analyzing-the-security-of-machine-learning-research-code/268445", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [1464, 696], "tags": [1511, 453, 813, 1953, 1731, 369, 1877, 2377], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/man-with-laptop.png", "jetpack_shortlink": "https://wp.me/pcCQAL-iuZ", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71113"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1587"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=71113"}], "version-history": [{"count": 36, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71113/revisions"}], "predecessor-version": [{"id": 71438, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71113/revisions/71438"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/71134"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=71113"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=71113"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=71113"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 71382, "date": "2023-10-03T09:00:00", "date_gmt": "2023-10-03T16:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=71382"}, "modified": "2023-11-02T11:14:46", "modified_gmt": "2023-11-02T18:14:46", "slug": "event-nvidia-computer-vision-speaker-series", "status": "publish", "type": "post", "link": "https://nvda.ws/3F2IrsY", "title": {"rendered": "Event: NVIDIA Computer Vision Speaker Series"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>Discover how PepsiCo, Runway, SoftServe, and AWS used GPU-accelerated SDKs for their CV applications.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Discover how PepsiCo, Runway, SoftServe, and AWS used GPU-accelerated SDKs for their CV applications.</p>\n", "protected": false}, "author": 1466, "featured_media": 71384, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "", "discourse_permalink": "", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "https://nvda.ws/3F2IrsY", "_links_to_target": "_blank"}, "categories": [2724, 2758, 63], "tags": [3312, 452, 453, 90, 1472, 1958, 2056], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/computer-vision-speaker-series-graphic.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-izk", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71382"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1466"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=71382"}], "version-history": [{"count": 13, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71382/revisions"}], "predecessor-version": [{"id": 71396, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71382/revisions/71396"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/71384"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=71382"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=71382"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=71382"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 71241, "date": "2023-10-02T12:01:48", "date_gmt": "2023-10-02T19:01:48", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=71241"}, "modified": "2023-10-19T12:05:56", "modified_gmt": "2023-10-19T19:05:56", "slug": "ai-powered-simulation-tools-for-surrogate-modeling-engineering-workflows-with-siml-ai-and-nvidia-modulus", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/ai-powered-simulation-tools-for-surrogate-modeling-engineering-workflows-with-siml-ai-and-nvidia-modulus/", "title": {"rendered": "AI-Powered Simulation Tools for Surrogate Modeling Engineering Workflows with Siml.ai and NVIDIA Modulus"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>Simulations are quintessential for complex engineering challenges, like designing nuclear fusion reactors, <a rel=\"noreferrer noopener\" href=\"https://blogs.nvidia.com/blog/2022/03/22/siemens-gamesa-wind-farms-digital-twins/\" target=\"_blank\">optimizing wind farms</a>, developing <a rel=\"noreferrer noopener\" href=\"https://developer.nvidia.com/blog/using-carbon-capture-and-storage-digital-twins-for-net-zero-strategies/\" target=\"_blank\">carbon capture and storage techniques</a>, or building hydrogen batteries. Designing such systems often requires many iterations of scientific simulations that are computationally expensive to run. Solvers and parameters must often be tuned individually to each system studied. Thanks to AI and physics-informed machine learning (physics-ML) frameworks such as <a rel=\"noreferrer noopener\" href=\"https://developer.nvidia.com/modulus\" target=\"_blank\">NVIDIA Modulus</a>, it is now possible to overcome these challenges and turbocharge these simulations.</p>\n\n\n\n<p>NVIDIA Modulus is a state-of-the-art <a href=\"https://developer.nvidia.com/blog/physics-ml-platform-modulus-is-now-open-source/\" target=\"_blank\" rel=\"noreferrer noopener\">open-source physics-ML platform</a> that blends physics with deep learning training data to build high-fidelity, parameterized surrogate models with near-real-time latency. Engineers and scientists can explore and build physics-based AI surrogate models using NVIDIA Modulus. These principles are being applied across a wide range of solutions, from manufacturing to healthcare, including <a href=\"https://www.nvidia.com/en-us/glossary/high-performance-computing/\" target=\"_blank\" rel=\"noreferrer noopener\">high-performance computing</a> (HPC) scale applications like <a href=\"https://resources.nvidia.com/en-us-energy-efficiency/weather-prediction\" target=\"_blank\" rel=\"noreferrer noopener\">weather forecasting</a> and industrial <a href=\"https://blogs.nvidia.com/blog/2021/12/14/what-is-a-digital-twin/\" target=\"_blank\" rel=\"noreferrer noopener\">digital twins</a>.</p>\n\n\n\n<p><a href=\"https://www.dimensionlab.org/\" target=\"_blank\" rel=\"noreferrer noopener\">DimensionLab</a>, an <a href=\"https://www.nvidia.com/en-us/startups/\">NVIDIA Inception</a> partner, is a software studio building next-generation tools for engineers, scientists, makers, and creators. With an increased focus on user experience, simplicity, and modern design, the DimensionLab team is leveraging recent advancements in scientific machine learning to revolutionize how numerical simulation can be used for technology and product development.&nbsp;</p>\n\n\n\n<p>Recognizing the significant potential of NVIDIA Modulus, DimensionLab used it as a backbone of their flagship product, a web platform for AI-driven engineering called <a rel=\"noreferrer noopener\" href=\"http://siml.ai/\" target=\"_blank\">Siml.ai</a>.&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\">Simplifying AI surrogate modeling for domain experts</h2>\n\n\n\n<p>Siml.ai provides powerful no-code abstractions within its <a href=\"https://docs.siml.ai/model-engineer/introduction\" target=\"_blank\" rel=\"noreferrer noopener\">Model Engineer application</a>, which enables engineers to express their domain expertise more natively rather than having to become proficient in AI. The application builds on the Modulus interface. This enables domain experts to express their knowledge of the system using governing partial differential equations in symbolic form, for example, rather than in terms of how the loss function of a deep learning model captures such information.</p>\n\n\n\n<p>The goal of Model Engineer is to simplify and streamline the entire process, including:</p>\n\n\n\n<ul>\n<li>Constructing large datasets from traditional simulation exports or physical sensors that collect precise measurements from real-world experiments.</li>\n\n\n\n<li>Constructing the correct model architecture for the simulators\u2019 desired capabilities and constraints.&nbsp;</li>\n\n\n\n<li>Training and aggressively optimizing the learnable simulators in high-performance, GPU-powered cloud or HPC centers without the need to deal with the complexities of managing the cloud infrastructure.</li>\n</ul>\n\n\n\n<p>A flowchart-style visual editor in Model Engineer sets up the problem to launch training on the Modulus platform. Under the hood, the visual representation of the flowchart diagram is compiled into NVIDIA Modulus API calls. It represents the entire simulator state, with parameterized variables, neural network architectures, geometries, or constraints.&nbsp;</p>\n\n\n\n<p>You can drag-and-drop CAD geometries into the geometry node where they are automatically converted into STLs for the NVIDIA Modulus tessellation module. They are simultaneously converted into a fast web format for a 3D geometry viewer.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"1999\" height=\"1179\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-model-engineer-flowchart.png\" alt=\"Screenshot of Siml.ai Model Engineer showing how to use the flowchart-style visual editor to specify the problem with no need for explicit coding.\n\" class=\"wp-image-71255\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-model-engineer-flowchart.png 1999w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-model-engineer-flowchart-300x177.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-model-engineer-flowchart-625x369.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-model-engineer-flowchart-179x106.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-model-engineer-flowchart-768x453.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-model-engineer-flowchart-1536x906.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-model-engineer-flowchart-645x380.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-model-engineer-flowchart-500x295.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-model-engineer-flowchart-153x90.png 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-model-engineer-flowchart-362x214.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-model-engineer-flowchart-187x110.png 187w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-model-engineer-flowchart-1024x604.png 1024w\" sizes=\"(max-width: 1999px) 100vw, 1999px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. Siml.ai Model Engineer provides a flowchart-style visual editor for rapid simulator prototyping</em></figcaption></figure>\n\n\n\n<p>These Siml.ai interactive and visual tools free engineers and scientists to focus on exploring physics-ML models for simulating physics, without dealing with its complexities. They can start training their simulation models in just a few clicks by creating and deploying an Environment through the platform. The Environment uses a Simulator Inference and Training Environment (SITE): a containerized solution that does all the heavy lifting to compile a visual representation of the simulator into code for a trainable Modulus simulator. SITE is optimized for NVIDIA GPUs and offers everything needed for working with AI-driven simulators.</p>\n\n\n\n<p>The second part of the Siml.ai platform is a tool for real-time visualization of the simulation results, called Simulation Studio. It is a hybrid application (web-based and native), based on Unreal Engine and its pixel streaming capabilities. It runs the rendering in the cloud and sends rendered frames as a video stream to the Siml.ai frontend.&nbsp;</p>\n\n\n\n<p>Users can load parameterized simulators created in Model Engineer into the Simulation Studio to create interactive digital twins for fast virtual physics experimentation workflows.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"1999\" height=\"1076\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-simulation-studio-interface.png\" alt=\"Screenshot of the interface of the Simulation Studio application that enables engineers to interact with the Modulus trained model and visualize using Unreal Engine.\n\" class=\"wp-image-71258\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-simulation-studio-interface.png 1999w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-simulation-studio-interface-300x161.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-simulation-studio-interface-625x336.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-simulation-studio-interface-179x96.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-simulation-studio-interface-768x413.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-simulation-studio-interface-1536x827.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-simulation-studio-interface-645x347.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-simulation-studio-interface-500x269.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-simulation-studio-interface-160x86.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-simulation-studio-interface-362x195.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-simulation-studio-interface-204x110.png 204w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simlai-simulation-studio-interface-1024x551.png 1024w\" sizes=\"(max-width: 1999px) 100vw, 1999px\" /><figcaption class=\"wp-element-caption\"><em>Figure 2. Simulation Studio in Siml.ai encapsulates the parameterized surrogate AI model to provide interactive simulation exploration using Unreal Engine</em></figcaption></figure>\n\n\n\n<h2 class=\"wp-block-heading\">Physics-ML surrogate models save cost and time</h2>\n\n\n\n<p>To demonstrate the impact of these new tools and workflows in leveraging physics-ML, developers at DimensionLab used Siml.ai for a specific customer case study. The objective was to quantify the value of frameworks like NVIDIA Modulus and Siml.ai in building physics-ML models for a small consulting company with limited budget. The goal was to deliver an AI solution on par with the output of an industry standard simulation software, but with a fraction of the cost and time.</p>\n\n\n\n<p>The customer needed numerical simulations of a river flow into a hydropower plant to analyze the flood damage from past events. It took them 4 years to finalize and fine-tune the mathematical model in a popular numerical solver, and they spent months on complex geometry meshing.</p>\n\n\n\n<p>In contrast to classical modeling and simulation approaches, developers at DimensionLab helped the customer to apply physics-ML approaches to this engineering challenge. They created multiple comparable AI-driven simulations in Siml.ai that leverage Navier-Stokes equations, physics-informed neural networks, and Fourier neural operators from the NVIDIA Modulus framework.</p>\n\n\n\n<p>These models took just 3 weeks to develop and train multiple times with various configurations and parameterizations. They resulted in 96% cost and time savings compared to the previous approaches tried by the company.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Simulation for engineering resources</h2>\n\n\n\n<p>To learn more, see the <a href=\"https://docs.siml.ai/\" target=\"_blank\" rel=\"noreferrer noopener\">Siml.ai documentation</a> and <a href=\"https://www.siml.ai/university\" target=\"_blank\" rel=\"noreferrer noopener\">Siml.ai training content</a>. You can also read more about the tools in the <a href=\"https://www.siml.ai/blog\" target=\"_blank\" rel=\"noreferrer noopener\">Siml.ai blog</a>.</p>\n\n\n\n<p>To learn more about physics-ML and NVIDIA Modulus, check out the NVIDIA Deep Learning Institute course, <a href=\"https://courses.nvidia.com/courses/course-v1:DLI+S-OV-04+V1/\" target=\"_blank\" rel=\"noreferrer noopener\">Introduction to Physics-Informed Machine Learning with Modulus</a> and visit the <a href=\"https://github.com/NVIDIA/modulus\" target=\"_blank\" rel=\"noreferrer noopener\">NVIDIA/modulus</a> repo on GitHub.</p>\n\n\n\n<p>Learn more about <a href=\"https://www.nvidia.com/en-gb/startups/\" target=\"_blank\" rel=\"noreferrer noopener\">NVIDIA Inception</a>, designed to help startups evolve faster through cutting-edge technology, gain opportunities to connect with venture capitalists, and access to the latest technical resources from NVIDIA.&nbsp;</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Simulations are quintessential for complex engineering challenges, like designing nuclear fusion reactors, optimizing wind farms, developing carbon capture and storage techniques, or building hydrogen batteries. Designing such systems often requires many iterations of scientific simulations that are computationally expensive to run. Solvers and parameters must often be tuned individually to each system studied. Thanks to &hellip; <a href=\"https://developer.nvidia.com/blog/ai-powered-simulation-tools-for-surrogate-modeling-engineering-workflows-with-siml-ai-and-nvidia-modulus/\">Continued</a></p>\n", "protected": false}, "author": 1884, "featured_media": 71343, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1271038", "discourse_permalink": "https://forums.developer.nvidia.com/t/ai-powered-simulation-tools-for-surrogate-modeling-engineering-workflows-with-siml-ai-and-nvidia-modulus/268256", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [852, 503, 1903], "tags": [1913, 2375, 453, 2216, 1961, 3281], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/simlai-interaction.gif", "jetpack_shortlink": "https://wp.me/pcCQAL-ix3", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71241"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1884"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=71241"}], "version-history": [{"count": 16, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71241/revisions"}], "predecessor-version": [{"id": 71378, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71241/revisions/71378"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/71343"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=71241"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=71241"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=71241"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 71228, "date": "2023-10-02T11:54:26", "date_gmt": "2023-10-02T18:54:26", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=71228"}, "modified": "2023-10-23T10:13:13", "modified_gmt": "2023-10-23T17:13:13", "slug": "building-software-defined-high-performance-and-efficient-vran-requires-programmable-inline-acceleration", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/building-software-defined-high-performance-and-efficient-vran-requires-programmable-inline-acceleration/", "title": {"rendered": "Building Software-Defined, High-Performance, and Efficient vRAN Requires Programmable Inline Acceleration"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>In 3GPP fifth generation (5G) cellular standard, layer 1 (L1) or the physical layer (PHY) is the most compute-intensive part of the radio access network (RAN) workload. It involves some of the most complex mathematical operations with sophisticated algorithms like channel estimation and equalization, modulation/demodulation, and forward error correction (FEC). These functions require high compute densities to maintain 5G\u2019s low latency requirements and signal integrity in different radio conditions. </p>\n\n\n\n<p>Traditionally, this layer has been implemented using purpose-built hardware, for example, specialized application-specific integrated circuits (ASICs) with digital signal processing (DSP) cores. This approach, has several drawbacks, however, namely an inability to scale performance, tight hardware-software coupling, and closed single vendor solution. This all results in the high cost of deploying and operating the RAN.&nbsp;</p>\n\n\n\n<p>To address these challenges, the industry has been evolving towards virtualized RAN (vRAN) and open RAN (<a href=\"https://www.o-ran.org/\">O-RAN</a>) architectures using x86 CPU-based commercial-off-the-shelf (COTS) servers. There&#8217;s an expectation that this will lower the cost, and that the resultant hardware-software disaggregation will drive faster innovation cycles, leading the path toward a cloud-native architecture. </p>\n\n\n\n<p>However, the complex signal processing needs of L1 make it difficult to achieve the desired vRAN performance on x86 CPU-based COTS servers. To address this L1 performance gap, some industry players are building fixed-function accelerators. Examples include discrete ASICs, field programmable gate arrays (FPGAs), or integrated system-on-chips (SoCs). </p>\n\n\n\n<p>Fixed-function accelerators supplement the CPU performance and accelerate the processing of a selected set of functions offloaded from a vRAN L1 pipeline, while retaining the majority of the L1 processing within the CPU. This is an acceleration approach dubbed in the industry as <em>lookaside acceleration</em>.&nbsp;</p>\n\n\n\n<p>In many ways, fixed-function lookaside accelerator-based vRAN platforms are akin to going back in time to the appliance-like, macro base station architecture models, which lack scalability and agility. What our industry needs is a fully software-defined vRAN that can deliver programmability, performance, and software scalability while supporting interoperability and multi-vendor solutions, a key tenet of O-RAN. </p>\n\n\n\n<p>With the emergence of artificial intelligence and machine learning (AI/ML) as one of the key driving forces shaping the landscape beyond 5G, it is equally important for the industry to embrace a vRAN platform that is future-proof. It should be ready to enable new capabilities like AI/ML as augmented features on top of the existing RAN infrastructure.&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\">NVIDIA Aerial platform</h2>\n\n\n\n<p>The NVIDIA Aerial platform brings together the NVIDIA Aerial vRAN stack for 5G, AI frameworks, and the accelerated compute infrastructure. It delivers the key virtues by using the high degree of programmability and parallel processing capabilities of GPUs. The platform differs from the traditional fixed-function lookaside acceleration approach in two ways:</p>\n\n\n\n<ul>\n<li>It does not use any fixed-function accelerator </li>\n\n\n\n<li>Instead of selectively offloading a subset of L1 functions to the accelerator, NVIDIA Aerial implements the entire L1 processing pipeline within GPU, an approach called <em>inline acceleration</em>. </li>\n</ul>\n\n\n\n<p>The NVIDIA Aerial vRAN stack is a fully programmable, software-defined, AI-capable, and cloud-native 5G vRAN. For more information about how NVIDIA Aerial got started, see the <a href=\"https://developer.nvidia.com/mwc/2019/video/mwcla913-vid\">NVIDIA cuBB GPU Accelerated 5G vRAN</a> session from the 2019 Mobile World Congress.</p>\n\n\n\n<p>Our goal with this post is to show the merits of NVIDIA Aerial, a GPU-based inline architecture. We explain why programmable, inline acceleration is a critical foundation to deliver high-performance, energy-efficient, scalable, and cloud-native vRAN.<strong><em>&nbsp;</em></strong></p>\n\n\n\n<h2 class=\"wp-block-heading\">Understanding the lookaside and inline acceleration models</h2>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/v-ran-comparison.png\"><img decoding=\"async\" loading=\"lazy\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/v-ran-comparison.png\" alt=\"Diagram models architecture and data flows to highlight the challenges and benefits of the two acceleration models.\" class=\"wp-image-71329\" width=\"978\" height=\"933\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/v-ran-comparison.png 1955w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/v-ran-comparison-300x286.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/v-ran-comparison-625x597.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/v-ran-comparison-120x115.png 120w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/v-ran-comparison-768x733.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/v-ran-comparison-1536x1466.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/v-ran-comparison-645x616.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/v-ran-comparison-314x300.png 314w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/v-ran-comparison-94x90.png 94w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/v-ran-comparison-32x32.png 32w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/v-ran-comparison-362x346.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/v-ran-comparison-115x110.png 115w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/v-ran-comparison-1024x977.png 1024w\" sizes=\"(max-width: 978px) 100vw, 978px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 1. vRAN acceleration with the lookaside and inline models</em></figcaption></figure></div>\n\n\n<p>To begin with, look into the generic working principles of the lookaside and Inline acceleration models.&nbsp;</p>\n\n\n\n<p>Figure 1 shows the data flow in downlink and uplink directions for two different acceleration models: <em>Lookaside</em> and <em>Inline</em>. For more information, see <a href=\"https://arxiv.org/ftp/arxiv/papers/2305/2305.09588.pdf\">Hardware Acceleration for Open Radio Access Networks: A Contemporary Overview</a>.</p>\n\n\n\n<p>In a lookaside acceleration model, the host CPU invokes data processing offload to the accelerator and receives the results back when the processing is done. The lookaside approach requires a back-and-forth data transfer between the CPU and the accelerator. If there are multiple, non-contiguous functional blocks offload (for example, FEC decode and channel estimation), the overhead of the host-to-device data transfer and resulting memory bandwidth consumption becomes significantly high.&nbsp;</p>\n\n\n\n<p>In an inline acceleration model, the accelerator directly exchanges data with the network interface card (NIC) without involving the CPU in the critical path. For full L1 acceleration in an inline model, the entire L1 processing is offloaded to the accelerator.&nbsp;</p>\n\n\n\n<p>Inline acceleration does not require a back-and-forth redundant data transfer between the host and the device, unlike lookaside acceleration. The net effect of this is more efficient usage of memory and PCIe bandwidth.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Programmable, inline acceleration is better for vRAN</h2>\n\n\n\n<p>Take a closer look at vRAN solutions based on two acceleration approaches: </p>\n\n\n\n<ul>\n<li>Lookaside with a fixed-function accelerator </li>\n\n\n\n<li>Inline with a programmable accelerator </li>\n</ul>\n\n\n\n<p>In this section, we highlight the merits and limitations of each and explain why the inline approach with programmable accelerators is more suitable for vRAN compared to lookaside with fixed-function accelerators.</p>\n\n\n\n<ul>\n<li>Lookaside offload costs affect latency and performance</li>\n\n\n\n<li>Lookaside quality of service guarantees increase complexity</li>\n\n\n\n<li>Lookaside accelerator integrated as a PCIe device is not equivalent to an inline accelerator</li>\n\n\n\n<li>Fixed-function acceleration is inherently not cloud-native</li>\n\n\n\n<li>Fixed-function accelerators lack scalability</li>\n\n\n\n<li>Fixed-function accelerators are not agile</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\">Lookaside offload costs affect latency and performance</h3>\n\n\n\n<p>Lookaside acceleration results in a cost of offload due to the request/response transaction across the PCIe interface between the CPU and the accelerator. In the case of multiple, back-and-forth transactions (due to offloading a set of non-contiguous functions), lookaside acceleration increases both the CPU cycle consumption and latency, impacting perf/Watt and perf/$$. </p>\n\n\n\n<p>To reduce the cost of offload, the accelerator driver may combine or batch several requests together. However, this leads to undesired buffering and queuing, resulting in significantly higher latency for various user data flows.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/comparison-pcie-ddr.png\"><img decoding=\"async\" loading=\"lazy\" width=\"488\" height=\"319\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/comparison-pcie-ddr.png\" alt=\"Diagram shows that lookaside acceleration consumes significantly higher PCIe and DDR bandwidth compared to inline acceleration.\u00a0\" class=\"wp-image-71324\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/comparison-pcie-ddr.png 488w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/comparison-pcie-ddr-300x196.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/comparison-pcie-ddr-176x115.png 176w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/comparison-pcie-ddr-459x300.png 459w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/comparison-pcie-ddr-138x90.png 138w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/comparison-pcie-ddr-362x237.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/comparison-pcie-ddr-168x110.png 168w\" sizes=\"(max-width: 488px) 100vw, 488px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 2. Comparison of PCIe/DDR bandwidth</em></figcaption></figure></div>\n\n\n<p>&nbsp;Figure 2 shows the expected host PCIe and the double data rate bandwidth (DDR BW) consumption (Gbps) as the number of supported 4-transmit-4-receive (4T4R) 100MHz cells increases. The graph shows that the aggregated transaction bandwidth needed to support four downlink (DL) layers and two uplink (UL) layers (for each 100MHz cell) when deploying with a lookaside accelerator is much worse. Approximately 40x more bandwidth is consumed when compared to the inline accelerator. </p>\n\n\n\n<p>It is also worth mentioning that as the number of cells increases, PCIe Gen4 technology cannot sustain the required bandwidth and PCIe Gen5 technology is required to support the lookaside accelerator.&nbsp;</p>\n\n\n\n<h3 class=\"wp-block-heading\">Lookaside quality of service guarantees increase complexity</h3>\n\n\n\n<p>Fine-grained QoS support for various user data flows is another challenge with lookaside accelerators. The complex queuing architecture required across the PCIe interface to meet the QoS needs can result in performance degradation and impact tail latency of queued requests to the accelerator. </p>\n\n\n\n<p>As an example, consider a DU system that supports mixed user data flows for voice over Internet protocol (VoIP), Internet of things (IoT), enhanced mobile broadband (eMBB), and ultra-reliable low-latency communications (URLLC) applications. In the lookaside model, if a VoIP or URLLC packet gets stuck behind large blocks of eMBB data queued to the accelerator, it incurs significant latency and jitter and degrades the QoS. The fact that this can accumulate over time as every transaction needs to go through a Lookaside accelerator results in significant performance degradation. </p>\n\n\n\n<p>There are ways to address these issues through QoS guarantees and hierarchical scheduling across the lookaside PCIe interface. However, this increases both the hardware and the software complexity, resulting in increased cost and energy consumption, as well as reduced cell capacity.</p>\n\n\n\n<p>To further demonstrate the cell capacity and power efficiency benefits of deploying an inline accelerator compared to lookaside, we evaluated the performance of both acceleration modes with respect to two metrics for the following system configuration: 100 MHz, 4T4R, 4 DL/2 UL layers: </p>\n\n\n\n<ul>\n<li>Number of 100MHz cells supported </li>\n\n\n\n<li>MHz*Layers/Watt</li>\n</ul>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/normalized-cells-power-efficiency.png\"><img decoding=\"async\" loading=\"lazy\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/normalized-cells-power-efficiency.png\" alt=\"Bar charts show normalized cells and power efficiency for CPU only, CPU plus fixed-function lookaside acceleration, and NVIDIA Aerial inline acceleration.\" class=\"wp-image-71509\" width=\"1200\" height=\"347\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/normalized-cells-power-efficiency.png 2400w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/normalized-cells-power-efficiency-300x87.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/normalized-cells-power-efficiency-625x180.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/normalized-cells-power-efficiency-179x52.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/normalized-cells-power-efficiency-768x222.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/normalized-cells-power-efficiency-1536x444.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/normalized-cells-power-efficiency-2048x591.png 2048w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/normalized-cells-power-efficiency-645x186.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/normalized-cells-power-efficiency-500x144.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/normalized-cells-power-efficiency-160x46.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/normalized-cells-power-efficiency-362x105.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/normalized-cells-power-efficiency-381x110.png 381w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/normalized-cells-power-efficiency-1024x296.png 1024w\" sizes=\"(max-width: 1200px) 100vw, 1200px\" /></a></figure></div>\n\n\n<p>Figure 3 shows the performance comparison, with the number of supported cells metric (normalized) displayed on the left and the MHz*Layers/Watt metric displayed on the right. For each metric, the cell capacity and power efficiency benefits are clear when deploying an inline accelerator, compared to a fixed-function lookaside accelerator or no accelerator (that is, CPU only).&nbsp;</p>\n\n\n\n<h3 class=\"wp-block-heading\">Lookaside accelerator integrated as a PCIe device is not equivalent to an inline accelerator</h3>\n\n\n\n<p>Some argue that the integration of lookaside accelerators in the CPU makes it an inline architecture. Nothing could be farthest from the truth. </p>\n\n\n\n<p>While integration may result in limited power optimization and reduce the component price, any fixed-function lookaside accelerator, such as FEC, integrated in the CPU still manifests as a PCIe device and is accessed through DPDK BBDEV. The net effect is that the same inefficiency exists with fixed-function lookaside accelerators, no matter whether they are discrete components, or integrated in the CPU. </p>\n\n\n\n<p>In fact, integrating lookaside accelerators introduce a new set of problems: managing specific CPU stock-keeping units (SKUs), juggling feature prioritization, increasing CPU costs, and so on.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Fixed-function acceleration is inherently not cloud-native</h3>\n\n\n\n<p>The key tenet of cloud computing is that the infrastructure resources can be shared across applications, increasing the utilization, and delivering better economies of scale. </p>\n\n\n\n<p>Fixed-function accelerators (such as FPGA-based, low-density parity check (LDPC), SoC-based L1 high-PHY and so on) are single-purpose. When a fixed-function accelerator is not being used by 5G vRAN, it is a wasted resource that is not used by any other application. </p>\n\n\n\n<p>Typical 5G networks run at less than 50% average utilization. This means a fixed-function lookaside accelerator can just sit there in the cloud, not being used for more than 50% of the time. On the other hand, a general-purpose and programmable accelerator such as a GPU can be reused for other applications, such as large language model (LLM) training and inferencing, computer vision, and analytics.&nbsp;</p>\n\n\n\n<p>Data Plane Development Kit Baseband Device (<a href=\"https://doc.dpdk.org/guides/prog_guide/bbdev.html\">DPDK BBDEV</a>) is the commonly used application programming interface (API) for lookaside acceleration. It is not well-suited for cloud-native deployments. DPDK has many constructs that were designed for high-performance, in-network appliances, including the following: </p>\n\n\n\n<ul>\n<li>Huge page tables</li>\n\n\n\n<li>Pre-allocated buffers</li>\n\n\n\n<li>Pinned memory</li>\n\n\n\n<li>Single-root input/output virtualization (SR-IOV)</li>\n\n\n\n<li>Queue-centric enqueue-dequeue operations</li>\n</ul>\n\n\n\n<p>These features, however, create a strong affinity towards the underlying hardware, not enabling seamless portability and workload movement in a true cloud-native fashion.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Fixed-function accelerators lack scalability</h3>\n\n\n\n<p>A major drawback of fixed-function accelerators like FEC LDPC, discrete Fourier transform (DFT), inverse DFT (iDFT), and other selected baseband Layer 1 functions is that, while it may be right-sized for one configuration or use case, it is suboptimal for another configuration. </p>\n\n\n\n<p>Take FEC LDPC as an example. In a typical 5G frequency range 1 (FR1) sub-6 GHz system with 4T4R antenna and DDDSUUDDDD channel configuration (D: downlink, U: uplink, S: special) and 4 DL/2 UL layers, the LDPC decoder may constitute about 25% of the physical uplink shared channel (PUSCH) workload in an UL slot. </p>\n\n\n\n<p>Keeping other configurations unchanged, if the system dimension scales from a 4T4R to 64T64R antenna configuration (massive MIMO), the LDPC decoder compute load on the PUSCH pipeline, as it turns out, does not increase commensurately. In fact, in this higher dimensional system, LDPC constitutes approximately just 10% of the overall uplink workload. </p>\n\n\n\n<p>Why does this happen? It&#8217;s because the complexity of the LDPC decoder scales only linearly with the number of layers, where other algorithms, such as channel estimation or detection, scale superlinearly. This can easily lead to suboptimal designs from the point of view of resource utilization and power consumption, if these functions are implemented in fixed-function acceleration logic.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Fixed-function accelerators are not agile</h3>\n\n\n\n<p>Fixed-function accelerators are difficult to evolve with 3GPP releases (for example, with new features) as they are designed for a particular release of the specification. Upgrades of these complex algorithms running on fixed-function accelerators are difficult (especially when implemented in hardware), thereby throttling improvements over time. Also, hardware bug fixes are problematic to resolve, often resulting in costly replacement as being the only viable resolution.&nbsp;</p>\n\n\n\n<p>To summarize, fixed-function lookaside acceleration has several drawbacks:  an impact on performance and latency, lower energy efficiency, and lack of programmability and scalability. These issues directly result in higher CapEx and OpEx for telco operators.&nbsp;</p>\n\n\n\n<p>Next, we discuss an alternate approach taken by NVIDIA, that addresses many of the issues highlighted earlier by harnessing the principles of programmability and inline acceleration. This solution paves the way for industry-leading vRAN.</p>\n\n\n\n<h2 class=\"wp-block-heading\">NVIDIA Aerial: Programmable, GPU-based inline acceleration for vRAN&nbsp;</h2>\n\n\n\n<p>NVIDIA has taken a thoughtful architectural approach to use the inline architecture for a full L1 offload to a programmable GPU. The architecture uses <a href=\"https://www.nvidia.com/en-us/networking/products/data-processing-unit/\">Bluefield DPUs</a> to bring all fronthaul-enhanced common public radio interface (eCPRI) data traffic into the GPU without the CPU in the data path.&nbsp;</p>\n\n\n\n<p>A natural question to ask is why GPUs? The signal processing requirements of the 5G PHY are computationally challenging, compounded by intensive matrix operations. The massive parallelism of the GPU architecture brings the right hardware resources to support this class of workloads. </p>\n\n\n\n<p>From a developer perspective, GPUs are programmed using <a href=\"https://developer.nvidia.com/cuda-zone#:~:text=CUDA%C2%AE%20is%20a%20parallel,harnessing%20the%20power%20of%20GPUs.\">CUDA</a>, the world\u2019s most commercially successful parallel programming framework. This makes your job simpler as you can use mature tools and expansive libraries for software lifecycle management including planning, design, development, optimization, testing, and maintenance. This has been proven by the widespread adoption of GPUs in the computationally complex field of AI and machine learning.&nbsp;</p>\n\n\n\n<p>The second question is why inline? Inline architecture provides a full offload of vRAN L1 processing to the GPU without any CPU interactions. The interface for the offload is the functional application platform interface (<a href=\"https://scf.io/en/documents/222_5G_FAPI_PHY_API_Specification.php\">FAPI</a>), which is an industry standard developed within the Small Cell Forum (<a href=\"https://www.smallcellforum.org/\">SCF</a>). The full offload also avoids the complex and inefficient ping-pong effects of the lookaside model between the CPU and the accelerator across the host PCIe interface, resulting in the improved performance and lower latency explained earlier.&nbsp;</p>\n\n\n\n<p><a href=\"https://developer.nvidia.com/aerial-sdk\">NVIDIA Aerial</a>, enabling fully programmable, cloud-native, AI-capable, and high-performance end-to-end L1 high-PHY (7.2-x split) inline acceleration is built upon two fundamental principles: </p>\n\n\n\n<ul>\n<li>Accelerated compute </li>\n\n\n\n<li>Fast I/O</li>\n</ul>\n\n\n\n<p>Accelerated compute is manifested through the component<a href=\"https://developer.nvidia.com/aerial-sdk\"> CUDA baseband</a> (cuBB), the software stack providing a GPU-accelerated 5G L1 signal processing pipeline. cuBB delivers unprecedented throughput and efficiency by keeping all PHY layer processing within the high-performance GPU memory. cuBB includes 5G L1 high-PHY acceleration library cuPHY, which is highly optimized for NVIDIA GPUs and offers unparalleled scalability by using a GPU\u2019s massive computing power and high degree of parallelism.&nbsp;</p>\n\n\n\n<p>Fast I/O is manifested through the NVIDIA DOCA <a href=\"https://docs.nvidia.com/doca/sdk/gpunetio-programming-guide/index.html\">GPUNetIO</a> module, providing optimized I/O and packet processing by exchanging packets directly between GPU memory and a <a href=\"https://developer.nvidia.com/gpudirect\">GPUDirect</a>-capable NVIDIA <a href=\"https://www.nvidia.com/en-us/networking/ethernet/connectx-6-dx/\">ConnectX</a> SmartNIC. Enabling fast I/O processing and direct memory access (DMA) technology is essential in unleashing the full potential of inline acceleration. </p>\n\n\n\n<p>Towards that goal, the NVIDIA Aerial platform has adopted a GPU-centric approach, implemented with NVIDIA DOCA GPUNetIO Library. In this approach, an NVIDIA GPU directly interacts with an NVIDIA SmartNIC using <a href=\"https://developer.nvidia.com/blog/inline-gpu-packet-processing-with-nvidia-doca-gpunetio/\">GPUDirect Async Kernel-initiated Network</a> (GDAKIN) communications to configure and update NIC registers for orchestrating network send and receive operations without the intervention of the CPU. For more information, see <a href=\"https://developer.nvidia.com/blog/inline-gpu-packet-processing-with-nvidia-doca-gpunetio/\">Inline GPU Packet Processing with NVIDIA DOCA GPUNetIO</a>.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/lookaside-vs-inline-for-phy-layer-b.png\"><img decoding=\"async\" loading=\"lazy\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/lookaside-vs-inline-for-phy-layer-b.png\" alt=\"Diagram shows that the programmable inline accelerator (L1 high-PHY offload) delivers 10-40x efficiency in PCIe bandwidth usage compared to the fixed-function lookaside accelerator (FEC offload using DPDK BBDEV).\" class=\"wp-image-71350\" width=\"1309\" height=\"467\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/lookaside-vs-inline-for-phy-layer-b.png 2618w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/lookaside-vs-inline-for-phy-layer-b-300x107.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/lookaside-vs-inline-for-phy-layer-b-625x223.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/lookaside-vs-inline-for-phy-layer-b-179x64.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/lookaside-vs-inline-for-phy-layer-b-768x274.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/lookaside-vs-inline-for-phy-layer-b-1536x548.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/lookaside-vs-inline-for-phy-layer-b-2048x731.png 2048w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/lookaside-vs-inline-for-phy-layer-b-645x230.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/lookaside-vs-inline-for-phy-layer-b-500x178.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/lookaside-vs-inline-for-phy-layer-b-160x57.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/lookaside-vs-inline-for-phy-layer-b-362x129.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/lookaside-vs-inline-for-phy-layer-b-308x110.png 308w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/lookaside-vs-inline-for-phy-layer-b-1024x365.png 1024w\" sizes=\"(max-width: 1309px) 100vw, 1309px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 4. Comparison between fixed-function hardware-based lookaside acceleration and GPU-based programmable inline acceleration implementations for L1 high-PHY</em></figcaption></figure></div>\n\n\n<p>Figure 4 shows the architectural comparison for the PHY layer between the GPU-based inline acceleration implementation using NVIDIA Aerial and the typical fixed-function hardware accelerator (HWA)-based lookaside acceleration. On the right side, the NVIDIA Aerial platform offers a fast, efficient, and streamlined data flow all the way from L2 to L1 and to fronthaul, without requiring CPU staging copies or throttling of the host PCIe bandwidth. </p>\n\n\n\n<ul>\n<li>Higher level acceleration abstraction layer (AAL) between L2 and L1 (that is, FAPI)</li>\n\n\n\n<li>Converged architecture with GPU and DPU</li>\n\n\n\n<li>Interconnect powered by the NVIDIA DOCA GPUNetIO and GPUDirect technologies</li>\n</ul>\n\n\n\n<p>As the entire L1 processing pipeline and corresponding data are contained within the GPU kernels and dynamic random-access memory (DRAM) on the same converged card, NVIDIA Aerial does not consume critical shared resources with L2+ (for example, host DRAM or host PCIe), unlike the traditional lookaside architecture (left).&nbsp; <strong>&nbsp;</strong></p>\n\n\n\n<p>With less CPU core consumption and a high degree of GPU parallelism in processing the entire L1 workload, the NVIDIA Aerial platform delivers a lower CapEx and OpEx solution with unmatched performance, scalability, agility, programmability, and energy efficiency.</p>\n\n\n\n<h2 class=\"wp-block-heading\">NVIDIA Aerial addresses the key requirements</h2>\n\n\n\n<p>Table 1 presents a snapshot of the key requirements for 5G vRAN, the limitations of the lookaside architecture with a fixed-function accelerator in meeting these requirements, and the benefits of the inline architecture with a GPU-programmable accelerator in addressing those shortcomings.</p>\n\n\n\n<figure class=\"wp-block-table aligncenter is-style-stripes\"><table><tbody><tr><td><strong>Requirements</strong></td><td><strong>Fixed-function lookaside architecture</strong></td><td><strong>GPU-programmable inline architecture</strong></td></tr><tr><td>High performance and low latency</td><td>Multiple requests and responses across PCIe lead to increased CPU consumption and worse perf/Watt and perf/$$. Higher L1 processing latency due to batching and queuing of lookaside requests.</td><td>L2 \u2194 L1 \u2194 FH streamlined processing pipeline, no back-and-forth transactions over PCIe, leading to better perf/Watt and perf/$$. No buffering/queuing during L1 runtime, resulting in optimal L1 processing latency.</td></tr><tr><td>Cloud economics</td><td>No reuse: only does \u2018fixed\u2019 function and not sharable with other applications in cloud infrastructure.</td><td>Fully programmable and general purpose resulting in high resource utilization.</td></tr><tr><td>Application portability</td><td>DPDK BBDEV: Not easily portable because of the strong affinity to hardware.</td><td>FAPI: Better portability with higher level abstraction between L2 and L1.</td></tr><tr><td>Scalability</td><td>Designed and optimized for a specific system configuration.</td><td>Fully programmable and scalable for a range of system configs.</td></tr><tr><td>Agility</td><td>Not programmable, long design cycles, and difficult to update with evolving standards and algorithms.</td><td>Fully programmable and software-defined, easy to update for evolving standards and new algorithms.</td></tr></tbody></table><figcaption class=\"wp-element-caption\"><em>Table 1. Five key tenets of OpenRAN and the comparison between the fixed-function lookaside and the GPU programmable inline architectures</em></figcaption></figure>\n\n\n\n<h2 class=\"wp-block-heading\">Conclusion</h2>\n\n\n\n<p>In this post, we highlighted the inefficiencies of fixed-function accelerators and the lookaside processing model. We showed you how the lookaside model impacts performance and energy efficiency along with many scalability challenges. </p>\n\n\n\n<p>The inline processing model with a programmable accelerator addresses the technical bottlenecks of the fixed-function lookaside acceleration model and delivers high performance, energy efficiency, and scalability across various RAN configurations.</p>\n\n\n\n<p>NVIDIA Aerial is the only commercial platform that delivers the key tenets of emerging vRAN: high-performance, software-defined, COTS-based, cloud-native, and AI-ready. It implements the GPU-programmable inline processing model and full L1 offload to deliver efficient performance for a wide range of RAN configurations and use cases with a software architecture that is fully compliant with O-RAN standards.</p>\n\n\n\n<p>We invite you to collaborate with us in our quest to modernize the RAN infrastructure and enable an efficient, high-performance, scalable, agile, cloud-native, fully software-defined, and AI-ready vRAN.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>In 3GPP fifth generation (5G) cellular standard, layer 1 (L1) or the physical layer (PHY) is the most compute-intensive part of the radio access network (RAN) workload. It involves some of the most complex mathematical operations with sophisticated algorithms like channel estimation and equalization, modulation/demodulation, and forward error correction (FEC). These functions require high compute &hellip; <a href=\"https://developer.nvidia.com/blog/building-software-defined-high-performance-and-efficient-vran-requires-programmable-inline-acceleration/\">Continued</a></p>\n", "protected": false}, "author": 1673, "featured_media": 71335, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1271036", "discourse_permalink": "https://forums.developer.nvidia.com/t/building-software-defined-high-performance-and-efficient-vran-requires-programmable-inline-acceleration/268255", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [852, 1205], "tags": [817, 453, 2279], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/telco-tech-blog-future-of-vran-1920x1080-1.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-iwQ", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71228"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1673"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=71228"}], "version-history": [{"count": 22, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71228/revisions"}], "predecessor-version": [{"id": 72114, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71228/revisions/72114"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/71335"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=71228"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=71228"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=71228"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 70772, "date": "2023-10-02T11:16:58", "date_gmt": "2023-10-02T18:16:58", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=70772"}, "modified": "2023-10-19T12:05:57", "modified_gmt": "2023-10-19T19:05:57", "slug": "accelerated-vector-search-approximating-with-rapids-raft-ivf-flat", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/accelerated-vector-search-approximating-with-rapids-raft-ivf-flat/", "title": {"rendered": "Accelerated Vector Search: Approximating with RAPIDS RAFT IVF-Flat"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>Performing an exhaustive exact k-nearest neighbor (kNN) search, also known as <em>brute-force search</em>, is expensive, and it doesn\u2019t scale particularly well to larger datasets. During vector search, brute-force search requires the distance to be calculated between every query vector and database vector. For the frequently used Euclidean and cosine distances, the computation task becomes equivalent to a large matrix multiplication.</p>\n\n\n\n<p>Although GPUs are efficient at performing matrix multiplications, the computational cost becomes prohibitive with increasing data volumes. Yet many applications don\u2019t require exact results and can instead trade off some accuracy for faster searches. When exact results are not needed, approximate nearest neighbor (ANN) methods can often reduce the number of distance computations that must be performed during search.</p>\n\n\n\n<p>This post focuses on IVF-Flat, an ANN algorithm found in <a href=\"https://developer.nvidia.com/blog/reusable-computational-patterns-for-machine-learning-and-data-analytics-with-rapids-raft/\">RAPIDS RAFT</a>. The IVF-Flat method uses an inverted file index (IVF) with unmodified (that is, flat) vectors. This algorithm provides simple knobs to reduce the overall search space and to trade-off accuracy for speed.</p>\n\n\n\n<p>To help you understand how to use IVF-Flat, we discuss how the algorithm works, and demonstrate the usage of both the <a href=\"https://docs.rapids.ai/api/raft/stable/pylibraft_api/neighbors/#ivf-flat\">Python</a> and <a href=\"https://docs.rapids.ai/api/raft/stable/cpp_api/neighbors_ivf_flat/\">C++ APIs</a> in RAFT. We cover setting parameters for index building and give tips on how to configure GPU-accelerated IVF-Flat search. These steps can also be followed in the example <a href=\"https://github.com/rapidsai/raft/blob/a1002f8c8f4debc52fbab7191297a2f54ff42856/notebooks/ivf_flat_example.ipynb\">Python notebook</a> and <a href=\"https://github.com/rapidsai/raft/blob/a1002f8c8f4debc52fbab7191297a2f54ff42856/cpp/template/src/ivf_flat_example.cu\">C++ project</a>. Finally, we demonstrate that GPU-accelerated vector search can be an order of magnitude faster than CPU search.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><a></a>IVF-Flat algorithm</h2>\n\n\n\n<p>IVF methods accelerate vector search by grouping the dataset vectors into clusters and limiting the search to some number of nearest clusters for each query (Figure 1).</p>\n\n\n\n<p>Searching only a few clusters (instead of the whole dataset) is the actual approximation in the IVF-Flat algorithm. Using this approximation, you might miss some neighbors that are assigned to clusters you aren\u2019t searching, but it greatly improves search time.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dataset-points-query-clusters.png\"><img decoding=\"async\" loading=\"lazy\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dataset-points-query-clusters.png\" alt=\"Two diagrams show a) dataset points grouped into clusters and b) a subset of the clusters highlighted.\" class=\"wp-image-70784\" width=\"1000\" height=\"407\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dataset-points-query-clusters.png 1999w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dataset-points-query-clusters-300x122.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dataset-points-query-clusters-625x255.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dataset-points-query-clusters-179x73.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dataset-points-query-clusters-768x313.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dataset-points-query-clusters-1536x625.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dataset-points-query-clusters-645x263.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dataset-points-query-clusters-500x204.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dataset-points-query-clusters-160x65.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dataset-points-query-clusters-362x147.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dataset-points-query-clusters-270x110.png 270w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dataset-points-query-clusters-1024x417.png 1024w\" sizes=\"(max-width: 1000px) 100vw, 1000px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 1. A dataset divided into clusters (left), and search is restricted to clusters in the vicinity of the queries (right)</em></figcaption></figure></div>\n\n\n<p>Before you can search the dataset, you must build an index, which is a structure that stores the information that you need for efficient search. For IVF-Flat, the index stores the description of the clusters: the coordinates of their center, and the list of vectors that belong to the cluster. This list is the inverted list, also known as an inverted file, and that is where the IVF acronym comes from.</p>\n\n\n\n<p>In the following sections, after discussing inverted files, we demonstrate how to construct an index and explain how the search is performed.</p>\n\n\n\n<h3 class=\"wp-block-heading\">IVF meaning</h3>\n\n\n\n<p>For completeness, here\u2019s some historical context. The term <em>inverted file</em> (or inverted index) comes from the information retrieval field.</p>\n\n\n\n<p>Consider a simple example of a few text documents. To search documents that contain a given word, a<a href=\"https://en.wikipedia.org/wiki/Search_engine_indexing#The_forward_index\"> forward index</a> stores a list of words for each document. You must read each document explicitly to find the relevant ones.</p>\n\n\n\n<p>In contrast, an <a href=\"https://en.wikipedia.org/wiki/Inverted_index\">inverted index</a> would contain a dictionary of all the words that you can search, and for each word, you have a list of document indices where the word occurs. This is the inverted list (inverted file), and it enables you to restrict the search to the selected lists.</p>\n\n\n\n<p>Today, text data is often represented as vector embeddings. The IVF-Flat method defines cluster centers and these centers are analogous to the dictionary of words in the preceding example. For each cluster center, you have a list of vector indices that belong to the cluster, and search is accelerated because you only have to inspect the selected clusters.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><a></a>Index building</h2>\n\n\n\n<p>The index building is mainly a clustering operation on the dataset. An <code>ivf_flat</code> index can be created in Python using the following code example:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\nfrom pylibraft.neighbors import ivf_flat\n\nbuild_params = ivf_flat.IndexParams(\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 n_lists=1024,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 metric=&quot;sqeuclidean&quot;\n\u00a0\u00a0\u00a0 )\n\nindex = ivf_flat.build(build_params, dataset)\n</pre></div>\n\n\n<p>In C++, you have the following syntax:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\n#include &lt;raft/neighbors/ivf_flat.cuh&gt; \nusing namespace raft::neighbors;\nraft::device_resources dev_resources;\n\nivf_flat::index_params index_params;\nindex_params.n_lists = 1024;\nindex_params.metric = raft::distance::DistanceType::L2Expanded;\n\nauto index = ivf_flat::build(dev_resources, index_params,\nraft::make_const_mdspan(dataset.view()));\n</pre></div>\n\n\n<p>The most important hyperparameter for creating the index is <code>n_lists</code>, which tells how many clusters to use. You also specify the metric for distance calculation.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><a></a>Search</h2>\n\n\n\n<p>After the index is built, search is simple. In Python, the following call returns two arrays: the indices of the neighbors and their distances from the query vectors:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\ndistances, indices = ivf_flat.search(ivf_flat.SearchParams(n_probes=50), index, queries, k=10)\n</pre></div>\n\n\n<p>The equivalent call in C++ requires preallocating the output arrays:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\nint topk = 10;\nauto neighbors = raft::make_device_matrix&lt;int64_t, int64_t&gt;(dev_resources, n_queries, topk);\nauto distances = raft::make_device_matrix&lt;float, int64_t&gt;(dev_resources, n_queries, topk);\n\nivf_flat::search_params search_params;\nsearch_params.n_probes = 50;\n\nivf_flat::search(dev_resources,\n                search_params,\n                index,\n                raft::make_const_mdspan(queries.view()),\n                neighbors.view(),\n                distances.view());\n</pre></div>\n\n\n<p>Here you search <code>k=10</code> neighbors for each query. The parameter <code>n_probes</code> tells you how many clusters to search (or probe) for each query, and it determines the accuracy of the search.</p>\n\n\n\n<p>By testing only <code>n_probes</code> clusters for each query, you might omit some neighbors that were assigned to clusters whose centers are farther from the query point. The quality of the search is usually measured as the <em>recall rate,</em> which is the fraction of the actual nearest k-neighbors out of all the returned neighbors.</p>\n\n\n\n<p>Internally, the search is performed in two steps (Figure 2):</p>\n\n\n\n<ol type=\"1\" start=\"1\">\n<li>The coarse search selects <code>n_probes</code> nearby clusters for each query.</li>\n\n\n\n<li>A fine search compares the query vectors to all the dataset vectors in the selected clusters.</li>\n</ol>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/two-step-vector-search.png\"><img decoding=\"async\" loading=\"lazy\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/two-step-vector-search.png\" alt=\"Diagram of clusters represented by their centers with the clusters highlighted that are closest to the queries. Selected clusters shown with the individual points within these clusters.\" class=\"wp-image-70786\" width=\"1000\" height=\"395\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/two-step-vector-search.png 1999w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/two-step-vector-search-300x119.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/two-step-vector-search-625x247.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/two-step-vector-search-179x71.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/two-step-vector-search-768x304.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/two-step-vector-search-1536x607.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/two-step-vector-search-645x255.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/two-step-vector-search-500x198.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/two-step-vector-search-160x63.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/two-step-vector-search-362x143.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/two-step-vector-search-278x110.png 278w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/two-step-vector-search-1024x405.png 1024w\" sizes=\"(max-width: 1000px) 100vw, 1000px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 2. Two-step search: select nearby clusters by comparing the queries to cluster centers (left) and compare all the vectors in the selected clusters to the corresponding queries (right)</em></figcaption></figure></div>\n\n\n<h3 class=\"wp-block-heading\"><a></a>Coarse search</h3>\n\n\n\n<p>The coarse search is done using an exact kNN search between the cluster centers and the query vectors. Select the nearest cluster centers, <code>n_probes clusters</code> for each query. Coarse search is relatively cheap because the number of clusters is much smaller than the dataset size (for example, 10K clusters for 100M vectors).</p>\n\n\n\n<h3 class=\"wp-block-heading\"><a></a>Fine search</h3>\n\n\n\n<p>For IVF-Flat, the fine search is again an exact search. But each query has its own set of clusters to search (to probe), and the distance between the query vector and all the vectors in the probed clusters are calculated. </p>\n\n\n\n<p>For small batch sizes, the regions that you search around a query point do not overlap. Therefore, the problem structure becomes a batched matrix-vector multiplication (GEMV) operation. This operation is memory bandwidth bound, and the large bandwidth of GPU memory greatly accelerates this step.</p>\n\n\n\n<p>The top-k neighbors from each probed cluster are selected, which results in <code>n_probes * k neighbor candidates</code> for each query. This is reduced to the k-nearest neighbors.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><a></a>Tuning parameters for index building</h2>\n\n\n\n<p>In the previous sections, you got an overview of the index building and search. Here\u2019s a detailed look at how to set the parameters for index building.</p>\n\n\n\n<p>Construction of the index consists of two phases:</p>\n\n\n\n<ul>\n<li><strong>Training or computing the clusters (build):</strong> A balanced hierarchical k-means algorithm clusters the training data.</li>\n\n\n\n<li><strong>Adding the dataset vectors to the index (extend):</strong> Dataset vectors are assigned to their cluster and added to the appropriate list of vectors in the clusters.</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\"><a></a>Number of clusters</h3>\n\n\n\n<p>The <code>n_lists</code> parameter has a profound impact on overall performance during both training and search: it defines the number of clusters into which the index data is partitioned. Setting <code>n_lists = sqrt(n_samples)</code> is a good starting point (where <code>n_samples</code> is the number of vectors in the dataset). </p>\n\n\n\n<p>To make sure that the GPU resources are used efficiently, the average cluster size (that is, <code>n_samples/n_lists</code>) should be in the range of at least 1K vectors to keep individual streaming multiprocessors (SMs) busy.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><a></a>Index building with automatic data subsampling</h3>\n\n\n\n<p>K-means clustering is compute-intensive. To accelerate index building, sub-sample the dataset. Using parameter <code>kmeans_trainset_fraction=0.1</code> means that you use one-tenth of the dataset for training the cluster centers.</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\nbuild_params = ivf_flat.IndexParams(\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 n_lists=1024,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 metric=&quot;sqeuclidean&quot;,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 kmeans_trainset_fraction=0.1,\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 kmeans_n_iters=20\n\u00a0\u00a0\u00a0 )\n</pre></div>\n\n\n<p>The <code>kmeans_n_iters</code> parameter is passed directly to the k-means algorithm during training. It&#8217;s set to a reasonable default of 20, which works for most datasets. However, this parameter is just a recommendation for the clustering algorithm. Under the hood, it usually performs more iterations in a \u201cbalancing\u201d phase to make sure the clusters have similar sizes.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><a></a>Index building with specific training data for clustering</h3>\n\n\n\n<p>In the previous examples, a single call to <code>ivf_flat.build</code> performed the clustering and added the whole dataset into the index. Alternatively, you could call <code>ivf_flat.build</code> to train the vectors without adding them to the index (by setting <code>add_data_on_build=False</code>). This allows exact control of what vectors are used for training the index. Subsequently, <code>ivf_flat.extend</code> can be used to add vectors to the index.</p>\n\n\n\n<p>This is shown in the following Python code example:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\nn_train = 10000\ntrain_set = dataset&#91;cp.random.choice(dataset.shape&#91;0], n_train, replace=False),:]\n\nbuild_params = ivf_flat.IndexParams(\n        n_lists=1024,\n        metric=&quot;sqeuclidean&quot;,\n        kmeans_trainset_fraction=1,\n        kmeans_n_iters=20,\n        add_data_on_build=False\n    )\n\nindex = ivf_flat.build(build_params, train_set)\nivf_flat.extend(index, dataset, cp.arange(dataset.shape&#91;0], dtype=cp.int64))\n</pre></div>\n\n\n<p>The dataset vectors can be added to the index by a single call to <code>ivf_flat.extend</code>. Internally, the data is processed batch-wise if needed to reduce memory consumption. The corresponding C++ code is as follows:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\nindex_params.add_data_on_build = false;\n// Sub sample the dataset to create trainset.\n// ...\n// Run k-means clustering using the training set\nauto index = ivf_flat::build(dev_resources, index_params,\n    raft::make_const_mdspan(trainset.view()));\n\n// Fill the index with the dataset vectors\nindex = ivf_flat::extend(dev_resources,\n    raft::make_const_mdspan(dataset.view()),\n    std::optional&lt;raft::device_vector_view&lt;const int64_t, int64_t&gt;&gt;(),\n    index);\n</pre></div>\n\n\n<h3 class=\"wp-block-heading\"><a></a>Adding new vectors to the index</h3>\n\n\n\n<p>New vectors can be added at any time to the dataset by calling <code>ivf_flat.extend</code>. By default, the cost of growing the list of vectors is amortized away by allocating extra space when the list size is increased. C++ API users can change this behavior by setting the following parameter:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\nindex_params.conservative_memory_allocation = true;\n</pre></div>\n\n\n<p>This can be beneficial if the number of clusters is large, and it is not expected to add vectors often.</p>\n\n\n\n<p>By default, the cluster centers do not change when you add vectors to the dataset. The <code>adaptive_centers</code> flag can be enabled during index construction if you want the cluster centers to drift with the new data.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><a></a>Tuning parameters for search</h2>\n\n\n\n<p>Here\u2019s how to set the parameters for search: use GPU resources efficiently and increase the value of <code>n_probes</code>.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><a></a>GPU resources</h3>\n\n\n\n<p>During search, you create internal workspace memory. We recommend using a pooling allocator to reduce the overhead of memory allocation.</p>\n\n\n\n<p>Constructing the RAFT <code>resources</code> object is time-consuming. The <code>resources</code> object should be reused by passing a resource handle to the search function. In Python, you can configure the device resources and the memory pool in the following way:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: python; title: ; notranslate\" title=\"\">\nfrom pylibraft.common import DeviceResources\nimport rmm\nmr = rmm.mr.PoolMemoryResource(\n     rmm.mr.CudaMemoryResource(),\n     initial_pool_size=2**30\n)\nrmm.mr.set_current_device_resource(mr)\n\nhandle = DeviceResources()\n\nsearch_params = ivf_flat.SearchParams(n_probes=50)\ndistances, indices = ivf_flat.search(search_params, index, queries, k=10, handle=handle)\nhandle.sync()\n</pre></div>\n\n\n<p>Users of the C++ API always have to pass an explicit device_resources handle, and this should be reused among separate calls to search. The pool allocator can be set up in the following way:</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\nraft::device_resources dev_resources;\nraft::resource::set_workspace_to_pool_resource(\n\u00a0\u00a0\u00a0 dev_resources, 2 * 1024 * 1024 * 1024ull);\nivf_flat::search(dev_resources, ...)\n</pre></div>\n\n\n<p>C++ users can&nbsp;specify a separate allocator for temporary workspace arrays, and this is used in the preceding example. The global allocator (used for creating input/output arrays) can be set using <a href=\"https://docs.rapids.ai/api/rmm/stable/api/#rmm.mr.set_current_device_resource\">rmm::mr::set_current_device_resource</a>.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><a></a>Number of probes</h3>\n\n\n\n<p>The ratio <code>n_probes/n_lists</code> tells what fraction of the dataset is compared to each query. The number of distance computations is reduced to the <code>n_probes/n_clusters</code> fraction of what brute force search would compute. The quality of the search, as well as the compute time, increases as you increase <code>n_probes</code>, and the right value depends on the dataset.</p>\n\n\n\n<p>In Figure 3 and Figure 4, respectively, you can observe how throughput (queries per second) and search accuracy (recall) depends on the number of probes. Here, you are searching through 100M vectors from the <a href=\"https://research.yandex.com/blog/benchmarks-for-billion-scale-similarity-search#14h2\">DEEP1B dataset</a>, and an H100 GPU is used for the search.</p>\n\n\n\n<p>The throughput is inversely proportional to the number of probes. The dataset was divided into 100 thousand clusters. Searching just the 100 closest clusters for each query leads to a recall of 96% and searching 1000 clusters (1% of the dataset) leads to an accuracy of 99.8%.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-throughput.png\"><img decoding=\"async\" loading=\"lazy\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-throughput.png\" alt=\"The throughput graph follows 1/x trend.\" class=\"wp-image-70787\" width=\"600\" height=\"371\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-throughput.png 1200w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-throughput-300x186.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-throughput-625x386.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-throughput-179x111.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-throughput-768x475.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-throughput-645x399.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-throughput-485x300.png 485w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-throughput-146x90.png 146w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-throughput-362x224.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-throughput-178x110.png 178w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-throughput-1024x633.png 1024w\" sizes=\"(max-width: 600px) 100vw, 600px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 3. Search throughput (queries per second) as a function of the </em>n_probes<em> search parameter</em></figcaption></figure></div>\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-accuracy.png\"><img decoding=\"async\" loading=\"lazy\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-accuracy.png\" alt=\"Search accuracy graph shows that recall improves quickly as you increase n_probes from 20 to 200 and flattens out above that (region with 99% recall).\" class=\"wp-image-70788\" width=\"600\" height=\"371\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-accuracy.png 1200w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-accuracy-300x186.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-accuracy-625x386.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-accuracy-179x111.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-accuracy-768x475.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-accuracy-645x399.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-accuracy-485x300.png 485w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-accuracy-146x90.png 146w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-accuracy-362x224.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-accuracy-178x110.png 178w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf-flat-search-accuracy-1024x633.png 1024w\" sizes=\"(max-width: 600px) 100vw, 600px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 4. Accuracy (recall) as a function of the </em>n_probes<em> search parameter</em></figcaption></figure></div>\n\n\n<p>We often combine these plots in a single QPS vs. recall plot (Figure 5). This is useful when you want to have a compact picture of the trade-off between accuracy and search throughput. It is also beneficial while comparing different ANN methods. </p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/combined-qps-recall.png\"><img decoding=\"async\" loading=\"lazy\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/combined-qps-recall.png\" alt=\"Graph shows that the QPS drops when you require high recall.\" class=\"wp-image-70789\" width=\"713\" height=\"441\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/combined-qps-recall.png 950w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/combined-qps-recall-300x186.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/combined-qps-recall-625x387.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/combined-qps-recall-179x111.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/combined-qps-recall-768x475.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/combined-qps-recall-645x399.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/combined-qps-recall-485x300.png 485w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/combined-qps-recall-145x90.png 145w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/combined-qps-recall-362x224.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/combined-qps-recall-178x110.png 178w\" sizes=\"(max-width: 713px) 100vw, 713px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 5. Combined QPS-recall plot</em></figcaption></figure></div>\n\n\n<p>If <code>n_lists == n_probes</code>, that is like an exact (brute force) search: you compare all dataset vectors to all query vectors. You\u2019d expect the recall to be equal to 1 in such a case (apart from small round-off errors).</p>\n\n\n\n<p>As <code>n_probes</code> approach <code>n_lists</code>, IVF-Flat becomes slower than brute force because of the extra work the algorithm does (coarse plus fine search).&nbsp; In practice, searching around 0.1-1% of lists is enough for many datasets. But this depends on how well the input can be clustered.</p>\n\n\n\n<p>Due to the <a href=\"https://bib.dbvis.de/uploadedFiles/155.pdf\">surprising behavior of distance metrics in high dimensions space</a>, clustering becomes difficult if the dataset has no structure (for example, uniform random numbers). In those cases, IVF methods don&#8217;t work well.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><a></a>Performance</h2>\n\n\n\n<p>The RAFT library provides a fast implementation of the IVF-Flat algorithm. Indexing 100M vectors can be done in under a minute (Figure 6). This is 14x faster than a CPU. </p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/index-build-times.png\"><img decoding=\"async\" loading=\"lazy\" width=\"600\" height=\"371\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/index-build-times.png\" alt=\"Bar chart showing high index building time on the CPU and significantly faster times with GPU implementations.\" class=\"wp-image-71298\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/index-build-times.png 600w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/index-build-times-300x186.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/index-build-times-179x111.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/index-build-times-485x300.png 485w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/index-build-times-146x90.png 146w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/index-build-times-362x224.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/index-build-times-178x110.png 178w\" sizes=\"(max-width: 600px) 100vw, 600px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 6. Index build times for different dataset and cluster sizes</em></figcaption></figure></div>\n\n\n<p class=\"has-text-align-center has-small-font-size\">Measurements were performed on an NVIDIA H100 SXM GPU using RAFT 23.10 for GPU tests and on Intel Xeon Platinum 8480CL CPU with <a href=\"https://github.com/facebookresearch/faiss\">FAISS</a> 1.7.4.</p>\n\n\n\n<p>There are two main factors that enable this speedup:</p>\n\n\n\n<ul>\n<li><strong>High compute throughput of the GPU</strong>: RAFT uses Tensor Cores to accelerate the k-means clustering during index building.</li>\n\n\n\n<li><strong>The improved algorithm</strong>: RAFT uses a balanced hierarchical k-means clustering, which clusters the dataset efficiently even as the number of vectors reaches hundreds of millions.</li>\n</ul>\n\n\n\n<p>You can also observe that the time to construct the index increases linearly with the number of vectors, and linearly with the number of clusters.</p>\n\n\n\n<p>Searching through the index is facilitated by the high memory throughput of the GPU. RAFT\u2019s IVF-Flat index uses an optimized memory layout. The vectors are interleaved for vectorized memory access to ensure large bandwidth utilization while looping through the dataset vectors in each probed cluster.</p>\n\n\n\n<p>Another important step during the fine search is to filter out the top-k candidates. We have <a href=\"https://sc23.supercomputing.org/presentation/?id=pap294&amp;sess=sess156\">highly optimized methods to select the top-k candidates</a>. We use optimized block-select-k kernel fused into the distance computation kernels. This enables a more than 20x speedup (at recall=0.95), when we compare the performance of RAFT IVF-Flat to a CPU implementation, as the plot in Figure 7 shows.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"600\" height=\"371\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/search-throughput-different-levels-recall.png\" alt=\"Graph compares IVF-Flat search throughput on the GPU and on the CPU.\" class=\"wp-image-71297\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/search-throughput-different-levels-recall.png 600w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/search-throughput-different-levels-recall-300x186.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/search-throughput-different-levels-recall-179x111.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/search-throughput-different-levels-recall-485x300.png 485w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/search-throughput-different-levels-recall-146x90.png 146w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/search-throughput-different-levels-recall-362x224.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/10/search-throughput-different-levels-recall-178x110.png 178w\" sizes=\"(max-width: 600px) 100vw, 600px\" /><figcaption class=\"wp-element-caption\"><em>Figure 7. Search throughput for different levels of recall (accuracy)</em></figcaption></figure></div>\n\n\n<p>For the purpose of this benchmark, the CPU implementation of FAISS IVF-Flat was used. FAISS also provides a GPU implementation of this algorithm. If you use FAISS, you can already benefit from GPU acceleration with a minor change in your code. We are collaborating with Meta to bring the performance improvements from RAFT to FAISS, so you will soon be able to use RAFT through FAISS as well.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><a></a>Summary</h2>\n\n\n\n<p>When performing vector search in large databases, it\u2019s important to be aware of the high cost of an exact search, as it can result in low latency not suitable for online services.</p>\n\n\n\n<p>The RAPIDS RAFT library provides efficient algorithms that improve vector search latency and throughput by focusing the search to the most relevant part of the dataset. This post discussed how the RAFT IVF-Flat algorithm works and how to set the parameters for index building and searching. Finally, we presented benchmarks to highlight the superior performance of GPUs for IVF-Flat search. You can test it out yourself using our <a href=\"https://docs.rapids.ai/api/raft/stable/raft_ann_benchmarks/\">benchmark tools</a>.</p>\n\n\n\n<p>RAFT is an <a href=\"https://github.com/rapidsai/raft\">open-source library</a> for vector search and more. It provides an easy-to-use <a href=\"https://docs.rapids.ai/api/raft/stable/\">C++ and Python API</a> so you can integrate GPU-accelerated vector search into your applications. We love to hear your feedback! Send us questions and report issues on the <a href=\"https://github.com/rapidsai/raft/issues/new/choose\">/rapidsai/raft</a> GitHub repo. You can also find us at <a href=\"https://twitter.com/rapidsai\">@rapidsai</a>.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Performing an exhaustive exact k-nearest neighbor (kNN) search, also known as brute-force search, is expensive, and it doesn\u2019t scale particularly well to larger datasets. During vector search, brute-force search requires the distance to be calculated between every query vector and database vector. For the frequently used Euclidean and cosine distances, the computation task becomes equivalent &hellip; <a href=\"https://developer.nvidia.com/blog/accelerated-vector-search-approximating-with-rapids-raft-ivf-flat/\">Continued</a></p>\n", "protected": false}, "author": 1870, "featured_media": 70800, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1271026", "discourse_permalink": "https://forums.developer.nvidia.com/t/accelerated-vector-search-approximating-with-rapids-raft-ivf-flat/268251", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [2724, 1050, 1464, 696, 1968], "tags": [1932, 9, 453, 1953, 126, 3496], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ivf_blog_search2.png", "jetpack_shortlink": "https://wp.me/pcCQAL-ipu", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70772"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1870"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=70772"}], "version-history": [{"count": 20, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70772/revisions"}], "predecessor-version": [{"id": 71460, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70772/revisions/71460"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/70800"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=70772"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=70772"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=70772"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 67496, "date": "2023-10-02T09:00:00", "date_gmt": "2023-10-02T16:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=67496"}, "modified": "2023-10-19T12:05:58", "modified_gmt": "2023-10-19T19:05:58", "slug": "explainer-what-is-photogrammetry", "status": "publish", "type": "post", "link": "https://blogs.nvidia.com/blog/2023/06/07/what-is-photogrammetry/", "title": {"rendered": "Explainer: What Is Photogrammetry?"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>Photogrammetry is the process of capturing images and stitching them together to create a digital model of the physical world.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Photogrammetry is the process of capturing images and stitching them together to create a digital model of the physical world.</p>\n", "protected": false}, "author": 1248, "featured_media": 71290, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "", "discourse_permalink": "", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "https://blogs.nvidia.com/blog/2023/06/07/what-is-photogrammetry/", "_links_to_target": "_blank"}, "categories": [97, 1235], "tags": [3268, 2973, 453], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/06/Photogrammetry_Neath_Ironworks-online-video-cutter.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-hyE", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/67496"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1248"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=67496"}], "version-history": [{"count": 3, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/67496/revisions"}], "predecessor-version": [{"id": 71291, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/67496/revisions/71291"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/71290"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=67496"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=67496"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=67496"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 70873, "date": "2023-09-29T12:46:58", "date_gmt": "2023-09-29T19:46:58", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=70873"}, "modified": "2023-10-19T12:05:58", "modified_gmt": "2023-10-19T19:05:58", "slug": "comparing-solutions-for-boosting-data-center-redundancy", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/comparing-solutions-for-boosting-data-center-redundancy/", "title": {"rendered": "Comparing Solutions for Boosting Data Center Redundancy"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>In today\u2019s data center, there are many ways to achieve system redundancy from a server connected to a fabric. Customers usually seek redundancy to increase service availability (such as achieving end-to-end AI workloads) and find system efficiency using different multihoming techniques.</p>\n\n\n\n<p>In this post, we discuss the pros and cons of the well-known proprietary multi-chassis link aggregation group (MLAG) compared to standards-based EVPN multihoming (EVPN-MH).&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\">Introduction to MLAG\u00a0\u00a0</h2>\n\n\n\n<p>Multihoming is necessary for all modern data centers, which enables a single host to connect to two or more nodes and serve in an all-active or single-active manner. All-active focuses on increasing capacity first and redundancy second. Single-active focuses primarily on redundancy.\u00a0\u00a0</p>\n\n\n\n<p>In the Internet Service Provider world, multihoming is a familiar concept, primarily for Point of Presence locations, where customer equipment interconnects with Provider Edge equipment locations.\u00a0</p>\n\n\n\n<p>This connection is almost always a layer 3 routed connection and doesn&#8217;t introduce the challenges of the layer 2 world because it is intended to solve redundant site access or Internet access. However, in data centers, when we connect servers or end nodes into the network in a redundant way, we must get down to layer 2.&nbsp;</p>\n\n\n\n<p>MLAG came along in the early 2010s and many vendors implemented similar features that performed similar functionalities. One important thing to keep in mind is that MLAG is vendor-dependent proprietary technology. According to Wikipedia, <a href=\"https://en.wikipedia.org/wiki/Multi-chassis_link_aggregation_group\">MLAG&#8217;s</a> &#8220;implementation varies by vendor; notably, the protocol existing between the chassis is proprietary.\u201d<em> </em>This is a fundamental problem for <a href=\"https://docs.nvidia.com/networking-ethernet-software/cumulus-linux/Layer-2/Multi-Chassis-Link-Aggregation-MLAG/\">MLAG</a> that triggers many other issues.\u00a0</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"496\" height=\"567\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-1.-Typical-MLAG-wiring.png\" alt=\"Image shows a typical MLAG wiring. \" class=\"wp-image-70877\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-1.-Typical-MLAG-wiring.png 496w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-1.-Typical-MLAG-wiring-262x300.png 262w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-1.-Typical-MLAG-wiring-101x115.png 101w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-1.-Typical-MLAG-wiring-79x90.png 79w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-1.-Typical-MLAG-wiring-362x414.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-1.-Typical-MLAG-wiring-96x110.png 96w\" sizes=\"(max-width: 496px) 100vw, 496px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. Typical MLAG wiring&nbsp;</em></figcaption></figure></div>\n\n\n<p>With MLAG (Figure 1), a client device can be a server or hypervisor, and a switch or router forms a classical link aggregation group (LAG) that typically bonds two physical links into a single logical link. On the other side of these links, you typically have two switches, which these links connect to. From an LACP point of view, these two switches act like a single switch with the same LACP system ID. This makes MLAG work from a server perspective.&nbsp;</p>\n\n\n\n<p>However, for the two MLAG participating switches, things are a bit more complex. Because they require state and MAC synchronization between them, a heartbeat is also needed to prevent split-brain situations and traffic flow over peer links in case one of the participating switches loses its uplink. This peer link makes the entire design non-standard, complex, and error-prone (not fitting in a CLOS leaf and spine architecture).&nbsp;&nbsp;</p>\n\n\n\n<p>There are efforts to make state and MAC synchronization standard. <a href=\"https://datatracker.ietf.org/doc/html/rfc7275\">RFC7275</a> focuses on solving this problem and addressing it with a new protocol called Inter-Chassis Control Protocol (ICCP). However, different vendors still implement various flavors of RFC7275 and end up with the same issues. This MLAG solution solved the multihoming problem in a limited scope.\u00a0\u00a0</p>\n\n\n\n<p>While the future of MLAG is bleak, there\u2019s a more flexible and technically superior multihoming solution: EVPN multihoming (also called EVPN-LAG or ESI-LAG).&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\">Benefits of EVPN multihoming&nbsp;&nbsp;</h2>\n\n\n\n<p>Multihoming is no stranger to the ISP world and initially came along as a WAN technology. However, it became clear that modern data centers require their own way of implementing multihoming.&nbsp;</p>\n\n\n\n<p>Coincidentally, EVPN itself was first introduced as a WAN technology, then evolved into a data center technology. EVPN adopted multihoming functionality rather quickly. With <a href=\"https://datatracker.ietf.org/doc/html/rfc7432\">RFC7432,</a> EVPN-MH uses a new addressing field called the Ethernet Segment Identifier (ESI). This fundamental building block that makes EVPN-MH work is used everywhere across the fabric, as far as type-1 and type-4 routes are propagated.\u00a0ESI is a 10-byte field that specifies a specific multihomed segment.</p>\n\n\n\n<p>Let\u2019s talk about what is under the hood of EVPN-MH, route types, and what makes it attractive compared to legacy and proprietary MLAG.&nbsp;&nbsp;</p>\n\n\n\n<p>EVPN-MH uses Border Gateway Protocol (BGP) as the control plane in contrast to ICCP, which MLAG uses. And, EVPN-MH uses several different types of EVPN route types as per RFC7432.</p>\n\n\n\n<h3 class=\"wp-block-heading\">EVPN Route Type-1</h3>\n\n\n\n<p>EVPN Type-1 Route functions can be listed as mass withdrawal, aliasing, and load sharing (Figure 2).</p>\n\n\n\n<h4 class=\"wp-block-heading\">Mass withdrawal&nbsp;</h4>\n\n\n\n<p>Mass withdrawal makes sure that if a particular link goes down on an ES, you can withdraw all dependent MAC addresses connected to that particular link. This way, you achieve fast convergence by sending a mass withdrawal instead of one by one for each MAC. This assumes that a hypervisor is connected to that ES with many VMs, over the same VLAN, or over hundreds of VLANs.\u00a0</p>\n\n\n\n<h4 class=\"wp-block-heading\">Aliasing and load balancing</h4>\n\n\n\n<p>Aliasing and load balancing makes sure that downstream traffic towards an ES is load-balanced across ES member switches, also known as EVI. This way, the ES member switches can receive traffic from other switches in the fabric in a load-shared manner, regardless of whether they are advertising that particular MAC behind their ES.\u00a0</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"455\" height=\"192\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-2.-EVPN-Ethernet-Auto-Discovery-route.png\" alt=\"Image shows EVPN Type-1 Route frame format\" class=\"wp-image-70880\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-2.-EVPN-Ethernet-Auto-Discovery-route.png 455w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-2.-EVPN-Ethernet-Auto-Discovery-route-300x127.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-2.-EVPN-Ethernet-Auto-Discovery-route-179x76.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-2.-EVPN-Ethernet-Auto-Discovery-route-160x68.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-2.-EVPN-Ethernet-Auto-Discovery-route-362x153.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-2.-EVPN-Ethernet-Auto-Discovery-route-261x110.png 261w\" sizes=\"(max-width: 455px) 100vw, 455px\" /><figcaption class=\"wp-element-caption\"><em>Figure 2. EVPN Ethernet Auto-Discovery route Type-1 frame format</em></figcaption></figure></div>\n\n\n<h3 class=\"wp-block-heading\">EVPN Route Type-2</h3>\n\n\n\n<p>Type-2 (MAC/IP) routes are advertised by the same ES member leafs and they include the ESI value for each MAC attached to this Ethernet Segment\u00a0(Figure 3).</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"446\" height=\"411\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-3.-EVPN-MACIP-Advertisement-Route-type2-frame-format.png\" alt=\"Image shows EVPN Type-2 Route frame format\" class=\"wp-image-70882\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-3.-EVPN-MACIP-Advertisement-Route-type2-frame-format.png 446w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-3.-EVPN-MACIP-Advertisement-Route-type2-frame-format-300x276.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-3.-EVPN-MACIP-Advertisement-Route-type2-frame-format-125x115.png 125w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-3.-EVPN-MACIP-Advertisement-Route-type2-frame-format-326x300.png 326w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-3.-EVPN-MACIP-Advertisement-Route-type2-frame-format-98x90.png 98w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-3.-EVPN-MACIP-Advertisement-Route-type2-frame-format-362x334.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-3.-EVPN-MACIP-Advertisement-Route-type2-frame-format-119x110.png 119w\" sizes=\"(max-width: 446px) 100vw, 446px\" /><figcaption class=\"wp-element-caption\"><em>Figure 3. EVPN MAC/IP Advertisement Route type-2 frame format</em></figcaption></figure></div>\n\n\n<p>Type-2 routes are not part of the EVPN-MH setup, however, they make use of ESI information when it\u2019s present for a specific destination MAC.</p>\n\n\n\n<h3 class=\"wp-block-heading\">EVPN Route Type-4</h3>\n\n\n\n<p>EVPN Type-4 routes are used for election of designated forwarder (DF) and autodiscovery of multihomed ES (Figure 4).</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"487\" height=\"219\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-4.-EVPN-Ethernet-Segment-Route-type4-frame-format.png\" alt=\"Image shows EVPN Type-4 Route frame format\" class=\"wp-image-70884\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-4.-EVPN-Ethernet-Segment-Route-type4-frame-format.png 487w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-4.-EVPN-Ethernet-Segment-Route-type4-frame-format-300x135.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-4.-EVPN-Ethernet-Segment-Route-type4-frame-format-179x80.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-4.-EVPN-Ethernet-Segment-Route-type4-frame-format-160x72.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-4.-EVPN-Ethernet-Segment-Route-type4-frame-format-362x163.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-4.-EVPN-Ethernet-Segment-Route-type4-frame-format-245x110.png 245w\" sizes=\"(max-width: 487px) 100vw, 487px\" /><figcaption class=\"wp-element-caption\"><em>Figure 4. EVPN Ethernet Segment Route type-4 frame format</em></figcaption></figure></div>\n\n\n<p>EVPN type-1 and type-4 routes make EVPN-MH work and provide standards-based interoperability. Type-4 routes are imported by only routers or leafs that participate in that particular ES. Other routers or leafs in the fabric that don\u2019t participate in that ES don&#8217;t import type-4 routes. Type-4 routes are used for DF elections to select where to send local BUM traffic.As BUM traffic has to be flooded across the network, in multihomed scenarios, only the DF is responsible for sending BUM traffic to its clients (such as multihomed servers).\u00a0</p>\n\n\n\n<p>Typical EVPN-MH topology can be seen in Figure 5.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"619\" height=\"687\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-5-typical-EVPNMH-wiring-1.png\" alt=\"Image shows typical EVPN-MH wiring.\" class=\"wp-image-70885\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-5-typical-EVPNMH-wiring-1.png 619w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-5-typical-EVPNMH-wiring-1-270x300.png 270w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-5-typical-EVPNMH-wiring-1-104x115.png 104w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-5-typical-EVPNMH-wiring-1-81x90.png 81w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-5-typical-EVPNMH-wiring-1-362x402.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-5-typical-EVPNMH-wiring-1-99x110.png 99w\" sizes=\"(max-width: 619px) 100vw, 619px\" /><figcaption class=\"wp-element-caption\"><em>Figure 5. Typical EVPN-MH wiring</em></figcaption></figure></div>\n\n\n<h3 class=\"wp-block-heading\">Advantages of EVPN-MH:\u00a0</h3>\n\n\n\n<ul>\n<li>Control-plane based MAC and state synchronization&nbsp;</li>\n\n\n\n<li>Standards-based, BGP EVPN route types, and interoperability&nbsp;</li>\n\n\n\n<li>Fabric-wide-route distribution of multihomed connections\u00a0</li>\n\n\n\n<li>Fast convergence, withdrawal&nbsp;</li>\n\n\n\n<li>Capable of 2+ multihoming&nbsp;</li>\n\n\n\n<li>No need for physical peer link connectivity&nbsp;</li>\n\n\n\n<li>Future proof&nbsp;</li>\n\n\n\n<li>Scalable with BGP\u00a0</li>\n</ul>\n\n\n\n<h2 class=\"wp-block-heading\">Conclusion</h2>\n\n\n\n<p>EVPN-MH is a future-proof technology that uses BGP as its control plane. Its standards-based architecture, ability to provide multihoming to end hosts with more than two gateways, and active-active load balancing make it an attractive de facto solution in modern data center networks. Also, removing the need for a peer link between leafs fits EVPN-MH into the Clos architecture perfectly, reducing cost and complexity.\u00a0\u00a0</p>\n\n\n\n<p>I recommend using EVPN-MH for data centers with EVPN as the control plane, which will soon substitute all MLAG deployments in the field. Existing networks can stay with MLAG as they are already operational. However, new deployments and designs should certainly be based on EVPN-MH.&nbsp;</p>\n\n\n\n<p>For more resources, check out the <a href=\"https://docs.nvidia.com/networking-ethernet-software/cumulus-linux/Layer-2/Multi-Chassis-Link-Aggregation-MLAG/\">NVIDIA Cumulus Linux Multi-Chassis Link Aggregation\u2013MLAG configuration guide</a>.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>In today\u2019s data center, there are many ways to achieve system redundancy from a server connected to a fabric. Customers usually seek redundancy to increase service availability (such as achieving end-to-end AI workloads) and find system efficiency using different multihoming techniques. In this post, we discuss the pros and cons of the well-known proprietary multi-chassis &hellip; <a href=\"https://developer.nvidia.com/blog/comparing-solutions-for-boosting-data-center-redundancy/\">Continued</a></p>\n", "protected": false}, "author": 1877, "featured_media": 65833, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1270163", "discourse_permalink": "https://forums.developer.nvidia.com/t/comparing-solutions-for-boosting-data-center-redundancy/268018", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [852, 1205], "tags": [1634, 453, 2365, 2377], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/05/taboola-data-center-featured.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-ir7", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70873"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1877"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=70873"}], "version-history": [{"count": 21, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70873/revisions"}], "predecessor-version": [{"id": 71286, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70873/revisions/71286"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/65833"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=70873"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=70873"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=70873"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 71033, "date": "2023-09-28T13:37:48", "date_gmt": "2023-09-28T20:37:48", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=71033"}, "modified": "2023-10-19T12:05:59", "modified_gmt": "2023-10-19T19:05:59", "slug": "preventing-health-data-leaks-with-federated-learning-using-nvidia-flare", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/preventing-health-data-leaks-with-federated-learning-using-nvidia-flare/", "title": {"rendered": "Preventing Health Data Leaks with Federated Learning Using NVIDIA FLARE"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p><a href=\"https://www.theverge.com/2021/12/8/22822202/health-data-leaks-hacks\">More than 40 million people had their health data leaked in 2021</a>, and the trend is not optimistic.</p>\n\n\n\n<p>The key goal of federated learning and analytics is to perform data analytics and machine learning without accessing the raw data of the remote sites. That\u2019s the data you don\u2019t own and are not supposed to access directly. But how can you make this happen with a higher degree of confidence?</p>\n\n\n\n<p>Imagine a siloed federated learning scenario with a biotech company collaborating with a network of hospitals. They\u2019re collaborating on an improved lung cancer detection model based on CT scans of images stored locally in local infrastructure.</p>\n\n\n\n<p>Both the aggregator and the biotech data scientists are not permitted to access images directly or download them. They are only permitted to perform federated learning, training, and validation of remote models and to build better-aggregated models, which are then shared with all hospitals for improved generalization and better detection accuracy.</p>\n\n\n\n<p>The goal of data protection seems to be obvious at first. It\u2019s a question of permissions, roles, and maybe some encryption here and there. Unfortunately, it\u2019s not as easy as it might seem.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"618\" height=\"327\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-configuration.jpg\" alt=\"The diagram shows how the NVFlare server connects to clients at multiple hospitals to access CT data.\" class=\"wp-image-71042\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-configuration.jpg 618w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-configuration-300x159.jpg 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-configuration-179x95.jpg 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-configuration-500x265.jpg 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-configuration-160x85.jpg 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-configuration-362x192.jpg 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-configuration-208x110.jpg 208w\" sizes=\"(max-width: 618px) 100vw, 618px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. Configuration of the NVIDIA FLARE server</em></figcaption></figure></div>\n\n\n<h2 class=\"wp-block-heading\"><a></a>Federated privacy defaults</h2>\n\n\n\n<p>Federated learning solutions tend to focus on the following:</p>\n\n\n\n<ul>\n<li>Transmission channel security</li>\n\n\n\n<li>Point-to-point trust (using certificates)</li>\n\n\n\n<li>Efficiency of the workflows</li>\n\n\n\n<li>Support for many existing algorithms</li>\n</ul>\n\n\n\n<p>All these reduce the risk of inference of the raw data from the model itself.</p>\n\n\n\n<p>However, most of the products and publications omit the important threat of a too-curious data scientist. Many products, by design or default, prioritize the near-absolute freedom of data processing by enabling external data scientists to send any queries or operations against remote data.</p>\n\n\n\n<p>This is a perfectly acceptable setup for networks with virtually unlimited trust between the participants or whenever no sensitive data is being used. For instance, the network might be used for demonstration purposes or everything could happen within the boundaries of the data-owner organization.</p>\n\n\n\n<p>This is how NVIDIA FLARE works by default when you want to use custom training and validation code.</p>\n\n\n\n<p>No matter what encryption you use, how strong the transmission channel security guarantees are, or how up-to-date all the systems are on component vulnerabilities, when you permit data scientists to send any queries or code against remote data, you cannot guarantee data leakage protection.</p>\n\n\n\n<p>On the contrary, you are fully dependent on trust levels for individuals or contracts. Or, you could worry later by analyzing logs of the operations and queries executed against the data that you don\u2019t own in a federated network.</p>\n\n\n\n<p>One or more data scientists may one day abandon honesty. Or, the damage could be accidental instead of malicious. <a href=\"https://www.statista.com/statistics/1376346/data-loss-via-insiders-companies-worldwide/\">Market data</a> shows that the majority of <a href=\"https://www.businesswire.com/news/home/20210713005123/en/94-Of-Organizations-Have-Suffered-Insider-Data-Breaches-Egress-Research-Reveals\">data attacks are coming from the inside</a>. Unfortunately, <a href=\"https://www.idwatchdog.com/insider-threats-and-data-breaches\">inside threats are also on the rise</a>.</p>\n\n\n\n<p>Proper employee education, contract clauses, trust, privacy awareness, and work ethics are important but you should provide much stronger guarantees using technical measures.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><a></a>What to do about it</h2>\n\n\n\n<p>Data owners should be in full control: who does what when against what data.</p>\n\n\n\n<p>Logging all data-related operations is often promised as a solution by multiple product vendors. Well, after the potential damage of the data leak is done, it\u2019s too late. You must be proactive and prevent such things during the design phase.</p>\n\n\n\n<p>What about existing permission systems? In the case of NVIDIA FLARE, it is either on or off, enabling remote data scientists to execute any jobs on remote sites (local policies). Also, the biotech administration can\u2019t manage those permissions centrally, as they would be able to override local policies remotely.</p>\n\n\n\n<p>Other solutions opt for binary Docker images pushed from a central repository to remote sites (hospitals), based on the trust that whatever is there can be trusted. This practically eliminates the data owners from the acceptance process, as they can only trust the closed box of the image. Technically, they could download the image, mount it, and review files but it\u2019s impractical at scale.</p>\n\n\n\n<p>There\u2019s a more practical approach available.</p>\n\n\n\n<h2 class=\"wp-block-heading\"><a></a>Step up your data protection game using NVIDIA FLARE 2.3.2</h2>\n\n\n\n<p>Here\u2019s how to lower the risk of data leakage significantly with all its consequences, both financial and reputational. You can deliver on the promise of data protection, which is a key element of federated learning and analytics using the latest features introduced in NVIDIA FLARE 2.3.2, as a result of our fruitful collaboration.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><a></a>Job acceptance and rejection requirements</h3>\n\n\n\n<p>You need a solution that enables data owners to review the code to be executed against their data before it happens. Practically, in NVIDIA FLARE, it means Python code implementing the trainer, validation, and federated statistics plus configuration settings.</p>\n\n\n\n<p>Data owners should be able to review and accept or reject the code themselves or use trusted third-party reviewers. Nothing should happen against data without the explicit acceptance of the data owner.</p>\n\n\n\n<p>No job code should be changed from the previously accepted code to malicious code overnight. It should be rejected because its contents have changed and it must be re-reviewed and re-accepted.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><a></a>Solution</h3>\n\n\n\n<p>NVIDIA FLARE 2.3.2 delivers enablement of custom event handlers that perform actions to enable the components to be created at the site and controlled by the site.</p>\n\n\n\n<p>But why object creation? Can&#8217;t you just focus on the execution?</p>\n\n\n\n<p>Because too-curious data scientists could easily inject the code into object initialization (constructor), object creation is essential. Act as early as possible to prevent the code that data owners don\u2019t want from running against their data.</p>\n\n\n\n<p>The following simplified flow is the default:</p>\n\n\n\n<ul>\n<li>A central server controlled by external data scientists submits jobs to clients.</li>\n\n\n\n<li>Clients schedule and execute those jobs.</li>\n\n\n\n<li>If the code contains uploading data to the cloud, virtually anything that Python permits is executed.</li>\n\n\n\n<li>Even worse, the code may change with each job submission and it won\u2019t be detected or prevented from execution.</li>\n</ul>\n\n\n\n<p>Jobs are sent from the orchestration node to local nodes for execution. They contain code and configuration.</p>\n\n\n\n<p>After the federated network is built using the default NVIDIA FLARE configuration, there is unconditional trust in external data scientists by data owners. They are then permitted to submit jobs with local policies.</p>\n\n\n\n<p>After the change, with a custom implementation:</p>\n\n\n\n<ul>\n<li>A central server controlled by external data scientists submits jobs to clients.</li>\n\n\n\n<li>A data owner reviews the job code and determines if it\u2019s acceptable from the data leakage risk perspective.</li>\n\n\n\n<li>If the code is approved, the hash is added to the list of accepted hashes.</li>\n\n\n\n<li>The job code (hash, signature) is checked locally at the site against the list of accepted hashes of jobs.</li>\n\n\n\n<li>The job is executed on the client and results are returned to the server.</li>\n</ul>\n\n\n\n<p>Here&#8217;s more detail about how the job workflow changes.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><img decoding=\"async\" loading=\"lazy\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-job-workflow-federated-learning-1.png\" alt=\"Workflow diagram highlights the first job being sent from the BioTech orchestration node to the first hospital node. \" class=\"wp-image-71239\" width=\"752\" height=\"320\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-job-workflow-federated-learning-1.png 1002w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-job-workflow-federated-learning-1-300x128.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-job-workflow-federated-learning-1-625x266.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-job-workflow-federated-learning-1-179x76.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-job-workflow-federated-learning-1-768x327.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-job-workflow-federated-learning-1-645x274.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-job-workflow-federated-learning-1-500x213.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-job-workflow-federated-learning-1-160x68.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-job-workflow-federated-learning-1-362x154.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvflare-server-job-workflow-federated-learning-1-259x110.png 259w\" sizes=\"(max-width: 752px) 100vw, 752px\" /><figcaption class=\"wp-element-caption\"><em>Figure 2. Federated learning network with full local trust</em> </figcaption></figure></div>\n\n\n<p>Figure 2 shows a federated learning network consisting of a BioTech orchestration node and three hospital nodes. The same federated training job is sent from the orchestration node for the local nodes. The job is not even created to prevent any malicious code as part of the initialization or constructor of the job object.</p>\n\n\n\n<p>Figure 3 shows the flow of job acceptance and execution using a new type of event and event handler.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/threat-model-nvflare-1.png\"><img decoding=\"async\" loading=\"lazy\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/threat-model-nvflare-1.png\" alt=\"Workflow diagram for job 1 showing job acceptance and rejection to prevent data leaks.\" class=\"wp-image-71193\" width=\"807\" height=\"520\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/threat-model-nvflare-1.png 1076w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/threat-model-nvflare-1-300x193.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/threat-model-nvflare-1-625x403.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/threat-model-nvflare-1-179x115.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/threat-model-nvflare-1-768x495.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/threat-model-nvflare-1-645x415.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/threat-model-nvflare-1-466x300.png 466w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/threat-model-nvflare-1-140x90.png 140w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/threat-model-nvflare-1-362x233.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/threat-model-nvflare-1-171x110.png 171w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/threat-model-nvflare-1-1024x660.png 1024w\" sizes=\"(max-width: 807px) 100vw, 807px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 3. Job acceptance and execution flow with data protection</em></figcaption></figure></div>\n\n\n<h3 class=\"wp-block-heading\"><a></a>Job code acceptance strategies</h3>\n\n\n\n<p>Thanks to the open event\u2013based model delivered in NVIDIA FLARE 2.3.2, it is possible to implement any suitable code verification strategy. Such strategies must always be designed, defined, and agreed upon in a federated network and then deployed on each node (a client, such as a hospital).</p>\n\n\n\n<p>For demonstration purposes, you can compare the code content hash against the accepted code stored in a different directory.</p>\n\n\n\n<p>For more real-world, enterprise-grade scenarios, you can also provide implementations based on digital signatures of the code and even co-signatures provided by the third party trusted by data owners. This is independent of biotech performing the federated training.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><a></a>Code example</h3>\n\n\n\n<p>NVIDIA FLARE raises the BEFORE_BUILD_COMPONENT event before a new component (that is, a job) is instantiated. All you must do is write the event handler to analyze the code and determine if it was accepted. There\u2019s no turnkey solution for that, as different federated networks may require different strategies. The following code example demonstrates such a handler. For demonstration purposes, the example only focuses on a subset of jobs.</p>\n\n\n<div class=\"wp-block-syntaxhighlighter-code \"><pre class=\"brush: cpp; title: ; notranslate\" title=\"\">\nfocuses on a subset of jobs.\ndef handle_event(self, event_type: str, fl_ctx: FLContext):\n    if event_type == EventType.BEFORE_BUILD_COMPONENT:\n       \n        # scanning only too curious data scientist jobs\n        if self.playground_mode:\n            meta = fl_ctx.get_prop(FLContextKey.JOB_META)\n            log.info(f&quot;meta: {meta}&quot;)\n            if not &quot;too-curious-data-scientist&quot; in meta&#91;&quot;name&quot;]:\n                return\n           \n        workspace: Workspace = fl_ctx.get_prop(key=ReservedKey.WORKSPACE_OBJECT) \n        job_id = fl_ctx.get_job_id()\n       \n        log.debug(fl_ctx.get_prop(FLContextKey.COMPONENT_CONFIG))\n        log.debug(f&quot;Run id in filter: &quot; + job_id)\n        log.debug(f&quot;rootdir: {workspace.get_root_dir()}, app_config_dir: {workspace.get_app_config_dir(job_id)}, app_custom_dir: {workspace.get_app_custom_dir(job_id)}&quot; )\n       \n        #making sure that approved_configs hash set is up to date (it's possible to update )\n        self.populate_approved_hash_set(os.path.join(workspace.get_root_dir(), self.approved_config_directory_name))\n        log.debug(f&quot;Approved hash list contains: {len(self.approved_hash_set)} items&quot;)\n       \n        # check if client configuration json is approved (job configuration)\n        current_hash = self.hash_file(os.path.join(workspace.get_app_config_dir(job_id), JobConstants.CLIENT_JOB_CONFIG))\n        if current_hash in self.approved_hash_set:\n            log.info(f&quot;Client job configuration in approved list! with hash {current_hash}&quot;)\n        else:\n            log.error(f&quot;Client job configuration not in approved list! with hash {current_hash}&quot;)\n            log.error(&quot;Not approved job configuration! Throwing UnsafeComponentError!&quot;)\n            raise UnsafeComponentError(&quot;Not approved job configuration! Killing workflow&quot;)\n       \n        # check if all classes added to custom directory are approved\n        job_custom_classes = list(Path(os.path.join(workspace.get_app_custom_dir(job_id))).rglob(&quot;*.py&quot;))\n        for current_class_file in job_custom_classes:\n            current_class_file_hash = self.hash_file(current_class_file)\n            if current_class_file_hash in self.approved_hash_set:\n                log.info(f&quot;Custom class {current_class_file} in approved list!&quot;)\n            else:\n                log.error(f&quot;Class {current_class_file} not in approved list!&quot;)\n                log.error(&quot;Not approved job! Throwing UnsafeComponentError!&quot;)\n                raise UnsafeComponentError(f&quot;Class {current_class_file} not in approved list! with hash {current_class_file_hash}. Not approved job! Killing workflow&quot;)\n</pre></div>\n\n\n<p>As we demonstrated earlier, all the required contextual data is provided by NVIDIA FLARE to be able to perform required actions such as finding the custom code files, calculating their hashes, and so on.</p>\n\n\n\n<h3 class=\"wp-block-heading\"><a></a>There\u2019s more</h3>\n\n\n\n<p>This does not solve all the problems related to data protection. However, in all the scenarios with data owners having limited trust for the remote data scientists training models on their data without seeing it, addressing this problem is imperative.</p>\n\n\n\n<p>While this feature is not a definitive fail-safe measure against malicious users, it provides an additional layer of protection. It empowers nodes and fosters collaborative research through shared responsibility.</p>\n\n\n\n<p>Next, consider focusing on other important areas, such as the following:</p>\n\n\n\n<ul>\n<li>Model inference attacks</li>\n\n\n\n<li>Differential privacy</li>\n\n\n\n<li>Transmission channel security</li>\n\n\n\n<li>Output filters</li>\n</ul>\n\n\n\n<h2 class=\"wp-block-heading\"><a></a>Summary</h2>\n\n\n\n<p>The principle of defense in depth in the case of federated learning and analytics makes it necessary to protect the data owner from possibly malicious remote code sent by external data scientists. In the case of truly federated scenarios, when there\u2019s no full trust relationship between data owners and remote scientists, this is not optional.</p>\n\n\n\n<p>The promise of remote data inaccessibility doesn\u2019t deliver itself; you must empower data owners. It\u2019s not guaranteed by default.</p>\n\n\n\n<p>In this post, we demonstrated how to address this important threat using <a href=\"https://developer.nvidia.com/flare\">NVIDIA FLARE 2.3.2</a> to enable better data protection and build more secure federated learning networks today and in the future.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>More than 40 million people had their health data leaked in 2021, and the trend is not optimistic. The key goal of federated learning and analytics is to perform data analytics and machine learning without accessing the raw data of the remote sites. That\u2019s the data you don\u2019t own and are not supposed to access &hellip; <a href=\"https://developer.nvidia.com/blog/preventing-health-data-leaks-with-federated-learning-using-nvidia-flare/\">Continued</a></p>\n", "protected": false}, "author": 1883, "featured_media": 71073, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1269824", "discourse_permalink": "https://forums.developer.nvidia.com/t/preventing-health-data-leaks-with-federated-learning-using-nvidia-flare/267936", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [1464, 696, 1205], "tags": [2842, 453, 2916], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-flare-featured.png", "jetpack_shortlink": "https://wp.me/pcCQAL-itH", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71033"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1883"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=71033"}], "version-history": [{"count": 11, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71033/revisions"}], "predecessor-version": [{"id": 71249, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71033/revisions/71249"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/71073"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=71033"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=71033"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=71033"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 71196, "date": "2023-09-28T08:25:49", "date_gmt": "2023-09-28T15:25:49", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=71196"}, "modified": "2023-11-24T10:50:56", "modified_gmt": "2023-11-24T18:50:56", "slug": "nvidia-h100-system-sets-records-for-hpc-and-generative-ai-financial-risk-calculations", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/nvidia-h100-system-sets-records-for-hpc-and-generative-ai-financial-risk-calculations/", "title": {"rendered": "NVIDIA H100 System for HPC and Generative AI Sets Record for Financial Risk Calculations"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p><a href=\"https://www.nvidia.com/en-us/glossary/data-science/generative-ai/\">Generative AI</a> is taking the world by storm, from large language models (LLMs) to generative pretrained transformer (GPT) models to diffusion models. NVIDIA is uniquely positioned to accelerate generative AI workloads, but also those for data processing, analytics, <a href=\"https://www.nvidia.com/en-us/glossary/high-performance-computing/\">high-performance computing</a> (HPC), quantitative financial applications, and more. NVIDIA offers a one-stop solution for diverse workload needs.<br><br>In quantitative applications for financial risk management, for example, NVIDIA GPUs offer incredible speed with great efficiency. <a href=\"https://www.nvidia.com/en-us/data-center/h100/\">NVIDIA H100 Tensor Core GPUs</a> were featured in a stack that set several records in a recent <a href=\"https://www.stacresearch.com/news/NVDA230721\">STAC-A2 audit</a>.\u00a0</p>\n\n\n\n<h2 class=\"wp-block-heading\">New STAC-A2 derivative risk results performed on NVIDIA H100s with HPE ProLiant XL675d</h2>\n\n\n\n<p>STAC-A2 is a risk management benchmark created by the Strategic Technology Analysis Center (STAC) Benchmark Council for the assessment of technology stacks used for compute-intensive analytic workloads in finance. Designed by quantitative analysts and technologists from some of the world&#8217;s largest banks, STAC-A2 reports the performance, scaling, quality, and resource efficiency of any technology stack that can handle the workload: Monte Carlo estimation of Heston-based Greeks for path-dependent, multi-asset options with early exercise.</p>\n\n\n\n<p>STAC-A2 is the technology benchmark standard based on financial market risk analysis. The workload can be a proxy extended to price discovery, market risk calculations such as sensitivity Greeks, profit and loss, and value at risk (VaR) in market risk. The benchmark as a proxy can also be extended to counterparty credit risk (CCR)\u00a0workloads such as credit valuation adjustment (CVA) and margin that financial institutions calculate for trading as well as risk management.\u00a0</p>\n\n\n\n<p>Compared to all publicly reported solutions to date, this NVIDIA H100-based solution set numerous performance and efficiency records, including (but not limited to) the following:</p>\n\n\n\n<ul>\n<li>The first sub-10ms warm time (8.9 ms) in the baseline Greeks benchmark.</li>\n\n\n\n<li>A cold time in the baseline Greeks benchmark of 38 ms, more than 3x faster than any previous benchmark.</li>\n\n\n\n<li>The fastest warm (0.51 s) and cold (1.85 s) times in the large Greeks benchmarks.</li>\n\n\n\n<li>The most correlated assets (400) and most paths (310,000,000) simulated in 10 minutes.</li>\n\n\n\n<li>The best energy efficiency (311,045 options/kWh).</li>\n</ul>\n\n\n\n<p>Compared to a solution using 8x NVIDIA A100 SXM4 80GB GPUs, as well as previous generations of the NVIDIA STAC Pack and NVIDIA CUDA, this solution performed as follows:</p>\n\n\n\n<ul>\n<li>10x faster in the cold run of the baseline Greeks benchmark (<em>STAC-A2.\u03b22.GREEKS.TIME.COLD</em>).</li>\n\n\n\n<li>1.38x faster in the warm runs of the baseline Greeks benchmark (<em>STAC-A2.\u03b22.GREEKS.TIME.WARM</em>).</li>\n\n\n\n<li>1.38x faster in the cold run of the large Greeks benchmark (<em>STAC-A2.\u03b22.GREEKS.10-100k-1260TIME.COLD</em>).</li>\n\n\n\n<li>1.4x faster in the warm runs of the large Greeks benchmark (<em>STAC-A2.\u03b22.GREEKS.10-100k-1260TIME.WARM</em>).</li>\n\n\n\n<li>With 10% more energy efficiency for benchmark 7.</li>\n</ul>\n\n\n\n<h2 class=\"wp-block-heading\">Integrated hardware plus software solutions</h2>\n\n\n\n<p>One of the industry\u2019s key concerns is risk calculation, which relies heavily on the latest technologies for real-time calculations and instant decision-making for trading and risk management. </p>\n\n\n\n<p>The HPE ProLiant XL675d Gen10 Plus server supports a dense node strategy for financial HPC, enabling up to 10 NVIDIA GPUs to efficiently populate a single HPC server. With this type of dense node, a compute farm for portfolio risk calculations can be realized with far fewer nodes achieving higher performance with lower operational costs for real-world calculations such as price discovery, market risk (such as VaR), and counterparty risk (such as CVA).</p>\n\n\n\n<p>In areas such as CVA, such setups have been shown to reduce the number of nodes from 100 to 4 in simulation\u2013 and compute-intensive calculations (separately from STAC benchmarking).</p>\n\n\n\n<p>This dense node solution enables an exciting strategy of scaling up with NVIDIA GPUs for a reduced number of nodes. It enables the highest performance at the lowest operating cost and the smallest data center footprint. The solutions can be extended to other workloads, such as AI language inference and backtesting as needed for a scaling strategy with such dense servers.</p>\n\n\n\n<p>In addition to the hardware, NVIDIA provides all the key software component layers. This offers multiple options to developers, including the language of choice such as CUDA C++.</p>\n\n\n\n<p>In calculations that are typically developed for fast run times, this implementation was developed on CUDA 12.0. The implementation uses the highly optimized libraries delivered with CUDA: </p>\n\n\n\n<ul>\n<li><a href=\"https://developer.nvidia.com/cublas\" data-type=\"link\" data-id=\"https://developer.nvidia.com/cublas\">cuBLAS</a>: The GPU-enabled implementation of the linear algebra package BLAS.</li>\n\n\n\n<li><a href=\"https://developer.nvidia.com/curand\" data-type=\"link\" data-id=\"https://developer.nvidia.com/curand\">cuRAND</a>: A parallel and efficient GPU implementation of random number generators.\u00a0</li>\n</ul>\n\n\n\n<p>The different components of the implementation are designed in a modular and maintainable framework using object-oriented programming. All floating-point operations were conducted in IEEE-754 double precision (64 bits). The implementation was developed using the various tools provided by NVIDIA to help debug and profile CUDA code: </p>\n\n\n\n<ul>\n<li><a href=\"https://developer.nvidia.com/nsight-systems\">NVIDIA Nsight Systems</a> for timeline profiling</li>\n\n\n\n<li><a href=\"https://developer.nvidia.com/nsight-compute\">NVIDIA Nsight Compute</a> for kernel profiling</li>\n\n\n\n<li><a href=\"https://developer.nvidia.com/compute-sanitizer\">NVIDIA Compute Sanitizer</a> and <a href=\"https://docs.nvidia.com/cuda/cuda-gdb/index.html\">CUDA-GDB</a> for debugging</li>\n</ul>\n\n\n\n<h2 class=\"wp-block-heading\">Solution for risk HPC and AI convergence</h2>\n\n\n\n<p>NVIDIA H100 GPUs are an integral part of the NVIDIA data center platform. Built for AI, HPC, and data analytics, the platform accelerates over 4,000 applications. It is available everywhere, from data center to edge, delivering both dramatic performance gains and cost-saving opportunities with the aim of accelerating \u201cevery workload, everywhere.\u201d&nbsp;</p>\n\n\n\n<p>The NVIDIA H100 PCIe GPU incorporates groundbreaking technology, such as the NVIDIA Hopper architecture, with a theoretical peak performance of 51 TFLOPS for single-precision and 26 TFLOPS for double-precision calculations. It uses 14,592 CUDA cores, plus 456 fourth-generation Tensor Core modules, which can deliver a theoretical peak performance of 1,513 TFLOPS for BF16 and 51 TFLOPS for FP64 matrix calculations.</p>\n\n\n\n<p>For HPC applications, the NVIDIA H100 almost triples the theoretical floating-point operations per second (FLOPS) of FP64 compared to the NVIDIA A100. It also adds dynamic programming instructions (DPX) to help achieve better performance. NVIDIA H100 GPUs feature fourth-generation Tensor Cores and the Transformer Engine with FP8 precision.&nbsp;</p>\n\n\n\n<p>With second-generation Multi-Instance GPU (MIG), built-in NVIDIA confidential computing, and <a href=\"https://www.nvidia.com/en-us/data-center/nvlink/\">NVIDIA NVLink</a>, the NVIDIA H100 aims to securely accelerate workloads for every data center, from enterprise to exascale. The NVIDIA GPUs in SXM form share a switched NVLink 4.0 interconnect, providing high-speed GPU-to-GPU communication bandwidth.&nbsp;</p>\n\n\n\n<p>The H100 PCIe Gen 4 configuration used in this SUT provides most of the specified capabilities of H100 SXM5 GPUs in just 350 watts of thermal design power (TDP). This configuration can optionally use the NVLink bridge for connecting up to two GPUs for applications like deep learning in AI that are coded to take advantage of inter-GPU communications. (The STAC-A2 Pack does not use these fabrics.)</p>\n\n\n\n<h2 class=\"wp-block-heading\">Summary</h2>\n\n\n\n<p>Whether at a single-server scale or in larger scaling systems optimized for today\u2019s most demanding HPC plus AI workloads, NVIDIA is uniquely positioned to accelerate workloads ranging from HPC quantitative financial applications and data processing to analytics and generative AI. In addition to risk calculations, organizations are converging NLP with generative AI, feeding inputs to quantitative calculations. </p>\n\n\n\n<p>This is an active area of work, wherein the convergence of HPC and AI is happening as financial firms work on big-picture solutions combining various modeling techniques including HPC quantitative finance, machine learning (ML), and AI with neural net as well as NLP with generative AI. This enables firms to drive multiple complex business needs with converged HPC plus AI solutions that are increasingly a result of accelerated AI adoption, combining workloads for unique solution needs in the financial industry.&nbsp;</p>\n\n\n\n<p>For more information, see <a href=\"https://community.hpe.com/t5/alliances/hpe-amp-nvidia-financial-services-solution-sets-new-records-in/ba-p/7197388\">HPE and NVIDIA Financial Services Solution, Powered by NVIDIA, Sets New Records in Performance</a>.\u00a0</p>\n\n\n\n<p><a href=\"mailto:financialservices@nvidia.com\">Reach out to NVIDIA Financial Services</a> with questions as you evaluate or apply accelerated compute to your critical business problems. Read the full report, <a href=\"https://www.stacresearch.com/news/NVDA230721\">CUDA 12.0 with 8x NVIDIA H100 PCIe 80GiB GPUs in an HPE ProLiant XL675d Gen10 Plus Server</a>.&nbsp;</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Generative AI is taking the world by storm, from large language models (LLMs) to generative pretrained transformer (GPT) models to diffusion models. NVIDIA is uniquely positioned to accelerate generative AI workloads, but also those for data processing, analytics, high-performance computing (HPC), quantitative financial applications, and more. NVIDIA offers a one-stop solution for diverse workload needs. &hellip; <a href=\"https://developer.nvidia.com/blog/nvidia-h100-system-sets-records-for-hpc-and-generative-ai-financial-risk-calculations/\">Continued</a></p>\n", "protected": false}, "author": 981, "featured_media": 71202, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1269706", "discourse_permalink": "https://forums.developer.nvidia.com/t/nvidia-h100-system-sets-records-for-hpc-and-generative-ai-financial-risk-calculations/267913", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [852, 696, 3110], "tags": [453, 1940, 2779, 608], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-gpu.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-iwk", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71196"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/981"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=71196"}], "version-history": [{"count": 23, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71196/revisions"}], "predecessor-version": [{"id": 74296, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71196/revisions/74296"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/71202"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=71196"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=71196"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=71196"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 71094, "date": "2023-09-27T09:00:00", "date_gmt": "2023-09-27T16:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=71094"}, "modified": "2024-01-10T10:07:54", "modified_gmt": "2024-01-10T18:07:54", "slug": "free-course-essentials-of-developing-omniverse-kit-applications", "status": "publish", "type": "post", "link": "https://courses.nvidia.com/courses/course-v1:DLI+S-OV-11+V1/?nvid=nv-int-tblg-698236", "title": {"rendered": "Free Course: Essentials of Developing Omniverse Kit Applications"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>Take this free self-paced course to learn how to leverage NVIDIA Omniverse Kit to easily build apps on the Omniverse platform.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Take this free self-paced course to learn how to leverage NVIDIA Omniverse Kit to easily build apps on the Omniverse platform.</p>\n", "protected": false}, "author": 1115, "featured_media": 71097, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "", "discourse_permalink": "", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "https://courses.nvidia.com/courses/course-v1:DLI+S-OV-11+V1/?nvid=nv-int-tblg-698236", "_links_to_target": "_blank"}, "categories": [503], "tags": [2964, 3366, 1935, 453], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dli-new-self-paced-omniverse-essentials-blog-1920x1080-1.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-iuG", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71094"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1115"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=71094"}], "version-history": [{"count": 3, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71094/revisions"}], "predecessor-version": [{"id": 71098, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71094/revisions/71098"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/71097"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=71094"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=71094"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=71094"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 71099, "date": "2023-09-26T17:00:00", "date_gmt": "2023-09-27T00:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=71099"}, "modified": "2023-11-14T10:58:58", "modified_gmt": "2023-11-14T18:58:58", "slug": "enabling-the-worlds-first-gpu-accelerated-5g-open-ran-for-ntt-docomo-with-nvidia-aerial", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/enabling-the-worlds-first-gpu-accelerated-5g-open-ran-for-ntt-docomo-with-nvidia-aerial/", "title": {"rendered": "Enabling the World\u2019s First GPU-Accelerated 5G Open RAN for NTT DOCOMO with NVIDIA Aerial"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>NVIDIA, working with Fujitsu and Wind&nbsp;River, has enabled NTT DOCOMO to launch the first GPU-accelerated commercial Open RAN 5G service in its network in Japan. This makes it the first-ever telco in the world to deploy a GPU-accelerated commercial 5G network.</p>\n\n\n\n<p>The <a href=\"https://blogs.nvidia.com/blog/2023/09/26/ntt-docomo-gpu-accelerated-5g-network/\" target=\"_blank\" rel=\"noreferrer noopener\">announcement</a> is a major milestone as the telecom industry strives to address the multi-billion-dollar problem of driving improvements in performance, total cost of ownership (TCO), and energy efficiency. The solution unlocks the flexibility, scalability, and supply chain diversity promise of Open RAN.</p>\n\n\n\n<p>DOCOMO and its partners <a href=\"https://www.docomo.ne.jp/english/info/media_center/pr/2023/0927_00.html\" target=\"_blank\" rel=\"noreferrer noopener\">confirmed</a> that the solution is based on Fujitsu\u2019s virtualized centralized unit (vCU) and virtualized distributed unit (vDU), the <a href=\"https://developer.nvidia.com/aerial-sdk/\" target=\"_blank\" rel=\"noreferrer noopener\">NVIDIA Aerial</a> platform, and Wind River\u2019s distributed cloud platform.</p>\n\n\n\n<p>The 5G Open RAN solution is the first 5G vRAN for telecom commercial deployment using the NVIDIA Aerial platform. The platform brings together the NVIDIA Aerial vRAN stack for 5G, AI frameworks, accelerated compute infrastructure, and long-term software support and maintenance. It delivers innovative and transformational new capabilities for telco operators.</p>\n\n\n\n<h2 class=\"wp-block-heading\">TCO and energy efficiency benefits</h2>\n\n\n\n<p>Working with vendors <a href=\"https://www.fujitsu.com/us/products/network/?utm_source=li&amp;utm_medium=soc\">Fujitsu</a> and <a href=\"https://www.windriver.com/studio/operator/cloud-platform\">Wind River</a>, the new deployment uses the NVIDIA Aerial platform to deliver high performance, high cell density, and flexibility to DOCOMO\u2019s 5G network, bringing better utilization of its network, lower TCO, and reduced power consumption.</p>\n\n\n\n<p>DOCOMO notes that, when compared to its standard network based on a proprietary solution, this new solution reduces TCO by up to 30%, improves network design utilization by up to 50%, and reduces power consumption at base stations by up to 50%.</p>\n\n\n\n<p>As of July 2023, DOCOMO serves over 22M 5G subscribers, from 20K+ base stations, with 5G coverage in over 815 cities. It uses 29 types of radio units (RUs) from four vendors and eight types of CUs from three vendors. The introduction of vRAN is expected to expand the capacity and coverage of the 5G network.</p>\n\n\n\n<p>While the ability to mix and match products from different vendors promises improvements in flexibility and scalability from Open RAN networks, it poses two major concerns for operators:</p>\n\n\n\n<ul>\n<li>First, it makes it challenging to bring out the best performance from the different vendor products.</li>\n\n\n\n<li>Second, there are often technical issues that are only found at interoperability testing, which any operator deploying Open RAN must deal with.</li>\n</ul>\n\n\n\n<h2 class=\"wp-block-heading\">NVIDIA, Fujitsu, Wind River 5G Open RAN partnership</h2>\n\n\n\n<p>DOCOMO launched <a href=\"https://ssw.web.docomo.ne.jp/orex/en/#orex\">OREX</a> as an Open RAN service brand to address the challenges facing Open RAN. After the project was launched in February 2021, Fujitsu, NVIDIA, and Wind River worked together under OREX to develop the 5G vRAN solution, which is based on Fujitsu\u2019s vDU and vCU.</p>\n\n\n\n<p>The solution uses the following components:</p>\n\n\n\n<ul>\n<li>Commercial-off-the-shelf (COTS) servers</li>\n\n\n\n<li>Wind River distributed cloud platform</li>\n\n\n\n<li>Fujitsu\u2019s 5G vRAN software</li>\n\n\n\n<li>NVIDIA Aerial vRAN stack</li>\n\n\n\n<li>NVIDIA Converged Accelerator</li>\n</ul>\n\n\n\n<p>This is the first vendor consortium to deliver a commercial live 5G vRAN that meets NTT DOCOMO\u2019s performance and interoperability requirements.</p>\n\n\n\n<p>The NVIDIA Aerial platform includes NVIDIA Aerial vRAN stack software for the physical (PHY) layer 1 (L1), and NVIDIA Converged Accelerator with its combined data processing unit (DPU) and GPU for hardware acceleration of the computationally intense L1 workload. This makes it the world\u2019s first DPU and GPU-accelerated (that is, NVIDIA-accelerated) 5G Open RAN to be deployed commercially to deliver a scalable, flexible, and cost-efficient network.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"751\" height=\"601\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-accelerated-vran-stack.png\" alt=\"Diagram shows the software stack of the Fujitsu DU, NVIDIA Aerial L1, and Wind River Studio Cloud platform. The hardware stack includes pictures of a COTS server and NVIDIA Converged Accelerator next to the GPU, DPU, and CPU boxes.\" class=\"wp-image-71101\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-accelerated-vran-stack.png 751w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-accelerated-vran-stack-300x240.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-accelerated-vran-stack-625x500.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-accelerated-vran-stack-144x115.png 144w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-accelerated-vran-stack-645x516.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-accelerated-vran-stack-375x300.png 375w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-accelerated-vran-stack-112x90.png 112w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-accelerated-vran-stack-362x290.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-accelerated-vran-stack-137x110.png 137w\" sizes=\"(max-width: 751px) 100vw, 751px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. NVIDIA-accelerated 5G vRAN stack deployed by NTT DOCOMO</em></figcaption></figure></div>\n\n\n<h2 class=\"wp-block-heading\">NVIDIA Aerial platform: Building blocks for wireless innovation</h2>\n\n\n\n<p>NVIDIA is driving innovation in the telecom industry with a portfolio of wireless frameworks, AI frameworks, and accelerated computing infrastructure. This enables the development of high-performance, fully software-defined, and AI-native networks with cloud economics (Figure 2).</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full is-resized\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ran-innovation-benefits.png\"><img decoding=\"async\" loading=\"lazy\" width=\"1844\" height=\"671\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ran-innovation-benefits.png\" alt=\"Diagram lists benefits for high-performance, AI-native, fully software-defined 5G networks with cloud economics: faster and flexible deployment, ease of management, open platform, highest spectral efficiency, and more.\" class=\"wp-image-71102\" style=\"width:922px;height:336px\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ran-innovation-benefits.png 1844w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ran-innovation-benefits-300x109.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ran-innovation-benefits-625x227.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ran-innovation-benefits-179x65.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ran-innovation-benefits-768x279.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ran-innovation-benefits-1536x559.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ran-innovation-benefits-645x235.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ran-innovation-benefits-500x182.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ran-innovation-benefits-160x58.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ran-innovation-benefits-362x132.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ran-innovation-benefits-302x110.png 302w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/ran-innovation-benefits-1024x373.png 1024w\" sizes=\"(max-width: 1844px) 100vw, 1844px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 2. RAN innovation benefits with the NVIDIA full-stack 5G vRAN</em></figcaption></figure></div>\n\n\n<p>&nbsp;The accelerated computing infrastructure is made up of a combination of CPU, DPU, and GPU, together with a range of NVIDIA-certified COTS hardware servers.</p>\n\n\n\n<p>NVIDIA Aerial is the platform with software, hardware, and support for delivering innovation in the wireless market segment. It brings together the NVIDIA Aerial vRAN stack for 5G, AI frameworks, other wireless frameworks, an accelerated compute infrastructure, and long-term software support.</p>\n\n\n\n<p>Thanks to this combination of industry-shaping hardware, software, and the long-term support and maintenance typical for a commercial-grade software stack, this enables new performance thresholds for 5G networks.&nbsp;</p>\n\n\n\n<p>The key components of the platform are as follows:</p>\n\n\n\n<ul>\n<li>Software: NVIDIA Aerial vRAN stack</li>\n\n\n\n<li>Hardware: NVIDIA Accelerated Computing</li>\n\n\n\n<li>Carrier-grade support</li>\n</ul>\n\n\n\n<h3 class=\"wp-block-heading\">Software: NVIDIA Aerial vRAN stack</h3>\n\n\n\n<p>This is an application framework for building high-performance, 100% software-defined, cloud-native, 5G vRAN, with O-RAN 7.2-x split. The NVIDIA Aerial vRAN stack is highly flexible and scalable and can deliver high performance for the L1.</p>\n\n\n\n<p>NVIDIA Aerial has adopted a GPU-centric approach and relies on two notable subcomponents:</p>\n\n\n\n<ul>\n<li><a href=\"https://developer.nvidia.com/aerial-sdk\">NVIDIA cuBB SDK</a> (CUDA baseband)</li>\n\n\n\n<li><a href=\"https://docs.nvidia.com/doca/sdk/gpunetio-programming-guide/index.html\">NVIDIA DOCA GPUNetIO</a></li>\n</ul>\n\n\n\n<p>cuBB provides GPU-accelerated 5G L1 processing. It delivers high throughput and efficiency by keeping all PHY layer processing within the high-performance GPU memory. The cuBB SDK also includes the 5G L1 high-PHY acceleration library cuPHY, which is optimized for NVIDIA GPUs. cuPHY offers unparalleled scalability by using the GPU\u2019s massive computing capability and a high degree of parallelism.</p>\n\n\n\n<p>NVIDIA DOCA GPUNetIO improves the performance of inline hardware acceleration. It provides optimized I/O and packet processing by exchanging packets directly between GPU memory and the<a href=\"https://developer.nvidia.com/gpudirect\"> </a>DPU using direct memory access (DMA) technology.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><a href=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-aerial-vran-stack.png\"><img decoding=\"async\" loading=\"lazy\" width=\"663\" height=\"404\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-aerial-vran-stack.png\" alt=\"The full stack for NVIDIA Aerial 5G vRAN showing the cuBB SDK, framework libraries, and the toolkit and drivers.\" class=\"wp-image-71103\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-aerial-vran-stack.png 663w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-aerial-vran-stack-300x183.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-aerial-vran-stack-625x381.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-aerial-vran-stack-179x109.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-aerial-vran-stack-645x393.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-aerial-vran-stack-492x300.png 492w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-aerial-vran-stack-148x90.png 148w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-aerial-vran-stack-362x221.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/nvidia-aerial-vran-stack-181x110.png 181w\" sizes=\"(max-width: 663px) 100vw, 663px\" /></a><figcaption class=\"wp-element-caption\"><em>Figure 3. NVIDIA Aerial vRAN stack for complete L1 PHY acceleration</em></figcaption></figure></div>\n\n\n<h3 class=\"wp-block-heading\">Hardware: NVIDIA Accelerated Computing</h3>\n\n\n\n<p>This is the processing engine of the vRAN and is made up of CPUs, DPUs, and GPUs, together with COTS hardware servers.</p>\n\n\n\n<p>The performance of the NVIDIA Aerial vRAN stack, especially the computationally intensive L1, is dependent on the choice of hardware it is deployed on. NVIDIA offers two hardware options for 5G network deployments. Their comparative performance is shown in Table 1 below.</p>\n\n\n\n<ul>\n<li>x86 and <a href=\"https://www.nvidia.com/en-gb/data-center/products/converged-accelerator/\">NVIDIA Converged Accelerator</a> (used in the NTT DOCOMO <a href=\"https://blogs.nvidia.com/blog/2023/09/26/ntt-docomo-gpu-accelerated-5g-network/\" target=\"_blank\" rel=\"noreferrer noopener\">announcement</a>)</li>\n\n\n\n<li><a href=\"https://www.nvidia.com/en-gb/data-center/grace-hopper-superchip/\">NVIDIA Grace Hopper</a> and <a href=\"https://www.nvidia.com/en-us/networking/products/data-processing-unit/\">NVIDIA BlueField DPU</a></li>\n</ul>\n\n\n\n<h4 class=\"wp-block-heading\">x86 and NVIDIA Converged Accelerator</h4>\n\n\n\n<p>This option combines the performance of NVIDIA DPUs and GPUs, together with an x86 CPU server, to deliver maximum performance for the 5G vRAN. This is also the hardware acceleration option in the current DOCOMO deployment.</p>\n\n\n\n<p>The integration of the GPU and DPU brings all front-haul enhanced common public radio interface (eCPRI) data traffic into the GPU without the CPU in the datapath. This is a full inline L1 offload, so the solution achieves high performance by avoiding the back-and-forth of eCPRI data between the CPU and the hardware accelerator in alternative systems across the host PCIe interface.</p>\n\n\n\n<p>After the data is in the GPU, it benefits from the massive parallelism of the GPU architecture to optimize the processing capacity of the base station system. This brings improved RU capacity and processing power, provides a high-quality communications environment, and can handle high-load data processing along with future improvements in antenna technologies.</p>\n\n\n\n<h4 class=\"wp-block-heading\">NVIDIA Grace Hopper and NVIDIA BlueField DPU</h4>\n\n\n\n<p>The NVIDIA Grace Hopper Superchip brings together the NVIDIA Grace CPU, which is based on the Arm architecture, and the high-performance NVIDIA Hopper GPU. The BlueField DPU helps to achieve the same performance from full inline L1 offload in a similar way to NVIDIA Converged Accelerator.</p>\n\n\n\n<p>However, the biggest boost to performance comes from the integration of the CPU and GPU architectures using <a href=\"https://www.nvidia.com/en-gb/data-center/nvlink-c2c/\">NVIDIA NVLink-C2C</a> to deliver a CPU+GPU coherent memory model for accelerated workloads such as 5G vRAN.</p>\n\n\n\n<p>NVIDIA NVLink-C2C is the NVIDIA memory-coherent, high-bandwidth, and low-latency interconnect. It delivers up to 900 GB/s total bandwidth: 7x higher bandwidth than the x16 PCIe Gen5 lanes commonly used in accelerated systems.</p>\n\n\n\n<p>With the NVLink-C2C memory coherency, both CPU and GPU threads can concurrently and transparently access both CPU and GPU resident memory, enabling the RAN to optimize how it handles eCPRI data across CPU and GPU.</p>\n\n\n\n<figure class=\"wp-block-table\"><table><tbody><tr><td class=\"has-text-align-center\" data-align=\"center\"><strong>X86 + NVIDIA Converged Accelerator&nbsp;</strong><br><em>(refer to AX800)</em></td><td class=\"has-text-align-center\" data-align=\"center\"></td><td class=\"has-text-align-center\" data-align=\"center\"><strong>Grace Hopper + BlueField 3&nbsp;</strong><br><em>(refer to GH200)</em></td></tr><tr><td class=\"has-text-align-center\" data-align=\"center\">Up to 20 peak cells of 4T4T = equivalent to 36 Gbps per 2U server</td><td class=\"has-text-align-center\" data-align=\"center\"><strong>Configuration*</strong></td><td class=\"has-text-align-center\" data-align=\"center\">Up to 40 peak cells of 4T4T = equivalent to 72 Gbps per 2U server</td></tr><tr><td class=\"has-text-align-center\" data-align=\"center\">3.2X&nbsp;<br>(36 Gbps)</td><td class=\"has-text-align-center\" data-align=\"center\"><strong>5G Performance*</strong></td><td class=\"has-text-align-center\" data-align=\"center\">6.4X&nbsp;<br>(72 Gbps)</td></tr><tr><td class=\"has-text-align-center\" data-align=\"center\">76X\u00a0<br>(tokens/sec)</td><td class=\"has-text-align-center\" data-align=\"center\"><strong>LLM*&nbsp;</strong><br><strong>(LLAMA 65B)</strong></td><td class=\"has-text-align-center\" data-align=\"center\">284X<br>(tokens/sec)</td></tr><tr><td class=\"has-text-align-center\" data-align=\"center\">1.3X<br>(34 W/Gbps)</td><td class=\"has-text-align-center\" data-align=\"center\"><strong>5G Power Efficiency*</strong></td><td class=\"has-text-align-center\" data-align=\"center\">3.3X<br>(13 W/Gbps)</td></tr><tr><td class=\"has-text-align-center\" data-align=\"center\">1X&nbsp;<br>(PCIE)</td><td class=\"has-text-align-center\" data-align=\"center\"><strong>CPU &#8211; GPU Bandwidth*</strong></td><td class=\"has-text-align-center\" data-align=\"center\">7X\u00a0<br>(C2C)</td></tr></tbody></table><figcaption class=\"wp-element-caption\"><em>* Relative performance is estimated vs X86 5G SKU&nbsp; for 100 MHZ ,4T4R, 4DL/2UL. PCIE Gen5, 2U Server&nbsp;</em><br><br><em>Table 1: Comparative performance of NVIDIA Converged Accelerators vs NVIDIA Grace Hopper for 5G vRAN. Footnote:&nbsp;DOCOMO&#8217;s current deployment is using the X86 + NVIDIA Converged Accelerator option</em>.</figcaption></figure>\n\n\n\n<h3 class=\"wp-block-heading\">Carrier-grade support</h3>\n\n\n\n<p>The NVIDIA Aerial platform provides a full-stack, carrier-grade, hardened, and mature 5G solution with 10 years of long-life support and maintenance for telecommunications operators. This level of carrier-grade support provides assurances of reliability and resilience for telcos for field or commercial deployment using the platform.</p>\n\n\n\n<h2 class=\"wp-block-heading\">OREX: Building out from Japan and beyond</h2>\n\n\n\n<p>The commercial deployment of a 5G Open RAN network by NTT DOCOMO, using the NVIDIA 5G platform, is a major milestone for the telecommunications industry. It showcases the capabilities of GPU-based acceleration for computationally intensive L1 PHY processing.</p>\n\n\n\n<p>This new network comes with improved performance, flexibility, and scalability, plus higher cell density, significant improvements in energy efficiency, and a reduction in TCO. The delivery of this network paves the way for widespread adoption of GPU-based acceleration in cellular RANs.</p>\n\n\n\n<p>DOCOMO and its partners in OREX are working together to promote a multi-vendor, Open RAN\u2013compliant 5G vRAN to the global operator community. The commercial deployment in Japan is in alignment with the vision of OREX, enabling its members to validate their solutions commercially and then promote it to other operators globally.</p>\n\n\n\n<p>NVIDIA continues to work with DOCOMO and other partners to support operators around the world to deploy high-performance, energy-efficient, software-defined, commercial 5G vRAN.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>NVIDIA, working with Fujitsu and Wind&nbsp;River, has enabled NTT DOCOMO to launch the first GPU-accelerated commercial Open RAN 5G service in its network in Japan. This makes it the first-ever telco in the world to deploy a GPU-accelerated commercial 5G network. The announcement is a major milestone as the telecom industry strives to address the &hellip; <a href=\"https://developer.nvidia.com/blog/enabling-the-worlds-first-gpu-accelerated-5g-open-ran-for-ntt-docomo-with-nvidia-aerial/\">Continued</a></p>\n", "protected": false}, "author": 1172, "featured_media": 71106, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1268411", "discourse_permalink": "https://forums.developer.nvidia.com/t/enabling-the-world-s-first-gpu-accelerated-5g-open-ran-for-ntt-docomo-with-nvidia-aerial/267708", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [852, 1205], "tags": [817, 549], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/docomo-open-ran-aerial-featured.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-iuL", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71099"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1172"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=71099"}], "version-history": [{"count": 19, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71099/revisions"}], "predecessor-version": [{"id": 73607, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71099/revisions/73607"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/71106"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=71099"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=71099"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=71099"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 70950, "date": "2023-09-26T10:01:11", "date_gmt": "2023-09-26T17:01:11", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=70950"}, "modified": "2023-10-19T12:06:01", "modified_gmt": "2023-10-19T19:06:01", "slug": "validating-nvidia-drive-sim-radar-models", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/validating-nvidia-drive-sim-radar-models/", "title": {"rendered": "Validating NVIDIA DRIVE Sim Radar Models"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>Sensor simulation is a critical tool to address the gaps in real-world data for autonomous vehicle (AV) development. However, it is only effective if sensor models accurately reflect the physical world.&nbsp;</p>\n\n\n\n<p>Sensors can be either passive, such as cameras\u2014or active, sending out either an electromagnetic wave (lidar, radar) or an acoustic wave (ultrasonic) to generate the sensor output. When modeled in simulation, each modality must be validated against its real-world counterpart.</p>\n\n\n\n<p>In previous posts, we detailed the validation process for camera and lidar models in <a href=\"https://www.nvidia.com/en-us/self-driving-cars/simulation/\">NVIDIA DRIVE Sim</a>. See <a href=\"https://developer.nvidia.com/blog/validating-drive-sim-camera-models/\">Validating NVIDIA DRIVE Sim Camera Models</a> and <a href=\"https://developer.nvidia.com/blog/validating-active-sensors-in-nvidia-drive-sim/\">Validating NVIDIA DRIVE Sim Lidar Models</a>. This post will cover radar, an essential sensor for obstacle detection and avoidance.&nbsp;</p>\n\n\n\n<p>There are multiple ways to approach radar validation. You can compare how an AV stack trained on real-world data behaves when encountering synthetic radar data, for example. Or, you can compare synthetic radar data to its physical counterpart in real-world experiments.&nbsp;</p>\n\n\n\n<p>Validating the model with an AV stack only evaluates its ability to the extent of triggering the AV function, which tests for a lower fidelity ceiling. For this reason, we will focus on the second approach.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Radar sensor pipeline</h2>\n\n\n\n<p>Radar sensors emit radio waves that reflect off objects in the scene and return to the sensor. The received signal then undergoes multiple processing stages that identify the returns from real objects and filter noises. These returns are then presented as a point cloud of the environment.</p>\n\n\n\n<p>Such postprocessing methods are typically part of a sensor maker\u2019s intellectual property, and thus NVIDIA DRIVE Sim sensor models aim to approximate them. Sensor suppliers in the DRIVE Sim ecosystem can include the exact implementations of their entire pipelines, including postprocessing.</p>\n\n\n\n<p>DRIVE Sim uses ray tracing to model active sensors. Rays that embed the radar radiation pattern are fired into the scene. For each ray that hits an object in the 3D scene, secondary rays are created for reflections and transmissions based on the hit material\u2019s wavelength-dependent properties. The materials in DRIVE Sim use bidirectional scattering distribution functions (BSDF). This enables simulating multipath effects.</p>\n\n\n\n<p>DRIVE Sim ray tracing is time-aware. Each ray has its own timestamp and sees a different environment and sensor position to match that time. This enables simulating time-based effects, such as rolling shutter and Doppler.</p>\n\n\n\n<p>For radar, after the stopping criteria for ray tracing are met, the sensor model consolidates the returns and processes them. Our radar model accounts for the sensor\u2019s field of view (FOV), antenna directivity, resolutions, ambiguities, and the radar\u2019s sensitivity pattern. A constant false alarm rate (CFAR) algorithm is used to extract valid detections over a simulated noise baseline. The detections are then encoded with the exact communication protocol as the real sensor to serve hardware-in-the-loop use cases.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"1360\" height=\"326\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/active-sensor-pipeline.png\" alt=\"Block diagram for active sensors in DRIVE Sim, starting with capturing the world state, ray-tracing with the NVIDIA Omniverse RTX Renderer, RTX sensor model, postprocessing, then integration with the AV stack.\" class=\"wp-image-70955\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/active-sensor-pipeline.png 1360w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/active-sensor-pipeline-300x72.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/active-sensor-pipeline-625x150.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/active-sensor-pipeline-179x43.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/active-sensor-pipeline-768x184.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/active-sensor-pipeline-645x155.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/active-sensor-pipeline-500x120.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/active-sensor-pipeline-160x38.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/active-sensor-pipeline-362x87.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/active-sensor-pipeline-459x110.png 459w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/active-sensor-pipeline-1024x245.png 1024w\" sizes=\"(max-width: 1360px) 100vw, 1360px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 1. Active sensor pipeline</em></em></figcaption></figure></div>\n\n\n<h2 class=\"wp-block-heading\">Radar validation&nbsp;</h2>\n\n\n\n<p>To validate the DRIVE Sim radar model, we designed three scenarios based on the technical product specification (TPS) of the real radar. The goal was to test various components of the radar sensor&#8217;s performance, including its detection capability over its FOV, separation capability, and accuracy in dynamic conditions. Then, we created a <a href=\"https://blogs.nvidia.com/blog/2021/12/14/what-is-a-digital-twin/\">digital twin</a> environment in simulation, collecting the equivalent data in DRIVE Sim for detailed analysis.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Data collection environment</h3>\n\n\n\n<p>For the data collection environment, we opted for an open spacious area\u2014the Transportation Research Center in California. In this environment, we could minimize noise and unwanted reflections to simplify digital twin construction in DRIVE Sim.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"469\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/data-collection-test-site-1-625x469.jpg\" alt=\"Zoomed-out aerial image of the test site.\" class=\"wp-image-71078\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/data-collection-test-site-1-625x469.jpg 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/data-collection-test-site-1-300x225.jpg 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/data-collection-test-site-1-153x115.jpg 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/data-collection-test-site-1-768x576.jpg 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/data-collection-test-site-1-1536x1152.jpg 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/data-collection-test-site-1-2048x1536.jpg 2048w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/data-collection-test-site-1-645x484.jpg 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/data-collection-test-site-1-400x300.jpg 400w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/data-collection-test-site-1-120x90.jpg 120w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/data-collection-test-site-1-362x272.jpg 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/data-collection-test-site-1-147x110.jpg 147w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/data-collection-test-site-1-1024x768.jpg 1024w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 2. Test site for data collection</em></em>. <em>Image courtesy of TRC</em></figcaption></figure></div>\n\n\n<h3 class=\"wp-block-heading\">Vehicle setup</h3>\n\n\n\n<p>We used radar sensors in the <a href=\"https://www.nvidia.com/en-us/self-driving-cars/drive-platform/hardware/\">NVIDIA DRIVE Hyperion</a> AV reference architecture, so developers building on NVIDIA DRIVE can easily transition between simulation and the real world. The sensors were mounted on a development vehicle (Figure 3). For this case, the front center radar (FCR) was the focus for evaluation.</p>\n\n\n\n<p>Operating at a frequency of 77GHz, the radar under test included two scans: a near scan, with a wide FOV but limited range, and a far scan with extended range but a narrow FOV. Additionally, a 360\u00b0 rotating lidar sensor (LD1) was mounted on top of the car to provide pseudo ground truth data.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"870\" height=\"511\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/vehicle-sensor-mounting-positions.png\" alt=\"Side-by-side images of the real-world test vehicle outfitted with sensors from two different angles (top). Two diagram sketches of where the sensors are placed (bottom).\n\" class=\"wp-image-70963\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/vehicle-sensor-mounting-positions.png 870w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/vehicle-sensor-mounting-positions-300x176.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/vehicle-sensor-mounting-positions-625x367.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/vehicle-sensor-mounting-positions-179x105.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/vehicle-sensor-mounting-positions-768x451.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/vehicle-sensor-mounting-positions-645x379.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/vehicle-sensor-mounting-positions-500x294.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/vehicle-sensor-mounting-positions-153x90.png 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/vehicle-sensor-mounting-positions-362x213.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/vehicle-sensor-mounting-positions-187x110.png 187w\" sizes=\"(max-width: 870px) 100vw, 870px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 3. Sensor mounting positions on vehicle under test</em></em></figcaption></figure>\n\n\n\n<h3 class=\"wp-block-heading\">Model validation process</h3>\n\n\n\n<p>Central to our three validation experiments were two trihedral corner reflectors. These are standard radar targets that reflect energy back in the incident direction. They are characterized by a radar cross-section (RCS) value, which is a measure of an object&#8217;s ability to reflect radar energy back to the receiver.&nbsp;</p>\n\n\n\n<p>We used one with a &#8220;high&#8221; RCS of 15.71 decibels relative to a square meter (dBsm), and another with a &#8220;low&#8221; RCS of 4.79 dBsm to characterize the model&#8217;s behavior across a wide RCS range.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"846\" height=\"278\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-principle.png\" alt=\"Three side-by-side images, the first showing a sketch of how the corner reflector reflects energy, followed by an image of the high radar cross section corner reflector and the low radar cross section corner reflector.\n\" class=\"wp-image-70966\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-principle.png 846w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-principle-300x99.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-principle-625x205.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-principle-179x59.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-principle-768x252.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-principle-645x212.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-principle-500x164.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-principle-160x53.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-principle-362x119.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-principle-335x110.png 335w\" sizes=\"(max-width: 846px) 100vw, 846px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 4. Corner reflector principle (left); high RCS CR (center); low RCS CR (right)</em></em></figcaption></figure>\n\n\n\n<p>The lidar\u2019s pseudo-ground truth measurements were used to replicate the test setup virtually in DRIVE Sim with accurate material assignments.&nbsp;</p>\n\n\n\n<p>After collecting the virtual data, we compared the radar model outputs to the real radar. Results of the comparison are presented for the three scenarios below.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Scenario 1: FOV sampling with corner reflector</h3>\n\n\n\n<p>In the first scenario, we assessed the radar&#8217;s detection capabilities across its FOV and verified its range and azimuth accuracy.&nbsp;</p>\n\n\n\n<p>We placed a corner reflector at multiple grid positions within the radar\u2019s FOV, as shown in Figure 5. We assumed the sensor&#8217;s behavior to be symmetric, and thus we only sampled half of the FOV to increase the sampling density.&nbsp;</p>\n\n\n\n<p>Altogether, we recorded a total of 579 positions for the high RCS corner reflector and 632 for the low RCS corner reflector.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"875\" height=\"382\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/grid-positions-real-environment-digital-twin.png\" alt=\"A diagram showing the different positions where the corner reflectors were placed, shown as dots, with side-by-side images below of the real-world vehicle and corner reflector next to the simulated version.\n\" class=\"wp-image-70968\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/grid-positions-real-environment-digital-twin.png 875w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/grid-positions-real-environment-digital-twin-300x131.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/grid-positions-real-environment-digital-twin-625x273.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/grid-positions-real-environment-digital-twin-179x78.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/grid-positions-real-environment-digital-twin-768x335.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/grid-positions-real-environment-digital-twin-645x282.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/grid-positions-real-environment-digital-twin-500x218.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/grid-positions-real-environment-digital-twin-160x70.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/grid-positions-real-environment-digital-twin-362x158.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/grid-positions-real-environment-digital-twin-252x110.png 252w\" sizes=\"(max-width: 875px) 100vw, 875px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 5. Example grid positions (left); real-world environment (center); digital twin (right)</em></em></figcaption></figure>\n\n\n\n<p>Figure 6 depicts a top-down view of both real and simulated radar detections across all 1,211 high and low RCS corner reflector positions. We used this as a coherence check to start. Although we observed differences in FOV coverages above 80m, the overall coverage presented a noticeable similarity that is sufficient for the cross check.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"860\" height=\"366\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-simulated-radar-scatter-plots.png\" alt=\"Side-by-side scatter plots showing the radar detections of the real sensor and the simulated sensor model, with similar patterns displayed on each.\n\" class=\"wp-image-70972\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-simulated-radar-scatter-plots.png 860w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-simulated-radar-scatter-plots-300x128.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-simulated-radar-scatter-plots-625x266.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-simulated-radar-scatter-plots-179x76.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-simulated-radar-scatter-plots-768x327.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-simulated-radar-scatter-plots-645x275.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-simulated-radar-scatter-plots-500x213.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-simulated-radar-scatter-plots-160x68.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-simulated-radar-scatter-plots-362x154.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-simulated-radar-scatter-plots-258x110.png 258w\" sizes=\"(max-width: 860px) 100vw, 860px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 6. Top-down view of real and simulated radar detections</em></em></figcaption></figure>\n\n\n\n<p>The histograms in Figure 7 present the error distribution in range, azimuth, and RCS relative to the ground truth for both the high and low RCS corner reflectors, combined. Where applicable, we quantified the results by fitting a Gaussian distribution to the data. Results for the real radar are displayed on the left, while the DRIVE Sim data is shown on the right.&nbsp;</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"469\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/range-error-distribution-histograms-625x469.png\" alt=\"Histograms showing the error distributions for range compared between the real and simulated radar. \n\" class=\"wp-image-71025\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/range-error-distribution-histograms-625x469.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/range-error-distribution-histograms-300x225.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/range-error-distribution-histograms-153x115.png 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/range-error-distribution-histograms-400x300.png 400w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/range-error-distribution-histograms-120x90.png 120w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/range-error-distribution-histograms-362x272.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/range-error-distribution-histograms-147x110.png 147w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/range-error-distribution-histograms.png 640w\" sizes=\"(max-width: 625px) 100vw, 625px\" /></figure>\n\n\n\n<figure class=\"wp-block-image aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"469\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/azimuth-error-distribution-histograms-625x469.png\" alt=\"Histograms showing the error distributions for azimuth, compared between the real and simulated radar. \n\" class=\"wp-image-71028\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/azimuth-error-distribution-histograms-625x469.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/azimuth-error-distribution-histograms-300x225.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/azimuth-error-distribution-histograms-153x115.png 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/azimuth-error-distribution-histograms-400x300.png 400w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/azimuth-error-distribution-histograms-120x90.png 120w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/azimuth-error-distribution-histograms-362x272.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/azimuth-error-distribution-histograms-147x110.png 147w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/azimuth-error-distribution-histograms.png 640w\" sizes=\"(max-width: 625px) 100vw, 625px\" /></figure>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"469\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/rcs-error-distribution-histograms2-625x469.png\" alt=\"Histograms showing the error distributions for RCS, compared between the real and simulated radar. \" class=\"wp-image-71080\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/rcs-error-distribution-histograms2-625x469.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/rcs-error-distribution-histograms2-300x225.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/rcs-error-distribution-histograms2-153x115.png 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/rcs-error-distribution-histograms2-400x300.png 400w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/rcs-error-distribution-histograms2-120x90.png 120w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/rcs-error-distribution-histograms2-362x272.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/rcs-error-distribution-histograms2-147x110.png 147w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/rcs-error-distribution-histograms2.png 640w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 7. Error distribution histograms for both CRs in Scenario 1</em></em></figcaption></figure></div>\n\n\n<p>We observed a high level of agreement between real and simulation data over various positions in the radar&#8217;s FOV, with both means and standard deviations sharing the same order of magnitude.</p>\n\n\n\n<p>The discrepancies are primarily attributable to uncertainties in the ground truth. While the lidar sensor has millimeter-level accuracy, identifying the position and orientation of an object like a pole-mounted corner reflector can introduce errors in the centimeter range. Furthermore, while we calibrated the sensor positions prior to data collection, there might still be minor misalignments.</p>\n\n\n\n<p>Overall, the agreement observed in RCS values, detection pattern, and the accuracies of the various detection properties validated the radar&#8217;s fidelity, wave propagation, and material modeling.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Scenario 2: Corner reflector separation capability test</h3>\n\n\n\n<p>In scenarios where road objects are near each other (stationary vehicles under a bridge, pedestrians or motorcyclists next to a vehicle or guard rail, or two closely parked cars, for example) radars can encounter difficulties in distinguishing individual objects. For this reason, it is crucial to accurately simulate this characteristic, known as <em>separation capability</em>.</p>\n\n\n\n<p>We assessed this capability by placing the two corner reflectors in close proximity to each other. The data was sampled at four different distances from the sensor. For each distance, the corner reflectors were positioned as shown in Figure 8.</p>\n\n\n\n<p>We selected different positions for the radar&#8217;s near and far scans, dependent on their corresponding FOV, to analyze their range and azimuth separation capabilities.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"860\" height=\"280\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/digital-twin-test-vehicle-corner-reflector-positions.png\" alt=\"A simulated image of two corner reflectors and a vehicle in the background (left) and a sketched diagram of the corner reflectors\u2019 position in relation to the vehicle (right).\n\" class=\"wp-image-70978\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/digital-twin-test-vehicle-corner-reflector-positions.png 860w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/digital-twin-test-vehicle-corner-reflector-positions-300x98.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/digital-twin-test-vehicle-corner-reflector-positions-625x203.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/digital-twin-test-vehicle-corner-reflector-positions-179x58.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/digital-twin-test-vehicle-corner-reflector-positions-768x250.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/digital-twin-test-vehicle-corner-reflector-positions-645x210.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/digital-twin-test-vehicle-corner-reflector-positions-500x163.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/digital-twin-test-vehicle-corner-reflector-positions-160x52.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/digital-twin-test-vehicle-corner-reflector-positions-362x118.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/digital-twin-test-vehicle-corner-reflector-positions-338x110.png 338w\" sizes=\"(max-width: 860px) 100vw, 860px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 8. Digital twin of the test vehicle and corner reflectors (left) and example positions for both corner reflectors (right)</em></em></figcaption></figure>\n\n\n\n<p>Tables 1 and 2 summarize the results for the near and far scans. The left column represents positions where CRs are close and we expect one detection per the TPS. The center and right columns represent positions where we expect two detections per the TPS. Each cell details the exact location of the CRs, and the number of detections observed for simulation and the real world. The percentage denotes the proportion of detections that followed our expectations in all considered scans. We define success when the simulated and real percentages are less than 20% apart.</p>\n\n\n\n<div class=\"wp-block-columns is-layout-flex wp-container-3 wp-block-columns-is-layout-flex\">\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\" style=\"flex-basis:100%\">\n<figure class=\"wp-block-table aligncenter\"><table><tbody><tr><td></td><td>Position of CRs (x,y) in meters</td><td>Position of CRs (x,y) in meters</td><td>Position of CRs (x,y) in meters</td></tr><tr><td>0\u00b0 and 50m</td><td>CR1 (50, 0),&nbsp;CR2 = CR1<br><strong>Real: One detection (100%)</strong><br><strong>Sim: One detection (100%)</strong></td><td>CR1 (50, 0),&nbsp;CR2 (50.5, 0)<br><strong>Real: Two detections (10%)</strong><br><strong>Sim: Two detections (0%)</strong></td><td>CR1 (50, 0),&nbsp;CR2 (50, -3)<br><strong>Real: Two detections (0%)</strong><br><strong>Sim: Two detections (0%)</strong></td></tr><tr><td>-45\u00b0 and 20m</td><td>CR1 (14.14, -14.14),&nbsp;CR2 = CR1<br><strong>Real: One detection (100%)</strong><br><strong>Sim: One detection (100%)</strong></td><td>CR1 (14.14, -14.14),CR2 (15.14, -14.14)<br><strong>Real: Two detections (100%)</strong><br><strong>Sim: Two detections (100%)</strong></td><td>CR1 (14.14, -14.14), CR2 (16.44, -11.84)<br><strong>Real: Two detections (100%)</strong><br><strong>Sim: Two detections&nbsp;(100%)</strong></td></tr><tr><td>-45\u00b0 and 50m</td><td>CR1 (35.36, -35.36),&nbsp;CR2 = CR1<br><strong>Real: One detection&nbsp; (100%)</strong><br><strong>Sim: One detection&nbsp; (100%)</strong></td><td>CR1 (35.36, -35.36),CR2 (36.36, -35.36)<br><strong>Real: Two detections (5%)</strong><br><strong>Sim: Two detections (100%)</strong></td><td>CR1 (35.36, -35.36), CR2 (41, -29)<br><strong>Real: Two detections (80%)</strong><br><strong>Sim: Two detections (100%)</strong></td></tr></tbody></table><figcaption class=\"wp-element-caption\"><em><em>Table 1. Number of detections per scan for near scan</em></em></figcaption></figure>\n</div>\n</div>\n\n\n\n<p>Results for all positions at 0\u00b0 and 50m, and -45\u00b0 and 20m, demonstrated a high degree of similarity between real and simulated. We observed a minor discrepancy at 0\u00b0 and 50m where CR2 (50.5, 0). In this scenario, the real radar returned two detections instead of one in 10% of the scans.</p>\n\n\n\n<p>Comparisons made at -45\u00b0 and 50m were mostly consistent, except for CR2 (36.36, -35.36), where the simulated radar returned two detections.&nbsp;</p>\n\n\n\n<figure class=\"wp-block-table aligncenter\"><table><tbody><tr><td></td><td>Position of CRs (x,y) in meters</td><td>Position of CRs (x,y) in meters</td><td>Position of CRs (x,y) in meters</td></tr><tr><td>0\u00b0 and 50m</td><td>CR1 (50, 0),&nbsp;CR2 = CR1<br><strong>Real: One detection (100%)</strong><br><strong>Sim: <strong>One</strong> detection (95%)</strong></td><td>CR1 (50, 0),&nbsp;CR2 (50.5, 0)<br><strong>Real: <strong>One</strong> detection (100%)</strong><br><strong>Sim: <strong>One</strong> detection (5%)</strong></td><td>CR1 (50, 0),&nbsp;CR2 (50, -3)<br><strong>Real: Two detections (0%)</strong><br><strong>Sim: Two detections (5%)</strong></td></tr><tr><td>0\u00b0 and 100m</td><td>CR1 (100,0),&nbsp;CR2 = CR1<br><strong>Real: <strong>One</strong> detection (100%)</strong><br><strong>Sim: <strong>One</strong> detection (60%)</strong></td><td>CR1 (100, 0),&nbsp;CR2 (104, 0)<br><strong>Real: Two detections (100%)</strong><br><strong>Sim: Two detections (95%)</strong></td><td>CR1 (100, 0),&nbsp;CR2 (100, -6)<br><strong>Real: Two detections (0%)</strong><br><strong>Sim: Two detections (0%)</strong></td></tr></tbody></table><figcaption class=\"wp-element-caption\"><em><em>Table 2. Number of detections per scan for far scan</em></em></figcaption></figure>\n\n\n\n<p>As shown in Table 2, the results from the simulated and real-world sensors are largely in correlation. Significant deviations are noted at 0\u00b0 and 50m where CR2 (50.5, 0). Furthermore, for 0\u00b0 and 100m where CR1=CR2, the simulated radar returns two detections in 40% of scans, while real world never returns two detections.&nbsp;</p>\n\n\n\n<p>Upon further analysis of the deviations, we attribute them to the fact that the technical product specification only described the radar\u2019s separation capability at a few angles. This made it difficult for us to estimate the exact layout of range and azimuth bins.&nbsp;</p>\n\n\n\n<p>In addition, our parameterization and implementation for the CFAR thresholding algorithm is an estimate, as it is a supplier\u2019s intellectual property. The separation capability of the radar is expected to be quite sensitive to the CFAR behavior.</p>\n\n\n\n<p>Overall, across both the near and far scans, we found the simulated separation capability to be close enough to the real sensor.</p>\n\n\n\n<h3 class=\"wp-block-heading\">Scenario 3: Driving toward a corner reflector with constant speed</h3>\n\n\n\n<p>Doppler measurement enables radars to accurately detect the speed of moving targets. We evaluated the model&#8217;s performance in dynamic conditions, where the test vehicle drove directly toward high and low RCS corner reflectors, taking separate trips at constant speeds of 10kph, 40kph, and 80kph, as shown below.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"407\" height=\"442\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-foreground-test-vehicle-background2.png\" alt=\"An image with a corner reflector in the foreground and a test vehicle at a far distance in the background./\" class=\"wp-image-70987\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-foreground-test-vehicle-background2.png 407w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-foreground-test-vehicle-background2-276x300.png 276w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-foreground-test-vehicle-background2-106x115.png 106w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-foreground-test-vehicle-background2-83x90.png 83w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-foreground-test-vehicle-background2-362x393.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/corner-reflector-foreground-test-vehicle-background2-101x110.png 101w\" sizes=\"(max-width: 407px) 100vw, 407px\" /><figcaption class=\"wp-element-caption\"><em>Figure 9. Real-world<em> environment </em></em></figcaption></figure></div>\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"853\" height=\"480\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/simulated-vehicle-in-motion-gif-3.gif\" alt=\"A GIF of a simulated vehicle driving toward a simulated corner reflector.\n\" class=\"wp-image-70988\" /><figcaption class=\"wp-element-caption\"><em>Figure 10. <em>Digital twin environment</em></em></figcaption></figure>\n\n\n\n<p>The histograms in Figure 11 present the Doppler error results for both the high and low RCS corner reflectors.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"469\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-10-kph-1-625x469.png\" alt=\"Histograms comparing the error distributions in Doppler effect between real and simulated radar.\n\" class=\"wp-image-71002\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-10-kph-1-625x469.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-10-kph-1-300x225.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-10-kph-1-153x115.png 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-10-kph-1-400x300.png 400w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-10-kph-1-120x90.png 120w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-10-kph-1-362x272.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-10-kph-1-147x110.png 147w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-10-kph-1.png 640w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>High RCS, 10kph</em></em></figcaption></figure>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"469\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-40-kph-1-625x469.png\" alt=\"Histograms comparing the error distributions in Doppler effect between real and simulated radar.\" class=\"wp-image-71003\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-40-kph-1-625x469.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-40-kph-1-300x225.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-40-kph-1-153x115.png 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-40-kph-1-400x300.png 400w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-40-kph-1-120x90.png 120w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-40-kph-1-362x272.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-40-kph-1-147x110.png 147w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-40-kph-1.png 640w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>High RCS, 40kph</em></em></figcaption></figure></div>\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"469\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-80-kph-1-625x469.png\" alt=\"Histograms comparing the error distributions in Doppler effect between real and simulated radar.\" class=\"wp-image-71004\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-80-kph-1-625x469.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-80-kph-1-300x225.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-80-kph-1-153x115.png 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-80-kph-1-400x300.png 400w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-80-kph-1-120x90.png 120w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-80-kph-1-362x272.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-80-kph-1-147x110.png 147w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-high-rcs-80-kph-1.png 640w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>High RCS, 80kph</em></em></figcaption></figure></div>\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"469\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-10-kph-1-625x469.png\" alt=\"Histograms comparing the error distributions in Doppler effect between real and simulated radar.\" class=\"wp-image-71005\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-10-kph-1-625x469.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-10-kph-1-300x225.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-10-kph-1-153x115.png 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-10-kph-1-400x300.png 400w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-10-kph-1-120x90.png 120w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-10-kph-1-362x272.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-10-kph-1-147x110.png 147w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-10-kph-1.png 640w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>Low RCS, 10kph</em></em></figcaption></figure></div>\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"469\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-40-kph-1-625x469.png\" alt=\"Histograms comparing the error distributions in Doppler effect between real and simulated radar.\" class=\"wp-image-71006\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-40-kph-1-625x469.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-40-kph-1-300x225.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-40-kph-1-153x115.png 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-40-kph-1-400x300.png 400w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-40-kph-1-120x90.png 120w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-40-kph-1-362x272.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-40-kph-1-147x110.png 147w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-40-kph-1.png 640w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>Low RCS, 40kph</em></em></figcaption></figure></div>\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"469\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-80-kph-1-625x469.png\" alt=\"Histograms comparing the error distributions in Doppler effect between real and simulated radar.\" class=\"wp-image-71007\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-80-kph-1-625x469.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-80-kph-1-300x225.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-80-kph-1-153x115.png 153w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-80-kph-1-400x300.png 400w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-80-kph-1-120x90.png 120w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-80-kph-1-362x272.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-80-kph-1-147x110.png 147w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-error-histogram-low-rcs-80-kph-1.png 640w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>Low RCS, 80kph</em></em><br><br><em>Figure 11. Doppler error histograms for Scenario 3</em></figcaption></figure></div>\n\n\n<p>We observed a remarkably high correlation in Doppler across all tested speeds. For 10kph, both real and simulated distributions exhibited similar peaks at approximately -3mps, -2mps, and 0mps. For 40kph, the peaks aligned around -10mps. For 80kph, peaks were observed at -20mps and 10mps. This high degree of accuracy was further demonstrated when plotting Doppler against range.</p>\n\n\n\n<div class=\"wp-block-columns is-layout-flex wp-container-5 wp-block-columns-is-layout-flex\">\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\"><div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"313\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-10-kph2-625x313.png\" alt=\"Mean error and standard deviation for Doppler effect between real and simulated radar sensors.\" class=\"wp-image-71082\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-10-kph2-625x313.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-10-kph2-300x150.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-10-kph2-179x90.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-10-kph2-768x384.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-10-kph2-645x323.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-10-kph2-500x250.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-10-kph2-160x80.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-10-kph2-362x181.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-10-kph2-220x110.png 220w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-10-kph2.png 1000w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>High RCS, 10kph</em></em></figcaption></figure></div>\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"313\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-40-kph2-625x313.png\" alt=\"Mean error and standard deviation for Doppler effect between real and simulated radar sensors.\" class=\"wp-image-71084\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-40-kph2-625x313.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-40-kph2-300x150.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-40-kph2-179x90.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-40-kph2-768x384.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-40-kph2-645x323.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-40-kph2-500x250.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-40-kph2-160x80.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-40-kph2-362x181.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-40-kph2-220x110.png 220w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-40-kph2.png 1000w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>High RCS, 40kph</em></em></figcaption></figure></div></div>\n</div>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"313\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-80-kph2-625x313.png\" alt=\"Mean error and standard deviation for Doppler effect between real and simulated radar sensors.\" class=\"wp-image-71086\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-80-kph2-625x313.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-80-kph2-300x150.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-80-kph2-179x90.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-80-kph2-768x384.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-80-kph2-645x323.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-80-kph2-500x250.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-80-kph2-160x80.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-80-kph2-362x181.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-80-kph2-220x110.png 220w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-high-rcs-80-kph2.png 1000w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em>High RCS, 80kph</em></figcaption></figure></div>\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"313\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-10-kph2-625x313.png\" alt=\"Mean error and standard deviation for Doppler effect between real and simulated radar sensors.\" class=\"wp-image-71088\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-10-kph2-625x313.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-10-kph2-300x150.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-10-kph2-179x90.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-10-kph2-768x384.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-10-kph2-645x323.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-10-kph2-500x250.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-10-kph2-160x80.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-10-kph2-362x181.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-10-kph2-220x110.png 220w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-10-kph2.png 1000w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>Low RCS, 10kph</em></em></figcaption></figure></div>\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"313\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-res-40-kph2-625x313.png\" alt=\"Mean error and standard deviation for Doppler effect between real and simulated radar sensors.\" class=\"wp-image-71089\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-res-40-kph2-625x313.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-res-40-kph2-300x150.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-res-40-kph2-179x90.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-res-40-kph2-768x384.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-res-40-kph2-645x323.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-res-40-kph2-500x250.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-res-40-kph2-160x80.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-res-40-kph2-362x181.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-res-40-kph2-220x110.png 220w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-res-40-kph2.png 1000w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>Low RCS, 40kph</em></em></figcaption></figure></div>\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-large\"><img decoding=\"async\" loading=\"lazy\" width=\"625\" height=\"313\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-80-kph2-625x313.png\" alt=\"Mean error and standard deviation for Doppler effect between real and simulated radar sensors.\" class=\"wp-image-71091\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-80-kph2-625x313.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-80-kph2-300x150.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-80-kph2-179x90.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-80-kph2-768x384.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-80-kph2-645x323.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-80-kph2-500x250.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-80-kph2-160x80.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-80-kph2-362x181.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-80-kph2-220x110.png 220w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/doppler-standard-deviation-low-rcs-80-kph2.png 1000w\" sizes=\"(max-width: 625px) 100vw, 625px\" /><figcaption class=\"wp-element-caption\"><em><em>Low RCS, 80kph</em></em><br><br><em>Figure 12. Doppler mean eror and standard deviation over the range for Scenario 3</em></figcaption></figure></div>\n\n\n<p>Figure 13 illustrates a top-down view of real and simulated radar detections across high and low RCS corner reflector positions and vehicle speeds.</p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"606\" height=\"537\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-and-simulated-radar-detections-scatter-plot2.png\" alt=\"Scatter plot showing both the real and simulated radar detections compared with the ground truth. The real and simulated detections follow similar patterns.\n\" class=\"wp-image-71022\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-and-simulated-radar-detections-scatter-plot2.png 606w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-and-simulated-radar-detections-scatter-plot2-300x266.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-and-simulated-radar-detections-scatter-plot2-130x115.png 130w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-and-simulated-radar-detections-scatter-plot2-339x300.png 339w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-and-simulated-radar-detections-scatter-plot2-102x90.png 102w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-and-simulated-radar-detections-scatter-plot2-362x321.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-and-simulated-radar-detections-scatter-plot2-124x110.png 124w\" sizes=\"(max-width: 606px) 100vw, 606px\" /><figcaption class=\"wp-element-caption\"><em><em>Figure 13. Top-down view of real and simulated radar detections</em></em></figcaption></figure>\n\n\n\n<p>Both the real and simulated Doppler measurements demonstrated substantial agreement in their mean and standard deviation values. However, we noticed deviations at higher speeds.&nbsp;</p>\n\n\n\n<p>We attribute these deviations to uncertainties during the creation of the digital twin. The position, speed, and orientation of the ego vehicle were estimated using lidar without the aid of differential GPS. The errors in these estimations are amplified at higher speeds as can be seen in 80kph.</p>\n\n\n\n<p>In addition, we observed that DRIVE Sim is able to replicate the Radar Aliasing phenomenon, which occurs when an object&#8217;s radial velocity surpasses the radar\u2019s maximum measurable unambiguous velocity, resulting in ambiguous velocity values. Real-world radars subtly shift the maximum measurable unambiguous velocity range with each cycle, enabling subsequent perception algorithms to disambiguate the velocities.&nbsp;</p>\n\n\n\n<p>Our simulation accurately replicated this behavior, as demonstrated by the alignment of the peaks in both the real and simulated data. Particularly, at a speed of 80kph, both the real and simulated radar exhibited similar velocity wrapping.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Conclusion</h2>\n\n\n\n<p>This study presents our first iteration for an in-depth validation of our simulated radar model using real-world data, including static and dynamic conditions. The analysis was designed to assess the model&#8217;s fidelity and accuracy across a variety of performance metrics.</p>\n\n\n\n<p>Our results demonstrate a high degree of correlation between the simulated and real-world radar data with the model adeptly handling complex interactions such as multibounce effects.&nbsp;</p>\n\n\n\n<p>Upcoming experiments will focus on capturing radar data from more complex objects (vehicles, pedestrians, motorbikes) mimicking real-world scenarios. These objects not only have more complicated geometries, but are also composed of a variety of materials, thus introducing further complexities in radar wave interactions. Through these efforts, we aim to continually enhance the model&#8217;s fidelity, further bridging the gap between simulation and reality.</p>\n\n\n\n<p>By validating accurate radar sensor behavior in simulated scenarios, we can improve system development efficiency, reduce dependence on costly and time-consuming real-world data collection, and enhance the safety and performance of AV systems.&nbsp;</p>\n\n\n\n<p>To learn more, see our previously published posts:</p>\n\n\n\n<ul>\n<li><a href=\"https://developer.nvidia.com/blog/validating-drive-sim-camera-models/\">Validating NVIDIA DRIVE Sim Camera Models</a></li>\n\n\n\n<li><a href=\"https://developer.nvidia.com/blog/validating-active-sensors-in-nvidia-drive-sim/\">Validating NVIDIA DRIVE Sim Lidar Models</a></li>\n</ul>\n", "protected": false}, "excerpt": {"rendered": "<p>Sensor simulation is a critical tool to address the gaps in real-world data for autonomous vehicle (AV) development. However, it is only effective if sensor models accurately reflect the physical world.&nbsp; Sensors can be either passive, such as cameras\u2014or active, sending out either an electromagnetic wave (lidar, radar) or an acoustic wave (ultrasonic) to generate &hellip; <a href=\"https://developer.nvidia.com/blog/validating-nvidia-drive-sim-radar-models/\">Continued</a></p>\n", "protected": false}, "author": 1878, "featured_media": 70961, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1268273", "discourse_permalink": "https://forums.developer.nvidia.com/t/validating-nvidia-drive-sim-radar-models/267683", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [2724, 1205, 503, 1903], "tags": [501, 2850, 3366, 453, 1409, 1718, 2377], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/real-radar-nvidia-drive-sim-radar-gif.gif", "jetpack_shortlink": "https://wp.me/pcCQAL-ism", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70950"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1878"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=70950"}], "version-history": [{"count": 37, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70950/revisions"}], "predecessor-version": [{"id": 71154, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70950/revisions/71154"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/70961"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=70950"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=70950"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=70950"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 71058, "date": "2023-09-25T10:00:00", "date_gmt": "2023-09-25T17:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=71058"}, "modified": "2023-10-19T12:06:02", "modified_gmt": "2023-10-19T19:06:02", "slug": "new-video-series-cuda-developer-tools-tutorials", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/new-video-series-cuda-developer-tools-tutorials/", "title": {"rendered": "New Video Series: CUDA Developer Tools Tutorials"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p><a href=\"https://www.nvidia.com/en-us/gpu-accelerated-applications/\">GPU acceleration</a> is enabling faster and more intelligent applications than ever before, and the <a href=\"https://developer.nvidia.com/cuda-toolkit\">CUDA Toolkit</a> is key to harnessing acceleration on NVIDIA GPUs. But debugging, profiling, and optimizing CUDA can be a challenge, especially if you are unable to inspect hardware-level throughput and performance. To help you harness CUDA acceleration, NVIDIA offers <a href=\"https://developer.nvidia.com/tools-overview\">Nsight Developer Tools</a>.&nbsp;</p>\n\n\n\n<p><a href=\"https://youtu.be/xdFQZSV5IrU\">CUDA Developer Tools</a> is a new tutorial video series for getting started with CUDA developer tools. Grow your skills, apply our examples to your own development environment, and stay updated on features and functionalities. The videos walk you through how to analyze performance reports, offer debugging tips and tricks, and show you the best ways to optimize your CUDA code.</p>\n\n\n\n<p>Watch the first three tutorials in the series now.&nbsp;</p>\n\n\n\n<p><a href=\"https://youtu.be/xdFQZSV5IrU\">CUDA Developer Tools | NVIDIA Nsight Tools Ecosystem</a> introduces you to the suite of tools NVIDIA offers. Learn how each is used, and how they&#8217;re built to work together.</p>\n\n\n\n<p><a href=\"https://developer.nvidia.com/nsight-systems\">NVIDIA Nsight Systems</a> offers system-wide performance traces and metrics, visualization of CPU and GPU utilization, API calls, memory copies, and more.&nbsp;</p>\n\n\n\n<p>With <a href=\"https://developer.nvidia.com/nsight-compute\">NVIDIA Nsight Compute</a>, you can dive deeper with an interactive profiler for CUDA and NVIDIA OptiX applications. It provides detailed performance metrics and API debugging. Guided analysis simplifies the performance tuning process with a built-in rule set for CUDA optimization designed by NVIDIA engineers.</p>\n\n\n\n<figure class=\"wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<span class=\"embed-youtube\" style=\"text-align:center; display: block;\"><iframe loading=\"lazy\" class=\"youtube-player\" width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/xdFQZSV5IrU?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent\" allowfullscreen=\"true\" style=\"border:0;\" sandbox=\"allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox\"></iframe></span>\n</div></figure>\n\n\n\n<p><a href=\"https://youtu.be/dUDGO66IadU\">CUDA Developer Tools | Intro to NVIDIA Nsight Systems</a> walks you through how to trace performance and hardware activity to better tune your CUDA application. Learn the profiling process, including project setup and configuration, and how to specify profiling targets, launch an application to trace, and view the results.</p>\n\n\n\n<p>You\u2019ll also learn how to read and analyze an Nsight Systems report. The built-in timeline view provides an intuitive visualization of system events, making it easy to understand your application&#8217;s behavior. With the timeline view, you can see CPU threads, CUDA API calls, GPU activity, and more.&nbsp;</p>\n\n\n\n<figure class=\"wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<span class=\"embed-youtube\" style=\"text-align:center; display: block;\"><iframe loading=\"lazy\" class=\"youtube-player\" width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/dUDGO66IadU?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent\" allowfullscreen=\"true\" style=\"border:0;\" sandbox=\"allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox\"></iframe></span>\n</div></figure>\n\n\n\n<p><a href=\"https://youtu.be/Iuy_RAvguBM\">CUDA Developer Tools | Intro to NVIDIA Nsight Compute</a> explains how to use Nsight Compute to analyze CUDA kernels. You\u2019ll learn how to set up Nsight Compute, including key capabilities and features for workload analysis. Discover how Nsight Compute collects performance metrics, and how to configure permissions for accessing GPU counters and source-level details.</p>\n\n\n\n<p>The video also covers the detailed reports Nsight Compute generates, and how to read information like runtime information, speedup estimations, and more.</p>\n\n\n\n<figure class=\"wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<span class=\"embed-youtube\" style=\"text-align:center; display: block;\"><iframe loading=\"lazy\" class=\"youtube-player\" width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/Iuy_RAvguBM?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent\" allowfullscreen=\"true\" style=\"border:0;\" sandbox=\"allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox\"></iframe></span>\n</div></figure>\n\n\n\n<p>Stay tuned for more episodes of CUDA Developer Tools tutorials.</p>\n\n\n\n<ul>\n<li>Learn more about <a href=\"https://developer.nvidia.com/tools-overview\">NVIDIA Nsight Developer Tools for CUDA</a>.</li>\n\n\n\n<li>Download <a href=\"http://developer.nvidia.com/nsight-systems\">NVIDIA Nsight Systems</a>.</li>\n\n\n\n<li>Download <a href=\"http://developer.nvidia.com/nsight-compute\">NVIDIA Nsight Compute</a>.</li>\n\n\n\n<li>Ask questions and dive deeper in the <a href=\"https://forums.developer.nvidia.com/c/developer-tools/cuda-developer-tools/285\">CUDA Developer Tools forum</a>.</li>\n</ul>\n", "protected": false}, "excerpt": {"rendered": "<p>GPU acceleration is enabling faster and more intelligent applications than ever before, and the CUDA Toolkit is key to harnessing acceleration on NVIDIA GPUs. But debugging, profiling, and optimizing CUDA can be a challenge, especially if you are unable to inspect hardware-level throughput and performance. To help you harness CUDA acceleration, NVIDIA offers Nsight Developer &hellip; <a href=\"https://developer.nvidia.com/blog/new-video-series-cuda-developer-tools-tutorials/\">Continued</a></p>\n", "protected": false}, "author": 724, "featured_media": 71061, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1267086", "discourse_permalink": "https://forums.developer.nvidia.com/t/new-video-series-cuda-developer-tools-tutorials/267534", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [852, 696, 503, 1903], "tags": [1932, 21, 453, 529, 2377], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/class-learning-with-laptops.png", "jetpack_shortlink": "https://wp.me/pcCQAL-iu6", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71058"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/724"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=71058"}], "version-history": [{"count": 9, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71058/revisions"}], "predecessor-version": [{"id": 71071, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/71058/revisions/71071"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/71061"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=71058"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=71058"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=71058"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 70926, "date": "2023-09-21T12:00:00", "date_gmt": "2023-09-21T19:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=70926"}, "modified": "2023-10-19T12:06:02", "modified_gmt": "2023-10-19T19:06:02", "slug": "just-released-nvidia-modulus-23-09", "status": "publish", "type": "post", "link": "https://nvda.ws/460n3ke", "title": {"rendered": "Just Released: NVIDIA Modulus 23.09"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>NVIDIA Modulus 23.09 is now available, providing ease-of-use updates, fixes, and other enhancements.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>NVIDIA Modulus 23.09 is now available, providing ease-of-use updates, fixes, and other enhancements.</p>\n", "protected": false}, "author": 1466, "featured_media": 70927, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "", "discourse_permalink": "", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "https://nvda.ws/460n3ke", "_links_to_target": "_blank"}, "categories": [503], "tags": [1916, 1913, 453, 608, 2216, 1958, 3281, 61, 3420], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/hpc-modulus-simnet.png", "jetpack_shortlink": "https://wp.me/pcCQAL-irY", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70926"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1466"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=70926"}], "version-history": [{"count": 5, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70926/revisions"}], "predecessor-version": [{"id": 70932, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70926/revisions/70932"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/70927"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=70926"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=70926"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=70926"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 70919, "date": "2023-09-20T10:00:00", "date_gmt": "2023-09-20T17:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=70919"}, "modified": "2023-11-03T00:14:57", "modified_gmt": "2023-11-03T07:14:57", "slug": "workshop-building-conversational-ai-applications", "status": "publish", "type": "post", "link": "https://nvda.ws/48oZgfp", "title": {"rendered": "Workshop: Building Conversational AI Applications"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>Learn how to build and deploy production-quality conversational AI apps with real-time transcription and NLP.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Learn how to build and deploy production-quality conversational AI apps with real-time transcription and NLP.</p>\n", "protected": false}, "author": 1466, "featured_media": 70920, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "", "discourse_permalink": "", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "https://nvda.ws/48oZgfp", "_links_to_target": "_blank"}, "categories": [1050], "tags": [2964, 1935, 453, 1958, 3545, 1976, 106, 1685], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dli-social-convai-workshop-and-scaling-gpu-1920x1080-1.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-irR", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70919"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1466"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=70919"}], "version-history": [{"count": 5, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70919/revisions"}], "predecessor-version": [{"id": 70925, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70919/revisions/70925"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/70920"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=70919"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=70919"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=70919"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 70763, "date": "2023-09-20T09:20:00", "date_gmt": "2023-09-20T16:20:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=70763"}, "modified": "2023-10-19T12:06:03", "modified_gmt": "2023-10-19T19:06:03", "slug": "new-video-representing-data-with-openusd-custom-schemas", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/new-video-representing-data-with-openusd-custom-schemas/", "title": {"rendered": "New Video: Representing Data with OpenUSD Custom Schemas"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>Custom schemas in <a href=\"https://developer.nvidia.com/usd\">Universal Scene Description, known as OpenUSD or USD</a>, are pivotal for developers seeking to represent and encode sophisticated virtual worlds. By formalizing data models, schemas enable the interpretation of raw data by USD-compliant runtimes.</p>\n\n\n\n<p>Whether underpinning physics simulations or expanding <a href=\"https://www.nvidia.com/en-us/omniverse/solutions/digital-twins/\">digital twins</a>, custom schemas provide the foundation for creativity, fidelity, and innovation in virtual environments.</p>\n\n\n\n<p>In the third installment of this <a href=\"https://www.youtube.com/playlist?list=PL3jK4xNnlCVcUP08kj6eOzvCA82U_JKiy\">OpenUSD series</a>, I share what developers must know about custom schemas.&nbsp;</p>\n\n\n\n<p>Specifically, we dive into:</p>\n\n\n\n<ul>\n<li><strong>Data formalization: </strong>Custom schemas formalize data models, such as geometric meshes. These schemas populate the USD schema registry with canonical definitions.</li>\n\n\n\n<li><strong>Data hierarchies: </strong>USD scenes, or <em>stages</em>, consist of <em>prims</em>\u2014hierarchies of primitives\u2014with each prim serving as a data container. Schemas formalize prim data, making them queryable and interpretable by USD-compliant runtimes.</li>\n\n\n\n<li><strong>Data modeling compared to runtime behaviors: </strong>Schemas define data structure but not runtime functionality, highlighting the separation between the two aspects in USD development.</li>\n\n\n\n<li><strong>Schema types:</strong> USD supports various schema types, including IsA (typed) schemas like UsdGeomMesh, and API schemas such as UsdPhysicsRigidBodyAPI to additionally annotate already-typed prims.</li>\n\n\n\n<li><strong>Standardization process:</strong> Standardizing new schemas involves prototyping, formalization, internal reviews, whitepaper publication, and broad industry review, leading to adoption as a USD standard.</li>\n</ul>\n\n\n\n<p>Custom schemas in USD open up numerous pathways for crafting more complex virtual worlds. OpenUSD includes core schemas like geometry and shading, with continuous development of custom schemas to broaden the digital landscape.</p>\n\n\n\n<figure class=\"wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<span class=\"embed-youtube\" style=\"text-align:center; display: block;\"><iframe loading=\"lazy\" class=\"youtube-player\" width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/-iCUjNk2aiA?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent\" allowfullscreen=\"true\" style=\"border:0;\" sandbox=\"allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox\"></iframe></span>\n</div><figcaption class=\"wp-element-caption\"><em>Video 1. Universal Scene Description (OpenUSD): Custom Schemas</em></figcaption></figure>\n\n\n\n<p>For the latest USD resources and tutorials, visit our <a href=\"https://developer.nvidia.com/usd\">OpenUSD resources page</a>. Try the free <a href=\"https://developer.nvidia.com/usd/validator\">RunUSD Validation Service</a> to validate the compatibility of your OpenUSD assets and applications against a range of OpenUSD versions and configurations.&nbsp;</p>\n\n\n\n<p>If you\u2019re a developer, start building OpenUSD-based apps and tools on the <a href=\"https://developer.nvidia.com/omniverse\" target=\"_blank\" rel=\"noreferrer noopener\">Omniverse platform</a>. Stay up to date on the platform by subscribing to the<a href=\"https://nvda.ws/3u5KPv1\"> newsletter</a>, and following NVIDIA Omniverse on <a href=\"https://www.instagram.com/nvidiaomniverse/\">Instagram</a>, <a href=\"https://medium.com/@nvidiaomniverse\">Medium</a>, and <a href=\"https://twitter.com/nvidiaomniverse\">Twitter</a>. Check out our <a href=\"https://forums.developer.nvidia.com/c/omniverse/300\">forums</a>, <a href=\"https://discord.com/invite/XWQNJDNuaC\">Discord server</a>, <a href=\"https://www.twitch.tv/nvidiaomniverse\">Twitch</a>, and <a href=\"https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA\">YouTube</a> channels.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Custom schemas in Universal Scene Description, known as OpenUSD or USD, are pivotal for developers seeking to represent and encode sophisticated virtual worlds. By formalizing data models, schemas enable the interpretation of raw data by USD-compliant runtimes. Whether underpinning physics simulations or expanding digital twins, custom schemas provide the foundation for creativity, fidelity, and innovation &hellip; <a href=\"https://developer.nvidia.com/blog/new-video-representing-data-with-openusd-custom-schemas/\">Continued</a></p>\n", "protected": false}, "author": 1775, "featured_media": 70846, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1264286", "discourse_permalink": "https://forums.developer.nvidia.com/t/new-video-representing-data-with-openusd-custom-schemas/267045", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [696, 503], "tags": [2375, 453, 55, 3096], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/USD-custom-schemas-video.gif", "jetpack_shortlink": "https://wp.me/pcCQAL-ipl", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70763"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1775"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=70763"}], "version-history": [{"count": 9, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70763/revisions"}], "predecessor-version": [{"id": 70949, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70763/revisions/70949"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/70846"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=70763"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=70763"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=70763"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 70820, "date": "2023-09-18T15:30:00", "date_gmt": "2023-09-18T22:30:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=70820"}, "modified": "2023-10-25T16:51:21", "modified_gmt": "2023-10-25T23:51:21", "slug": "how-to-train-an-object-detection-model-for-visual-inspection-with-synthetic-data", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/how-to-train-an-object-detection-model-for-visual-inspection-with-synthetic-data/", "title": {"rendered": "How to Train an Object Detection Model for Visual Inspection with Synthetic Data"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>AI is rapidly changing industrial visual inspection. In a factory setting, visual inspection is used for many issues, including detecting defects and missing or incorrect parts during assembly. Computer vision can help identify problems with products early on, reducing the chances of them being delivered to customers.&nbsp;</p>\n\n\n\n<p>However, developing accurate and versatile object detection models remains challenging for edge AI developers. Robust object detection models require access to comprehensive and representative datasets. In many manufacturing scenarios, real-world datasets fall short when capturing the complexity and diversity of actual scenarios. The constraints of narrow environments and limited variations pose challenges in training models to adapt to a range of situations effectively.</p>\n\n\n\n<p>Teams can harness <a href=\"https://www.nvidia.com/en-us/omniverse/synthetic-data/\" target=\"_blank\" rel=\"noreferrer noopener\">synthetic data</a> for training models on diverse, randomized data that closely resemble real-world scenarios and address dataset gaps. The result is more accurate and adaptable AI models that can be deployed for a wide range of edge AI applications in industrial automation, healthcare, and manufacturing, to name a few.</p>\n\n\n\n<h2 class=\"wp-block-heading\">From synthetic data generation to AI training&nbsp;</h2>\n\n\n\n<p><a href=\"https://edgeimpulse.com/\" target=\"_blank\" rel=\"noreferrer noopener\">Edge Impulse</a> is an integrated development platform that empowers developers to create and deploy AI models for edge devices. It supports data collection, preprocessing, model training, and deployment, helping users integrate AI capabilities into their applications effectively.</p>\n\n\n\n<p>With <a href=\"https://developer.nvidia.com/omniverse/replicator\" target=\"_blank\" rel=\"noreferrer noopener\">NVIDIA Omniverse Replicator</a>, a core extension of <a href=\"https://www.nvidia.com/en-us/omniverse/\" target=\"_blank\" rel=\"noreferrer noopener\">NVIDIA Omniverse</a>, users can produce physically accurate and photorealistic, synthetically generated annotated images in <a href=\"https://developer.nvidia.com/usd\" target=\"_blank\" rel=\"noreferrer noopener\">Universal Scene Description</a>, known as OpenUSD. These images can then be used for training an object detection model on the Edge Impulse platform.&nbsp;</p>\n\n\n\n<p>NVIDIA Omniverse is a computing platform that enables individuals and teams to develop Universal Scene Description (OpenUSD)-based 3D workflows and applications.</p>\n\n\n\n<p>OpenUSD is a highly versatile and interoperable 3D interchangeable and format that excels in synthetic data generation due to its scalability, performance, versioning, and asset management capabilities, making it an ideal choice for creating complex and realistic datasets. There&#8217;s a vast ecosystem of 3D content tools that connect to OpenUSD and <a href=\"https://developer.nvidia.com/omniverse/simready-assets\" target=\"_blank\" rel=\"noreferrer noopener\">USD-based SimReady assets</a> that make it easy to integrate physically-based objects into scenes and accelerate our synthetic data generation workflows.</p>\n\n\n\n<p>Omniverse Replicator enables randomization for USD data across several domains to represent scenarios that reflect real-world possibilities object detection models may encounter.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"1771\" height=\"550\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/infographic.png\" alt=\"A diagram showing the workflow from content in Omniverse being used to generate synthetic datasets in Replicator, which can then be used for AI training with Edge Impulse.\" class=\"wp-image-70906\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/infographic.png 1771w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/infographic-300x93.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/infographic-625x194.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/infographic-179x56.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/infographic-768x239.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/infographic-1536x477.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/infographic-645x200.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/infographic-500x155.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/infographic-160x50.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/infographic-362x112.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/infographic-354x110.png 354w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/infographic-1024x318.png 1024w\" sizes=\"(max-width: 1771px) 100vw, 1771px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. The end-to-end data to training pipeline, starting with Omniverse Replicator, and ending in the Edge Impulse platform</em></figcaption></figure></div>\n\n\n<p>Using the synthetically generated images in USD to train models in Edge Impulse only takes a few clicks with the new Edge Impulse Omniverse extension.</p>\n\n\n\n<p>Using the extension, which was developed using the <a href=\"https://github.com/NVIDIA-Omniverse/kit-extension-template\" target=\"_blank\" rel=\"noreferrer noopener\">Omniverse Kit Python extension template</a>, users can connect to the Edge Impulse API and select the dataset to upload their synthetic data. The Kit Python extension template is a simple and self-explanatory resource for code snippet options and developing an extension quickly.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Generating synthetic data for an object detection model</h2>\n\n\n\n<p>To understand the workflow for generating synthetic data with Omniverse Replicator and using it to train a model in Edge Impulse, follow our example detecting soda cans model.</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"1999\" height=\"944\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/soda-cans-synthetic-datasets.png\" alt=\"Two images showing cans being detected at different camera angles and distances.\" class=\"wp-image-70821\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/soda-cans-synthetic-datasets.png 1999w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/soda-cans-synthetic-datasets-300x142.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/soda-cans-synthetic-datasets-625x295.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/soda-cans-synthetic-datasets-179x85.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/soda-cans-synthetic-datasets-768x363.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/soda-cans-synthetic-datasets-1536x725.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/soda-cans-synthetic-datasets-645x305.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/soda-cans-synthetic-datasets-500x236.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/soda-cans-synthetic-datasets-160x76.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/soda-cans-synthetic-datasets-362x171.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/soda-cans-synthetic-datasets-233x110.png 233w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/soda-cans-synthetic-datasets-1024x484.png 1024w\" sizes=\"(max-width: 1999px) 100vw, 1999px\" /><figcaption class=\"wp-element-caption\"><em>Figure 2. An object detection model that detects soda cans after being trained on synthetic datasets</em></figcaption></figure></div>\n\n\n<p>The first step in the process is building a virtual replica or a digital twin of the environment that represents the real scenario. The scene for generating synthetic images \u200cconsists of movable and immovable objects. The immovable set includes lights, a conveyor belt, and two cameras, while the movable objects consist of soda cans. Employing <a href=\"https://docs.omniverse.nvidia.com/extensions/latest/ext_replicator/randomizer_details.html#learning-objectives\" target=\"_blank\" rel=\"noreferrer noopener\">domain randomization</a>, you can alter many properties, including location, lighting, colors, texture, background, and foreground of select immovable and movable objects.&nbsp;</p>\n\n\n\n<p>These assets are represented in Omniverse Replicator through OpenUSD. 3D model files can be converted into USD and imported into Omniverse Replicator using the Omniverse CAD Importer extension.</p>\n\n\n\n<p>Lighting plays a pivotal role in realistic image generation. Rectangular lights can emulate light generated from a panel and a dome light brightens the entire scene. You can randomize various parameters for the lights like temperature, intensity, scale, position, and rotation of the lights.&nbsp;</p>\n\n\n\n<p>The following script shows temperature and intensity randomized through sampling from normal distributions, with scales randomized by a uniform distribution. The position and rotation of lights are fixed to remain constant.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>python\n\n# Lightning setup for Rectangular light and Dome light&nbsp;\n\ndef rect_lights(num=1):\n\n&nbsp;&nbsp;&nbsp;&nbsp;lights = rep.create.light(\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;light_type=\"rect\",\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;temperature=rep.distribution.normal(6500, 500),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;intensity=rep.distribution.normal(0, 5000),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;position=(45, 110, 0),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rotation=(-90, 0, 0),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;scale=rep.distribution.uniform(50, 100),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;count=num\n\n&nbsp;&nbsp;&nbsp;&nbsp;)\n\n&nbsp;&nbsp;&nbsp;&nbsp;return lights.node\n\nrep.randomizer.register(rect_lights)\n\ndef dome_lights(num=3):\n\n&nbsp;&nbsp;&nbsp;&nbsp;lights = rep.create.light(\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;light_type=\"dome\",\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;temperature=rep.distribution.normal(6500, 500),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;intensity=rep.distribution.normal(0, 1000),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;position=(45, 120, 18),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rotation=(225, 0, 0),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;count=num\n\n&nbsp;&nbsp;&nbsp;&nbsp;)\n\n&nbsp;&nbsp;&nbsp;&nbsp;return lights.node\n\nrep.randomizer.register(dome_lights)</code></pre>\n\n\n\n<p>Most scenes have immovable objects important to the environment, like a table or in this case, a conveyor belt. The position of these objects can be fixed, while the material of the objects can be randomized to reflect real-world possibilities.</p>\n\n\n\n<p>The following script generates a conveyor belt in USD that the cans will be placed upon. It also fixes its position and rotation. In this example, we don\u2019t randomize the material of the conveyor belt.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>python&nbsp;\n\n# Import and position the conveyor belt\n\nconveyor = rep.create.from_usd(CONVEYOR_USD, semantics=&#91;('class', 'conveyor')])\n\nwith conveyor:\n\n&nbsp;&nbsp;&nbsp;&nbsp;rep.modify.pose(\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;position=(0, 0, 0),\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;rotation=(0, -90, -90),\n\n&nbsp;&nbsp;&nbsp;&nbsp;)</code></pre>\n\n\n\n<p>To guarantee a high-quality dataset, it\u2019s a good idea to use multiple cameras with different resolutions, and position them strategically in the scene. The position of the cameras can also be randomized. This script sets up two cameras of different resolutions strategically placed at various locations in the scene.</p>\n\n\n\n<pre class=\"wp-block-code\"><code># Multiple setup cameras and attach to render products\n\ncamera = rep.create.camera(focus_distance=focus_distance, focal_length=focal_length,\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;position=cam_position, rotation=cam_rotation, f_stop=f_stop)\n\ncamera2 = rep.create.camera(focus_distance=focus_distance2, focal_length=focal_length2,\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;position=cam_position2, rotation=cam_rotation, f_stop=f_stop)\n\n# Render images\n\nrender_product = rep.create.render_product(camera, (1024, 1024))\n\nrender_product2 = rep.create.render_product(camera2, (1024, 1024))</code></pre>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"1280\" height=\"720\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/synthetic-images-multiple-camera-positions.jpg\" alt=\"Image on left shows a close-up of cans on the conveyor belt, while image on right shows camera positioned further away from conveyor belt.\" class=\"wp-image-70823\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/synthetic-images-multiple-camera-positions.jpg 1280w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/synthetic-images-multiple-camera-positions-300x169.jpg 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/synthetic-images-multiple-camera-positions-625x352.jpg 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/synthetic-images-multiple-camera-positions-179x101.jpg 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/synthetic-images-multiple-camera-positions-768x432.jpg 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/synthetic-images-multiple-camera-positions-645x363.jpg 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/synthetic-images-multiple-camera-positions-960x540.jpg 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/synthetic-images-multiple-camera-positions-500x281.jpg 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/synthetic-images-multiple-camera-positions-160x90.jpg 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/synthetic-images-multiple-camera-positions-362x204.jpg 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/synthetic-images-multiple-camera-positions-196x110.jpg 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/synthetic-images-multiple-camera-positions-1024x576.jpg 1024w\" sizes=\"(max-width: 1280px) 100vw, 1280px\" /><figcaption class=\"wp-element-caption\"><em>Figure 3. Generating synthetic images from multiple camera positions</em></figcaption></figure></div>\n\n\n<p>The last step is randomizing the position of the movable objects while also keeping them in the relevant area. In this script, we initialize five instances of 3D-can models, randomly selected from a collection of available can assets.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>cans = list()\n\nfor i in range(TOTAL_CANS):\n\n    random_can = random.choice(cans_list)\n\n    random_can_name = random_can.split(\".\")&#91;0].split(\"/\")&#91;-1]\n\n    this_can = rep.create.from_usd(random_can, semantics=&#91;('class', 'can')]) \n\n    with this_can:\n\n        rep.modify.pose(\n\n            position=(0, 0, 0),\n\n            rotation=(0, -90, -90)\n\n        )\n\n    cans.append(this_can)</code></pre>\n\n\n\n<p>Then, the pose of the cans is randomized and scattered across two planes, keeping the cans on the conveyor belt while avoiding collisions.</p>\n\n\n\n<pre class=\"wp-block-code\"><code>with rep.trigger.on_frame(num_frames=50, rt_subframes=55):\n\n    planesList=&#91;('class','plane1'),('class','plane2')]\n\n    with rep.create.group(cans):\n\n        planes=rep.get.prims(semantics=planesList)\n\n        rep.modify.pose(\n\n            rotation=rep.distribution.uniform(\n\n                (-90, -180, 0), (-90, 180, 0)\n\n            )\n\n        )\n\n        rep.randomizer.scatter_2d(planes, check_for_collisions=True)</code></pre>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"600\" height=\"330\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/conveyor-belt-cans.gif\" alt=\"Multple cans on a conveyor belt.\" class=\"wp-image-70824\"/><figcaption class=\"wp-element-caption\"><em>Figure 4. Cans scattered across the conveyor belt in random poses</em></figcaption></figure></div>\n\n\n<h2 class=\"wp-block-heading\">Annotating data, building the model, and testing with real objects</h2>\n\n\n\n<p>After being generated, the images can be uploaded to Edge Impulse Studio in a few clicks with the Edge Impulse Omniverse extension. In Edge Impulse Studio, datasets can be annotated and trained using models, such as the <a href=\"https://github.com/edgeimpulse/yolov5\" target=\"_blank\" rel=\"noreferrer noopener\">Yolov5<strong> </strong>object detection model</a>. The version control system enables model performance tracking across different dataset versions and hyperparameters, to optimize precision.</p>\n\n\n\n<p>To test model accuracy with real-world objects, you can stream live video and run the model locally using the <a href=\"https://docs.edgeimpulse.com/docs/tools/edge-impulse-cli\" target=\"_blank\" rel=\"noreferrer noopener\">Edge Impulse CLI</a> tool.&nbsp;</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"1700\" height=\"954\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/model-Edge-Impulse.png\" alt=\"User interface for Edge Impulse, showing how someone can assess the performance of their model based on the classification results when testing on different dataset versions.\" class=\"wp-image-70828\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/model-Edge-Impulse.png 1700w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/model-Edge-Impulse-300x168.png 300w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/model-Edge-Impulse-625x351.png 625w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/model-Edge-Impulse-179x100.png 179w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/model-Edge-Impulse-768x431.png 768w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/model-Edge-Impulse-1536x862.png 1536w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/model-Edge-Impulse-645x362.png 645w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/model-Edge-Impulse-960x540.png 960w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/model-Edge-Impulse-500x281.png 500w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/model-Edge-Impulse-160x90.png 160w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/model-Edge-Impulse-362x203.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/model-Edge-Impulse-196x110.png 196w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/model-Edge-Impulse-1024x575.png 1024w\" sizes=\"(max-width: 1700px) 100vw, 1700px\" /><figcaption class=\"wp-element-caption\"><em>Figure 5. Testing model precision in Edge Impulse</em></figcaption></figure></div>\n\n\n<p>If the model does not detect the objects accurately, the model must be trained on additional datasets. This iterative process is the norm when it comes to AI model training. An added benefit of synthetic data is that required variations in subsequent iterations can be done programmatically.&nbsp;</p>\n\n\n\n<p>In this example, an additional synthetic dataset was generated and used to train the model to improve performance. The additional dataset used a camera distance further from the conveyor. Other parameters like the angle of the camera and materials can be modified in additional datasets to improve performance.&nbsp;</p>\n\n\n\n<p>Taking a data-centric approach, where you create more data around the failure points of the model, is crucial to solving ML problems. Additional training and fine-tuning of parameters can enable a model to generalize well across different orientations, materials, and other relevant conditions.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Get started training and deploying edge AI with synthetic data</h2>\n\n\n\n<p>Generating physically accurate synthetic data is easy in Omniverse Replicator. Simply <a href=\"https://www.nvidia.com/en-us/omniverse/download/\" target=\"_blank\" rel=\"noreferrer noopener\">download </a><a href=\"https://www.nvidia.com/en-us/omniverse/download/\">Omniverse free</a> and follow the instructions for <a href=\"https://docs.omniverse.nvidia.com/extensions/latest/ext_replicator/getting_started.html\" target=\"_blank\" rel=\"noreferrer noopener\">getting started with Replicator in Omniverse Code</a>.</p>\n\n\n\n<p>With Edge Impulse, you can use synthetic data generated in Omniverse to train your ML models. <a href=\"https://studio.edgeimpulse.com/trial-signup\" target=\"_blank\" rel=\"noreferrer noopener\">Sign up</a> and begin using embedded machine learning models today.</p>\n\n\n\n<p>Join Amit Goel, director of product management at NVIDIA, at the <a href=\"https://edgeimpulse.com/imagine\" target=\"_blank\" rel=\"noreferrer noopener\">Imagine 2023</a> keynote. Learn about industry insights on AI and machine learning, as well as use cases made possible by <a href=\"https://developer.nvidia.com/omniverse\" target=\"_blank\" rel=\"noreferrer noopener\">NVIDIA Omniverse</a> and Omniverse Replicator.&nbsp;&nbsp;&nbsp;</p>\n\n\n\n<p>Stay up to date with NVIDIA Omniverse by subscribing to the<a href=\"https://nvda.ws/3u5KPv1\" target=\"_blank\" rel=\"noreferrer noopener\"> newsletter</a>, and following us on<a href=\"https://www.instagram.com/nvidiaomniverse/\" target=\"_blank\" rel=\"noreferrer noopener\"> Instagram</a>,<a href=\"https://medium.com/@nvidiaomniverse\" target=\"_blank\" rel=\"noreferrer noopener\"> Medium</a>, and<a href=\"https://twitter.com/nvidiaomniverse\" target=\"_blank\" rel=\"noreferrer noopener\"> Twitter</a>. For more resources, check out our<a href=\"https://forums.developer.nvidia.com/c/omniverse/300\" target=\"_blank\" rel=\"noreferrer noopener\"> forums</a>,<a href=\"https://discord.com/invite/XWQNJDNuaC\"> </a><a href=\"https://discord.com/invite/XWQNJDNuaC\" target=\"_blank\" rel=\"noreferrer noopener\">Discord </a><a href=\"https://discord.com/invite/XWQNJDNuaC\">server</a>,<a href=\"https://www.twitch.tv/nvidiaomniverse\" target=\"_blank\" rel=\"noreferrer noopener\"> Twitch</a>, and<a href=\"https://www.youtube.com/channel/UCSKUoczbGAcMld7HjpCR8OA\" target=\"_blank\" rel=\"noreferrer noopener\"> YouTube</a> channels.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>AI is rapidly changing industrial visual inspection. In a factory setting, visual inspection is used for many issues, including detecting defects and missing or incorrect parts during assembly. Computer vision can help identify problems with products early on, reducing the chances of them being delivered to customers.&nbsp; However, developing accurate and versatile object detection models &hellip; <a href=\"https://developer.nvidia.com/blog/how-to-train-an-object-detection-model-for-visual-inspection-with-synthetic-data/\">Continued</a></p>\n", "protected": false}, "author": 1876, "featured_media": 70905, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1262858", "discourse_permalink": "https://forums.developer.nvidia.com/t/how-to-train-an-object-detection-model-for-visual-inspection-with-synthetic-data/266813", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [2724, 1235, 503], "tags": [2375, 453, 1718, 3096], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Edge-Impulse-Conveyor-Belt-Feature-Image.png", "jetpack_shortlink": "https://wp.me/pcCQAL-iqg", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70820"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1876"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=70820"}], "version-history": [{"count": 12, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70820/revisions"}], "predecessor-version": [{"id": 70912, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70820/revisions/70912"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/70905"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=70820"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=70820"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=70820"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 70826, "date": "2023-09-14T12:00:00", "date_gmt": "2023-09-14T19:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=70826"}, "modified": "2023-10-25T16:51:21", "modified_gmt": "2023-10-25T23:51:21", "slug": "software-defined-broadcast-with-nvidia-holoscan-for-media", "status": "publish", "type": "post", "link": "https://developer.nvidia.com/blog/software-defined-broadcast-with-nvidia-holoscan-for-media/", "title": {"rendered": "Software-Defined Broadcast with NVIDIA Holoscan for Media"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>The broadcast industry is undergoing a transformation in how content is created, managed, distributed, and consumed. This transformation includes a shift from traditional linear workflows bound by fixed-function devices to flexible and hybrid, software-defined systems that enable the future of live streaming.&nbsp;&nbsp;</p>\n\n\n\n<p>Developers can now apply to join the early access program for <a href=\"https://developer.nvidia.com/holoscan-for-media\" target=\"_blank\" rel=\"noreferrer noopener\">NVIDIA Holoscan for Media</a>, a software-defined platform for developing and deploying media applications on-prem, in the cloud, and at the edge.</p>\n\n\n\n<p>Using Holoscan for Media, broadcasters and solution providers can leverage the latest IT and provisioning technologies and a modern container-based approach to development, orchestration, and delivery.&nbsp;&nbsp;</p>\n\n\n\n<p>Holoscan for Media is an IP-based solution built on industry standards and APIs including SMPTE ST 2110, AMWA NMOS, RIST, SRT, and NDI.&nbsp;&nbsp;</p>\n\n\n\n<p>The platform integrates open-source and ubiquitous technologies, breaking from the proprietary and inflexible nature of SDI and FPGA-based systems. It also enables incorporation of the latest capabilities in production\u2014such as <a href=\"https://www.nvidia.com/en-us/glossary/data-science/generative-ai/\">generative AI</a>\u2014without additional infrastructure investments. With Holoscan for Media, countless NVIDIA application frameworks and SDKs are made accessible \u200b\u200bto the industry for development.&nbsp;&nbsp;</p>\n\n\n\n<p>This framework provides several benefits to both broadcasters and solution providers, including:&nbsp;</p>\n\n\n\n<ul>\n<li><strong>Repurposability:</strong> Use a single platform for many applications.&nbsp;</li>\n\n\n\n<li><strong>Lower TCO:</strong> Benefit from the cyclical cost reductions.&nbsp;</li>\n\n\n\n<li><strong>Flexibility:</strong> The platform is cloud-native and independent of location. An application can be developed once and deployed everywhere.&nbsp;</li>\n\n\n\n<li><strong>Sustainability:</strong> Provisioning technologies that drive resource sharing means that overall less equipment is required. This means lower power and cooling costs and reduced impact from shipping to and from events. Ultimately, this leads to CO2 reductions.&nbsp;&nbsp;</li>\n</ul>\n\n\n\n<figure class=\"wp-block-embed aligncenter is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio\"><div class=\"wp-block-embed__wrapper\">\n<span class=\"embed-youtube\" style=\"text-align:center; display: block;\"><iframe loading=\"lazy\" class=\"youtube-player\" width=\"640\" height=\"360\" src=\"https://www.youtube.com/embed/ZRZqdUnc_w0?version=3&#038;rel=1&#038;showsearch=0&#038;showinfo=1&#038;iv_load_policy=1&#038;fs=1&#038;hl=en-US&#038;autohide=2&#038;wmode=transparent\" allowfullscreen=\"true\" style=\"border:0;\" sandbox=\"allow-scripts allow-same-origin allow-popups allow-presentation allow-popups-to-escape-sandbox\"></iframe></span>\n</div></figure>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>IP-based platform architecture</strong>&nbsp;</h2>\n\n\n\n<p>NVIDIA Holoscan targets sensor data and media processing applications deployed at-scale across countless industries, in the cloud, on premises, and at the edge. Holoscan for Media tightens the focus on broadcast and live production workflows, with the first target being on-premises deployments.&nbsp;</p>\n\n\n<div class=\"wp-block-image\">\n<figure class=\"aligncenter size-full\"><img decoding=\"async\" loading=\"lazy\" width=\"520\" height=\"694\" src=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-1.-Holoscan-for-Media-platform-architecture.png\" alt=\"Image of NVIDIA Holoscan for Media platform architecture pieces described in the next section.\" class=\"wp-image-70831\" srcset=\"https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-1.-Holoscan-for-Media-platform-architecture.png 520w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-1.-Holoscan-for-Media-platform-architecture-225x300.png 225w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-1.-Holoscan-for-Media-platform-architecture-86x115.png 86w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-1.-Holoscan-for-Media-platform-architecture-67x90.png 67w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-1.-Holoscan-for-Media-platform-architecture-362x483.png 362w, https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Figure-1.-Holoscan-for-Media-platform-architecture-82x110.png 82w\" sizes=\"(max-width: 520px) 100vw, 520px\" /><figcaption class=\"wp-element-caption\"><em>Figure 1. Holoscan for Media platform architecture&nbsp;&nbsp;</em></figcaption></figure></div>\n\n\n<p>The hardware basis of the platform is therefore NVIDIA-certified systems from our partners, using <a href=\"https://www.nvidia.com/en-us/data-center/ampere-architecture/\" target=\"_blank\" rel=\"noreferrer noopener\">NVIDIA Ampere architecture</a> or later GPUs and <a href=\"https://www.nvidia.com/en-us/networking/products/data-processing-unit/\" target=\"_blank\" rel=\"noreferrer noopener\">NVIDIA BlueField-2</a> or later DPUs. The first systems are x86, but the entire software stack is multi-architecture to enable a wide range of systems and use cases with lower power consumption. In production, a minimal Holoscan for Media cluster consists of three nodes, and scales from there.&nbsp;</p>\n\n\n\n<p>The software stack begins with Kubernetes, the open-source container orchestration system for automating software deployment, scaling, and management. Partnering with the Red Hat OpenShift Container Platform brings enterprise-grade operation and support.&nbsp;</p>\n\n\n\n<p>The inclusion of Kubernetes plug-ins, known as operators, which provide and manage the hardware and underlay services, frees software developers to focus on their unique functionality. The open-source OpenShift Node Tuning Operator, <a href=\"https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/index.html\" target=\"_blank\" rel=\"noreferrer noopener\">NVIDIA GPU Operator</a>, and <a href=\"https://catalog.ngc.nvidia.com/orgs/nvidia/teams/cloud-native/containers/network-operator\" target=\"_blank\" rel=\"noreferrer noopener\">NVIDIA Network Operator</a> provide system, GPU, and high-speed secondary networking, tuned for performance and made available to every application that needs them. The GPU Operator can be used to assign one or more entire GPUs to an application.&nbsp;</p>\n\n\n\n<p>Support for <a href=\"https://www.nvidia.com/en-us/technologies/multi-instance-gpu/\" target=\"_blank\" rel=\"noreferrer noopener\">MIG (Multi-Instance GPU)</a> and <a href=\"https://www.nvidia.com/en-us/data-center/virtual-solutions/\" target=\"_blank\" rel=\"noreferrer noopener\">vGPU (virtual GPU) </a>enables GPUs to be securely shared between applications. The PTP Operator uses the PTP Hardware Clock on NVIDIA DPUs to provide precise timing from the secondary network to each application through a simple \u201cget time\u201d API. Other operators and plug-ins take care of IP address management (IPAM), DNS zone management, and more.&nbsp;</p>\n\n\n\n<p>Holoscan for Media also includes services such as an NMOS Registry and an easy-to-use graph-builder-based NMOS Controller user interface. These can be installed to support development and deployment of applications that act as media nodes and simplify integration with broadcast facility networks.&nbsp;</p>\n\n\n\n<p>Applications on the platform are packaged with Helm for simple, consistent deployment. A developer can indicate each container\u2019s required capabilities and resources, including GPU, CPU, memory, and storage. This enables the platform to schedule and monitor applications to ensure each one is appropriately isolated, their requirements are met, and that best use is made of the available hardware.&nbsp;</p>\n\n\n\n<p>Developers can build applications using the growing list of NVIDIA SDKs supported on the Holoscan for Media platform. Traditional real-time video encoding and decoding with the<a href=\"https://developer.nvidia.com/video-codec-sdk\" target=\"_blank\" rel=\"noreferrer noopener\"> Video Codec SDK</a>, GPU-accelerated computer vision by<a href=\"https://developer.nvidia.com/cv-cuda\" target=\"_blank\" rel=\"noreferrer noopener\"> CV-CUDA library</a>, and any parallel compute algorithm using the <a href=\"https://developer.nvidia.com/cuda-toolkit\" target=\"_blank\" rel=\"noreferrer noopener\">&nbsp;CUDA toolkit</a>. On top of GPU-accelerated inference through<a href=\"https://developer.nvidia.com/tensorrt\" target=\"_blank\" rel=\"noreferrer noopener\"> TensorRT SDK</a> or<a href=\"https://developer.nvidia.com/triton-inference-server\" target=\"_blank\" rel=\"noreferrer noopener\"> NVIDIA Triton Inference Server</a>, new AI capabilities are offered by SDK and Cloud APIs like<a href=\"https://developer.nvidia.com/maxine\" target=\"_blank\" rel=\"noreferrer noopener\"> Maxine</a> or<a href=\"https://developer.nvidia.com/omniverse/ace\" target=\"_blank\" rel=\"noreferrer noopener\"> NVIDIA Avatar Cloud Engine (ACE)</a>. Foundational SMPTE 2110 support and optimization of large media transfer is provided through <a href=\"https://developer.nvidia.com/networking/rivermax\">NVIDIA </a><a href=\"https://developer.nvidia.com/networking/rivermax\" target=\"_blank\" rel=\"noreferrer noopener\">Rivermax </a><a href=\"https://developer.nvidia.com/networking/rivermax\">SDK</a>. Developers can natively leverage Rivermax on the platform or through the <a href=\"https://developer.nvidia.com/deepstream-sdk\" target=\"_blank\" rel=\"noreferrer noopener\">DeepStream SDK</a>, a complete streaming analytics toolkit based on GStreamer for AI-based media processing. Additionally, if developers have wider use cases beyond media, and want to consume and control other sensor types, NVIDIA provides the <a href=\"https://developer.nvidia.com/holoscan-sdk\" target=\"_blank\" rel=\"noreferrer noopener\">Holoscan SDK</a> for creating real-time, AI-enabled sensor processing pipelines that meet latency requirements and scale from the data center to the edge.</p>\n\n\n\n<p>Full source for a containerized reference application is available to Holoscan for Media developers. This uses NVIDIA DeepStream and can be configured as an NMOS-capable ST 2110 transmitter, receiver or transcoder gateway.&nbsp;</p>\n\n\n\n<p>Altogether, this open platform architecture provides the building blocks for the Dynamic Media Facility, using the latest scalable IT and provisioning technologies and open standards to benefit both broadcasters and software vendors.&nbsp;</p>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>Get started with Holoscan for Media </strong>&nbsp;</h2>\n\n\n\n<p>Holoscan for Media is now available for <a href=\"https://developer.nvidia.com/holoscan-for-media\" target=\"_blank\" rel=\"noreferrer noopener\">early access</a>.&nbsp;Note that you must be registered in the<a href=\"https://developer.nvidia.com/developer-program\" target=\"_blank\" rel=\"noreferrer noopener\"> NVIDIA Developer Program</a> to apply for the early access release. You must also be logged in using your organization\u2019s email address. We cannot accept applications from accounts using Gmail, Yahoo, QQ, or other personal email accounts.</p>\n\n\n\n<p>To participate, fill out the short application form and provide details about your use case.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>The broadcast industry is undergoing a transformation in how content is created, managed, distributed, and consumed. This transformation includes a shift from traditional linear workflows bound by fixed-function devices to flexible and hybrid, software-defined systems that enable the future of live streaming.&nbsp;&nbsp; Developers can now apply to join the early access program for NVIDIA Holoscan &hellip; <a href=\"https://developer.nvidia.com/blog/software-defined-broadcast-with-nvidia-holoscan-for-media/\">Continued</a></p>\n", "protected": false}, "author": 1874, "featured_media": 70829, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "1261311", "discourse_permalink": "https://forums.developer.nvidia.com/t/software-defined-broadcast-with-nvidia-holoscan-for-media/266450", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "", "_links_to_target": ""}, "categories": [1235, 852, 2758, 1205, 1903], "tags": [453, 572, 49, 796], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/Holoscan-media-Techblog-1480x830-1.png", "jetpack_shortlink": "https://wp.me/pcCQAL-iqm", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70826"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1874"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=70826"}], "version-history": [{"count": 8, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70826/revisions"}], "predecessor-version": [{"id": 70903, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70826/revisions/70903"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/70829"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=70826"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=70826"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=70826"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 70848, "date": "2023-09-14T10:00:00", "date_gmt": "2023-09-14T17:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=70848"}, "modified": "2023-10-05T11:18:11", "modified_gmt": "2023-10-05T18:18:11", "slug": "adobe-scales-ml-pipelines-for-optimized-delivery-of-brand-messages", "status": "publish", "type": "post", "link": "https://nvda.ws/3EAXUAv", "title": {"rendered": "ICYMI: Run RAPIDS-Accelerated Apache Spark on Amazon EMR"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>Streamline and accelerate deployment by integrating ETL and ML training into a single Apache Spark script on Amazon EMR.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Streamline and accelerate deployment by integrating ETL and ML training into a single Apache Spark script on Amazon EMR.</p>\n", "protected": false}, "author": 1316, "featured_media": 70851, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "", "discourse_permalink": "", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "https://nvda.ws/3EAXUAv", "_links_to_target": "_blank"}, "categories": [852, 696], "tags": [278, 453], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/RAPIDS-Accelerated-Apache-Spark-e1694623961825.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-iqI", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70848"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1316"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=70848"}], "version-history": [{"count": 4, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70848/revisions"}], "predecessor-version": [{"id": 71093, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70848/revisions/71093"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/70851"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=70848"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=70848"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=70848"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}, {"id": 70806, "date": "2023-09-13T08:00:00", "date_gmt": "2023-09-13T15:00:00", "guid": {"rendered": "https://developer.nvidia.com/blog/?p=70806"}, "modified": "2023-10-05T11:18:12", "modified_gmt": "2023-10-05T18:18:12", "slug": "new-course-generative-ai-explained", "status": "publish", "type": "post", "link": "https://nvda.ws/3qN7PQ9", "title": {"rendered": "New Course: Generative AI Explained"}, "content": {"rendered": "<div style=\"margin-top: 0px; margin-bottom: 0px;\" class=\"sharethis-inline-share-buttons\" ></div>\n<p>Explore generative AI concepts and applications, along with challenges and opportunities in this self-paced course.</p>\n", "protected": false}, "excerpt": {"rendered": "<p>Explore generative AI concepts and applications, along with challenges and opportunities in this self-paced course.</p>\n", "protected": false}, "author": 1115, "featured_media": 70809, "comment_status": "open", "ping_status": "open", "sticky": false, "template": "", "format": "standard", "meta": {"publish_to_discourse": "", "publish_post_category": "318", "wpdc_auto_publish_overridden": "1", "wpdc_topic_tags": "", "wpdc_pin_topic": "", "wpdc_pin_until": "", "discourse_post_id": "", "discourse_permalink": "", "wpdc_publishing_response": "success", "wpdc_publishing_error": "", "footnotes": "", "_links_to": "https://nvda.ws/3qN7PQ9", "_links_to_target": "_blank"}, "categories": [1050, 3110, 1903], "tags": [2964, 1935, 453], "acf": [], "jetpack_featured_media_url": "https://developer-blogs.nvidia.com/wp-content/uploads/2023/09/dli-blog-new-self-paced-generative-ai-explained-1920x1080-1.jpg", "jetpack_shortlink": "https://wp.me/pcCQAL-iq2", "jetpack_likes_enabled": true, "jetpack_sharing_enabled": true, "_links": {"self": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70806"}], "collection": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts"}], "about": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/types/post"}], "author": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/users/1115"}], "replies": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/comments?post=70806"}], "version-history": [{"count": 5, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70806/revisions"}], "predecessor-version": [{"id": 70813, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/posts/70806/revisions/70813"}], "wp:featuredmedia": [{"embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media/70809"}], "wp:attachment": [{"href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/media?parent=70806"}], "wp:term": [{"taxonomy": "category", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/categories?post=70806"}, {"taxonomy": "post_tag", "embeddable": true, "href": "https://developer-blogs.nvidia.com/wp-json/wp/v2/tags?post=70806"}], "curies": [{"name": "wp", "href": "https://api.w.org/{rel}", "templated": true}]}}]